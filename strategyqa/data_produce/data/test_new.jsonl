{"qid": "3a20f77eb5aaebb051c7", "term": "D", "description": "letter in the Latin alphabet", "question": "Is the letter D influenced by the shape of ancient doors?", "answer": true, "facts": ["D is the fourth letter of the Latin alphabet", "D is a descendent of the ancient Phoenician Dalet", "Dalet was represented by a glyph of a door"], "decomposition": ["Which ancient language did the letter 'D' descend from?", "What was used to represent 'D' in #1?", "Was #2 a symbol of a door?"], "evidence": [[[["D-2"]], [["Dalet-2"]], [["Dalet-2"]]], [[["D-2"]], [["D-2"]], ["operation"]], [[["D-2"]], [["D-2"]], [["D-2", "Logogram-1"]]]]}
{"qid": "adf00eea72beb009ff3e", "term": "Portuguese Empire", "description": "Global empire centered in Portugal", "question": "Did Columbus obtain his funding from the rulers of the Portugese Empire?", "answer": false, "facts": [" King Ferdinand and Queen Isabella funded Columbus' voyage to the New World.", "King Ferdinand of Argon and Queen Isabella of Castille were the joint rulers of kingdoms of the Iberian Peninsula, which included modern-day Spain but excludes Portugal. ", "King John II of Portugal rejected Columbus' request for funding. "], "decomposition": ["Which major voyage did Columbus require funding to embark upon?", "Who funded #1?", "Which kingdoms did #2 rule over?", "Is the Portuguese Empire included in #3?"], "evidence": [[[["Voyages of Christopher Columbus-62"]], [["Voyages of Christopher Columbus-6"]], [["The empire on which the sun never sets-12"]], ["operation"]], [[["Christopher Columbus-1"]], [["Christopher Columbus-2"]], [["Isabella I of Castile-1"]], ["operation"]], [[["Voyages of Christopher Columbus-7"]], [["Voyages of Christopher Columbus-12"]], [["Voyages of Christopher Columbus-9"]], [["Portuguese Empire-4"], "operation"]]]}
{"qid": "c2f573c79ceab25e8fcd", "term": "Strawberry", "description": "edible fruit", "question": "Can a strawberry get worms similar to dogs?", "answer": true, "facts": ["Strawberry can suffer from black root rot and nematodes.", "Dogs can suffer from a variety of worms including roundworms that lay eggs on them.", "Nematodes are parasites that are also called roundworms and ascarids.", "Nematodes are parasites that feed off of strawberry plants."], "decomposition": ["What types of worms can strawberries become infected with?", "What types of worms can dogs become infected with?", "Are any of #1 present in #2?"], "evidence": [[[["Ditylenchus dipsaci-6"], "no_evidence"], [["Dog-18"]], ["no_evidence", "operation"]], [[["Strawberry-26"]], [["Worm-7"]], [["Worm-7"]]], [["no_evidence"], [["Dog-18"]], ["no_evidence", "operation"]]]}
{"qid": "4773d577873ff9e04a88", "term": "Woodrow Wilson", "description": "28th president of the United States", "question": "Did Woodrow Wilson consider Blacks to be equal members of society?", "answer": false, "facts": ["Woodrow Wilson supported the Ku Klux Klan.", "The Ku Klux Klan consider Blacks to be inferior. "], "decomposition": ["What group did Woodrow Wilson support?", "Did #1 consider Blacks to be equal members of society?"], "evidence": [[[["Woodrow Wilson-79"]], [["Ku Klux Klan-1", "Ku Klux Klan-2"]]], [[["Woodrow Wilson-79"]], [["Ku Klux Klan-104"]]], [[["Woodrow Wilson-79"], "no_evidence"], [["Woodrow Wilson-76"]]]]}
{"qid": "b921f2496791cca37167", "term": "Oyster", "description": "salt-water bivalve mollusc", "question": "Can oysters be preserved without refrigeration? ", "answer": true, "facts": ["In some types of Korean kimchi, oysters are placed between the leaves of nappa cabbage. ", "Many grocery stores carry canned oysters in the shelf stable section. "], "decomposition": ["How are oysters preserved in various types of Korean kimchi?", "What are the common methods of preserving oysters in grocery stores?", "Do any of #1 or #2 not require refrigeration?"], "evidence": [[[["Kimchi-28"], "no_evidence"], [["Oyster-57", "Oyster-61"]], ["operation"]], [[["Korean cuisine-25"], "no_evidence"], ["no_evidence"], ["operation"]], [[["Oyster-48"], "no_evidence"], [["Oyster-35"]], ["operation"]]]}
{"qid": "47ba45019129dd07cb55", "term": "Stephen King", "description": "American author", "question": "Could Stephen King join the NASA Astronaut Corps?", "answer": false, "facts": ["NASA Astronaut Corps candidates must have a master's degree from an accredited institution in engineering, biological science, physical science or mathematics.", "Stephen King studied at the University of Maine, graduating in 1970 with a Bachelor of Arts in English."], "decomposition": ["What degrees are acceptable to meet the minimum requirement for admittance to the NASA Astronaut Corps?", "What degrees does Stephen King hold?", "Is #2 also in #1?"], "evidence": [[[["NASA Astronaut Corps-10"]], [["Stephen King-6"]], ["operation"]], [[["NASA Astronaut Corps-10"]], [["Stephen King-6"]], ["operation"]], [[["NASA Astronaut Corps-10"]], [["Stephen King-6"]], ["operation"]]]}
{"qid": "ff848539d05ca985ed4f", "term": "Hyena", "description": "family of mammal", "question": "Would a human following a hyena diet be unwelcome at a vegan festival?", "answer": true, "facts": ["A hyena is a carnivorous mammal that feeds on the flesh of other animals.", "Vegans are people that stick to a strict diet that does not include animals or animal products."], "decomposition": ["What does the hyena diet consist mainly of?", "What do people on a vegan diet eat?", "Is there an overlap between #1 and #2?"], "evidence": [[[["Hyena-1", "Hyena-3"]], [["Veganism-1"]], ["operation"]], [[["Hyena-21"]], [["Veganism-1"]], ["operation"]], [[["Striped hyena-15"]], [["Veganism-31"]], ["operation"]]]}
{"qid": "ffd8a720264778c0fd6e", "term": "Toyota Hilux", "description": "Series of light commercial vehicles produced by the Japanese car-manufacturer Toyota.", "question": "Can the Toyota Hilux tip the scales against Mr. Ed?", "answer": true, "facts": ["The current generation of Toyota Hilux weighs at least 4,310 lbs", "Mr. Ed was portrayed by an adult horse", "The average adult horse weighs up to 2,000 lbs"], "decomposition": ["What does a Toyota Hilux weigh?", "What does an adult horse weigh?", "Is #1 greater than #2?"], "evidence": [[["no_evidence"], [["Horse-13"]], ["no_evidence", "operation"]], [["no_evidence"], [["Horse-13"]], ["operation"]], [[["Toyota Hilux-1"], "no_evidence"], [["Horse-12"]], ["operation"]]]}
{"qid": "b172aea303690917153e", "term": "Constitution of the Philippines", "description": "Supreme law of the Republic of the Philippines", "question": "Does the Constitution of the Philippines copy text from the British constitution?", "answer": false, "facts": ["The Constitution of the Philippines is a document ratified in 1987", "The British constitution is not an actual document, but a collection of legal statutes, precedent, political custom and social convention"], "decomposition": ["What was the British Constitution?", "What kind of document was the Constitution of the Philippines?", "Can #1 copy something from #2"], "evidence": [[[["Constitution of the United Kingdom-1"]], [["Constitution of the Philippines-1"]], ["operation"]], [[["Constitution of the United Kingdom-1"]], [["Constitution of the Philippines-1"], "no_evidence"], ["no_evidence", "operation"]], [[["Constitution of the United Kingdom-5"]], [["Constitution of the Philippines-1"]], ["no_evidence"]]]}
{"qid": "f39895e719acd479e7ba", "term": "E.T. the Extra-Terrestrial", "description": "1982 American science fiction film directed by Steven Spielberg", "question": "Is the E.T. the Extra-Terrestrial Atari Landfill story an urban legend?", "answer": true, "facts": ["An urban legend is a humorous or horrifying story based on hearsay that is circulated as true.", "E.T. the Extra Terrestrial was panned as one of the worst video games ever made.", "A widespread story stated that thousands of copies of E.T. the Extra Terrestrial video game were buried in a landfill", "A former Atari manager stated that 728,000 Atari games were in fact buried in a landfill.", "The Atari landfill was dug up and nearly 900 games were recovered, but there was only one copy of E.T. included."], "decomposition": ["Was what the widespread landfill rumor concerning copies of E.T. the Extra Terrestial video game?", "When the landfill was dug up, were the claims in #1 found to be false?", "Considering #2, does the rumor fit the description of an urban legend?"], "evidence": [[[["Atari video game burial-2"]], [["Atari video game burial-17"]], [["Legend-15"]]], [[["Atari video game burial-1"]], [["Atari video game burial-18"]], ["operation"]], [[["E.T. the Extra-Terrestrial (video game)-3"]], ["operation"], [["Urban legend-1"], "operation"]]]}
{"qid": "f740fed84da8bd24301a", "term": "Sarah", "description": "Biblical character", "question": "Did Methuselah live at least 800 years as long as Sarah?", "answer": true, "facts": ["The biblical Sarah lived to the age of 127.", "The biblical Methuselah lived to 969 years of age."], "decomposition": ["At what age did Methuselah die?", "At what age did Sarah die?", "What is the difference between #1 and #2?", "Is #3 at least 800?"], "evidence": [[[["Methuselah-1"]], [["Sarah-11"]], ["operation"], ["operation"]], [[["Methuselah-1"]], [["Sarah-11"]], ["operation"], ["operation"]], [[["Methuselah-1"]], [["Sarah-11"]], ["operation"], ["operation"]]]}
{"qid": "c864fb965099ee7f6ebd", "term": "Hypothermia", "description": "A human body core temperature below 35.0°C", "question": "Would someone on Venus be unlikely to experience hypothermia?", "answer": true, "facts": ["Hypothermia typically occurs from exposure to extreme cold.", "The average surface temperature on Venus is 863°F.", "A warmer surface temperature on the planet will result in a higher body temperature for people on that planet."], "decomposition": ["What is the average surface temperature on Venus?", "In order for the human body to experience hypothermia, it would have to be exposed to temperature that are what in relation to body temp?", "What is human body temperature?", "Does #1 meet the condition of #2 relative to #3?"], "evidence": [[[["Venus-23"]], [["Hypothermia-1"]], [["Human body temperature-4"]], ["operation"]], [[["Venus-2"]], [["Hypothermia-2"]], [["Human body temperature-7"]], ["operation"]], [[["Venus-19"]], [["Hypothermia-5"]], [["Human body temperature-4"]], ["operation"]]]}
{"qid": "6d124284e4c5dbc62e9d", "term": "Disneyland Paris", "description": "Theme park resort in France owned by The Walt Disney Company", "question": "Would an American feel lost due to language barriers at Disneyland Paris?", "answer": false, "facts": ["All Disneyland Paris cast members are required to know and speak English.", "Travelers from England go to Disneyland Paris often without issue."], "decomposition": ["What language do Americans mainly speak?", "At Disneyland Paris, what languages are workers required to know?", "Is #1 the same as #2?"], "evidence": [[[["Americans-34"]], [["Disneyland Paris-15"]], ["operation"]], [[["United States-80"]], [["Disneyland Paris-11"]], ["operation"]], [[["American English-2"]], [["Disneyland Paris-11", "Disneyland Paris-15"]], ["operation"]]]}
{"qid": "997096ba85eb878a4fd3", "term": "Eiffel Tower", "description": "Tower located on the Champ de Mars in Paris, France", "question": "Was King Kong climbing at a higher altitude than Eiffel Tower visitors?", "answer": true, "facts": ["The Eiffel Tower is 984 ft high, and the visitor platform is 906 ft high.", "King Kong climbed up to the top of the Empire State Building.", "The Empire State Building is 1230 ft high."], "decomposition": ["How high is the visitor platform at the Eiffel Tower?", "What is the height of the Empire State Building?", "Is #2 higher than #1?"], "evidence": [[[["Eiffel Tower-4"]], [["Empire State Building-1"]], ["operation"]], [[["Eiffel Tower-4"]], [["Empire State Building-1", "Empire State Building-28"]], ["operation"]], [[["Eiffel Tower-4"]], [["Empire State Building-1"]], ["operation"]]]}
{"qid": "a4526fcfad49a21eed15", "term": "Louvre", "description": "Art museum and Historic site in Paris, France", "question": "Can nitric acid break the Louvre?", "answer": true, "facts": ["Parts of the Louvre are built of limestone.", "Nitric acid dissolves limestone."], "decomposition": ["What materials were used to build the Louvre?", "Can any of #1 be destroyed by nitric acid?"], "evidence": [[[["Louvre Pyramid-2"]], [["Nitric acid-18"], "no_evidence", "operation"]], [[["Louvre-21"], "no_evidence"], ["no_evidence"]], [[["Louvre-1"], "no_evidence"], [["Nitric acid-25"], "no_evidence", "operation"]]]}
{"qid": "7f79c8faf724cc8f0e72", "term": "Frankenstein", "description": "1818 novel by Mary Shelley", "question": "Could Robert Wadlow hypothetically see Frankenstein's monster's bald spot from above?", "answer": true, "facts": ["The monster in Mary Shelley's novel, Frankenstein, was said to be 8 feet tall.", "Robert Wadlow was the world's tallest man.", "Robert Wadlow was 8 feet 11.1 inches tall."], "decomposition": ["How tall is Frankenstein?", "How tall is Robert Wadlow?", "Is #2 greater than #1?"], "evidence": [[[["Frankenstein-8"]], [["Robert Wadlow-2"]], ["operation"]], [[["Frankenstein-8"]], [["Robert Wadlow-2"]], ["operation"]], [[["Frankenstein-8"], "no_evidence"], [["Robert Wadlow-2"], "no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "5801d9ee89c288ccb4b7", "term": "Arnold Schwarzenegger", "description": "Austrian-American actor, businessman, bodybuilder and politician", "question": "Would Arnold Schwarzenegger have a hard time picking up a red fox in 1967?", "answer": false, "facts": ["In 1967, Schwarzenegger won the Munich stone-lifting contest, in which a stone weighing 508 German pounds (254 kg / 560 lb) is lifted between the legs while standing on two footrests.", "Red foxes weigh between 2.2–14 kg (5–31 lb)."], "decomposition": ["How much could Arnold Schwarzenegger life in 1967?", "What is the typical weight of a Red Fox?", "Is #2 more than #1?"], "evidence": [[[["Arnold Schwarzenegger-23"]], [["Red fox-18"]], ["operation"]], [[["Arnold Schwarzenegger-23"]], [["Red fox-18"]], ["operation"]], [[["Arnold Schwarzenegger-23"]], [["Vulpes-1"]], ["operation"]]]}
{"qid": "a505361d75535d674ebd", "term": "Paprika", "description": "spice made from dried fruits of Capsicum annuum", "question": "Can Paprika be made without a dehydrator?", "answer": true, "facts": ["Peppers can be dehydrated in the oven in lieu of a dehydrator.", "Sunlight and heat have been used for centuries to dry peppers and other foods."], "decomposition": ["What is paprika made from?", "Can #1 be dehydrated without using a dehydrator?"], "evidence": [[[["Paprika-4"], "no_evidence"], ["no_evidence", "operation"]], [[["Paprika-1"]], [["Food dehydrator-2"], "no_evidence", "operation"]], [[["Paprika-1"]], ["no_evidence"]]]}
{"qid": "f7b1cc5b3fab95aa1be4", "term": "Breast cancer", "description": "cancer that originates in the mammary gland", "question": "Is breast cancer associated with a ribbon?", "answer": true, "facts": ["Breast cancer is one of many diseases associated with a specific color of ribbon.", "Breast cancer's ribbon is pink."], "decomposition": ["Which diseases are associated with a (certain color of) ribbon?", "Is breast cancer included in #1?"], "evidence": [[[["Awareness ribbon-3"]], ["operation"]], [[["Awareness ribbon-3"]], ["operation"]], [[["Awareness ribbon-15"]], [["Awareness ribbon-15"]]]]}
{"qid": "4752f67ef92a9195ee36", "term": "Elijah", "description": "Biblical prophet", "question": "Is Elijah part of a Jewish holiday?", "answer": true, "facts": ["The Jewish holiday Passover involves a traditional ceremonial dinner.", "During the ceremony, it is customary to fill an extra cup with wine and put it at the center of the table.", "The door is then opened so the prophet Elijah can visit."], "decomposition": ["How is Elijah venerated according to Jewish custom?", "Does #1 include venerating Elijah at a holiday?"], "evidence": [[[["Elijah-49"], "no_evidence"], [["Elijah-43", "Elijah-44"], "operation"]], [[["Elijah-49"]], ["no_evidence"]], [[["Passover Seder-62"]], ["operation"]]]}
{"qid": "1d4a642a03f37de1b5d0", "term": "Wheelchair", "description": "chair with wheels, used by people for whom walking is difficult or impossible due to illness, injury, or disability", "question": "Do American wheelchair users know what the ADA is?", "answer": true, "facts": ["The ADA is the Americans with Disabilities Act.", "Non-ADA compliant businesses include those without wheelchair access points."], "decomposition": ["Which areas of interest are affected by the ADA?", "Is any of #1 of particular interest to wheelchair users in America?"], "evidence": [[[["Americans with Disabilities Act of 1990-1"]], [["Disability-4"], "operation"]], [[["American Association of People with Disabilities-1"]], [["American Association of People with Disabilities-1"]]], [[["Americans with Disabilities Act of 1990-6"]], [["Americans with Disabilities Act of 1990-6"]]]]}
{"qid": "68684152725123d32f4b", "term": "Haiku", "description": "very short form of Japanese poetry", "question": "Are most books written as a Haiku?", "answer": false, "facts": ["Haiku is a very short poem", "Haiku is written with 3 short phrases."], "decomposition": ["What is the format of a haiku?", "Are chapter books written like #1?"], "evidence": [[[["Haiku-2"]], ["operation"]], [[["Haiku-2"]], [["Chapter book-1"]]], [[["Haiku-2"]], ["no_evidence"]]]}
{"qid": "95c7c7b36b2dd981b820", "term": "Doctorate", "description": "academic or professional degree", "question": "Is a doctorate required to teach at a SUNY School?", "answer": false, "facts": ["At SUNY schools, there are some full time professors with doctorates.", "At SUNY schools, there are adjunct professors who teach with a Masters degree. "], "decomposition": ["Is it the case, that there are no people teaching at SUNY that do not have a doctorate degree?"], "evidence": [[["no_evidence"]], [[["New York (state)-93", "Professor-18", "Professor-5"]]], [[["SUNY Downstate Medical Center-1"], "no_evidence", "operation"]]]}
{"qid": "770d0ae34440013dcf8e", "term": "Ethiopian cuisine", "description": "Culinary traditions of Ethiopia", "question": "Is shrimp prevalent in Ethiopian cuisine?", "answer": false, "facts": ["Ethiopian cuisine specializes in vegetables and spicy meat dishes.", "Ethiopia is a landlocked country without access to seas or oceans."], "decomposition": ["What kind of aquatic environments are shrimp caught in?", "Does the geography of Ethiopia include any of #1?"], "evidence": [[[["Shrimp-2"]], [["Ethiopia-91"]]], [[["Shrimp and prawn as food-1"]], [["Ethiopia-1"], "operation"]], [[["Shrimp-8"]], [["Ethiopia-90"], "no_evidence"]]]}
{"qid": "6042b48035952d0e1a61", "term": "Friday", "description": "day of the week", "question": "Would an astrologer focus on the densest terrestrial planet for a Friday horoscope?", "answer": true, "facts": ["Friday is associated with Venus in astrology", "Venus is the densest of the terrestrial planets "], "decomposition": ["What astrological body is associated with Friday?", "Which is the densest terrestrial planet?", "Is #2 the same as #1?"], "evidence": [[[["Planetary hours-4"]], [["Venus-19"]], [["Planetary hours-4", "Venus-19"]]], [[["Friday-3"]], [["Outline of Venus-2"]], ["operation"]], [[["Friday-12"]], [["Venus-2"]], ["operation"]]]}
{"qid": "ee6e0bcf7be93da46dcc", "term": "Casio", "description": "Japanese electronics company", "question": "Could Casio's first invention be worn around the ankle?", "answer": false, "facts": ["Casio's first invention was the yubiwa pipe.", "The yubiwa pipe was a ring worn that held a cigarette in place worn on the finger.", "Ankles are several inches thicker than fingers."], "decomposition": ["What was Casio's first invention?", "Where was #1 worn?", "What is the largest diameter of #2?", "What is the smallest diameter of ankle?", "Is #4 less than or equal to #3?"], "evidence": [[[["Casio-2"]], [["Casio-2"]], [["Ring (jewellery)-17"], "no_evidence"], [["Ankle-1"], "no_evidence"], ["operation"]], [[["Casio-2"]], [["Casio-2"]], ["no_evidence"], ["no_evidence"], ["no_evidence", "operation"]], [[["Casio-2"]], [["Casio-2"]], [["Hand-3"], "no_evidence"], [["Ankle-4"], "no_evidence"], ["operation"]]]}
{"qid": "cb08864902f07be76e77", "term": "Earth's magnetic field", "description": "Magnetic field that extends from the Earth’s inner core to where it meets the solar wind", "question": "Do Flat Earthers doubt the existence of Earth's magnetic field?", "answer": true, "facts": ["Theories about the Earth's magnetic field depend on the globe model of the Earth.", "Flat Earthers are skeptical of most science related to the Earth and space, believing it to be part of a conspiracy coverup."], "decomposition": ["Which theory about the earth do the Flat-Earthers believe?", "Which earth theory supports the existence of the earth's magnetic field?", "Does #1 contradict #2?"], "evidence": [[[["Flat Earth-1"]], [["Earth's magnetic field-1"]], ["operation"]], [[["Modern flat Earth societies-1"]], [["Modern flat Earth societies-8"], "no_evidence"], ["no_evidence", "operation"]], [[["Flat Earth-58"]], [["History of geomagnetism-12"]], ["operation"]]]}
{"qid": "3f726a8aa808d26ab076", "term": "Anchor", "description": "Device used to connect a vessel to the bed of a body of water to prevent the craft from drifting", "question": "Does a Trek 9000 require an anchor in order to park?", "answer": false, "facts": ["A Trek 9000 is a mountain bike", "An anchor is used on water borne vehicles like boats"], "decomposition": ["What kind of vehicle is the Trek 9000?", "Does #1 need an anchor to park?"], "evidence": [[[["Trek Bicycle Corporation-7"]], ["operation"]], [[["International 9000-6"], "operation"], ["no_evidence"]], [[["Klein Bicycle Corporation-7"]], [["Bicycle-30"], "operation"]]]}
{"qid": "e29d4982a58b5e70410e", "term": "Eagle", "description": "large carnivore bird", "question": "Would  bald eagle deliver an urgent message before B-52?", "answer": false, "facts": ["A bald eagle can travel up to 99 MPH.", "The B-52 is a US air bomber that can travel up to 650 MPH."], "decomposition": ["How fast can an eagle travel?", "How fast can a B-52 travel?", "Is #1 greater than #2?"], "evidence": [[["no_evidence"], ["no_evidence"], ["no_evidence", "operation"]], [[["Eagle Flight-6"], "no_evidence"], [["B-52 (cocktail)-10"], "no_evidence"], ["no_evidence"]], [["no_evidence"], [["Boeing B-52 Stratofortress-6"]], ["operation"]]]}
{"qid": "955a55c2c64209b0ab7d", "term": "Call of Duty", "description": "First-person shooter video game franchise", "question": "Will Conan the Barbarian hypothetically last a short time inside of Call of Duty?", "answer": true, "facts": ["Conan the Barbarian is a comic book character.", "Conan the Barbarian is equipped with a sword and does not typically wear armor.", "Call of Duty is a modern warfare video game.", "Soldiers in Call of Duty are equipped with weapons like sniper rifles, shotguns, and machine guns."], "decomposition": ["What equipment for fighting does Conan the Barbarian use?", "What equipment for fighting does Call of Duty use?", "Are the items listed in #2 deadlier than those in #1?"], "evidence": [[[["Conan the Barbarian-1"]], [["Call of Duty-1"]], ["no_evidence", "operation"]], [[["Conan the Barbarian-20"]], [["Call of Duty-46"]], [["Sword-58"], "operation"]], [[["Conan the Barbarian-16"]], [["Call of Duty-4"]], ["operation"]]]}
{"qid": "f606b2166555bf5e6bfd", "term": "Cream", "description": "Dairy product", "question": "If someone is lactose intolerant, do they have to avoid cream?", "answer": true, "facts": ["People with lactose intolerance are unable to fully digest the sugar (lactose) in milk.", "Cream is a dairy product composed of the higher-fat layer skimmed from the top of milk before homogenization", "Cream contains milk."], "decomposition": ["What do people who are lactose intolerant have to avoid?", "Does cream contain #1?"], "evidence": [[[["Lactose intolerance-1"]], [["Cream-1", "Milk-51"]]], [[["Lactose intolerance-1"]], [["Cream-1"], "operation"]], [[["Lactose intolerance-1"]], [["Cream-1"], "operation"]]]}
{"qid": "e6fc47d0cb907a7ee266", "term": "Tonsillitis", "description": "Inflammation of the tonsils", "question": "Is strep throat harmless to singer Rita Ora after her 2020 tonsilitis surgery?", "answer": false, "facts": ["Tonsilitis is an inflammation of the tonsils.", "Singer Rita Ora had her tonsils removed in February of 2020 due to tonsilitis.", "Strep throat can still grow in the throat of people without tonsils."], "decomposition": ["What causes strep throat?", "Does #1 only flourish when tonsils are present?"], "evidence": [[[["Streptococcal pharyngitis-1"]], ["no_evidence"]], [[["Throat irritation-7"]], [["Streptococcal pharyngitis-1"]]], [[["Streptococcal pharyngitis-2"]], [["Streptococcal pharyngitis-1"], "no_evidence", "operation"]]]}
{"qid": "ab1f7f17560c5b0bc203", "term": "Eddie Murphy", "description": "American stand-up comedian and actor", "question": "Could Eddie Murphy's children hypothetically fill a basketball court by themselves?", "answer": true, "facts": ["Eddie Murphy has ten children.", "Basketball is played with two teams, each having five players on the court at one time."], "decomposition": ["How many children does Eddie Murphy have?", "How many players are on a basketball team?", "How many teams are on the basketball court at the same time?", "How much is #2 multiplied by #3?", "Is #1 greater than or equal to #4?"], "evidence": [[[["Eddie Murphy-40", "Eddie Murphy-41", "Eddie Murphy-43"]], [["Basketball-1"]], [["Basketball-1"]], ["operation"], ["operation"]], [[["Eddie Murphy-40"], "no_evidence"], [["Basketball-3"]], [["Basketball-1"]], ["operation"], ["operation"]], [[["Eddie Murphy-41"], "no_evidence"], [["Basketball-3"]], [["Basketball-1"]], ["operation"], ["operation"]]]}
{"qid": "a12eb8ae9b38c231a00f", "term": "Maroon 5", "description": "American pop punk band", "question": "Could Maroon 5 have hypothetically held a concert at Roman Colosseum?", "answer": true, "facts": ["The Roman Colosseum had a capacity of 87,000 people. ", "Maroon 5 has held concerts at Brazil's Allianz Parque, which has a capacity of close to 44,000.", "Almost 30,000 people attended Maroon 5's 2015 Madison Square Garden concert over two days."], "decomposition": ["How many spectators could the Roman Colosseum hold?", "How many people were in attendance at Maroon 5's largest concert?", "Is #1 greater than #2?"], "evidence": [[[["Colosseum-1"]], ["no_evidence"], ["operation"]], [[["Colosseum-1"]], [["Super Bowl LIII halftime show-1"], "no_evidence"], ["no_evidence", "operation"]], [[["Colosseum-2"]], [["Maroon V Tour-1"], "no_evidence"], ["operation"]]]}
{"qid": "7b75cf06f6fe3cdf08b4", "term": "Hamster", "description": "subfamily of mammals", "question": "Could a hamster experience two leap years?", "answer": false, "facts": ["Pet hamsters typically have a maximum lifespan of three years.", "Leap years are typically separated by four years."], "decomposition": ["How long is the lifespan of a hamster?", "How many years are between two leap years?", "Is #1 longer than #2?"], "evidence": [[[["Hamster-27"]], [["Leap year-16"]], ["operation"]], [[["Hamster-27"]], [["Leap year-16"]], ["operation"]], [[["Hamster-27"]], [["Leap year-6"]], ["operation"]]]}
{"qid": "3df705e3e1ff592c8149", "term": "Mathematician", "description": "person with an extensive knowledge of mathematics", "question": "Would Hodor hypothetically be a good math mathematician?", "answer": false, "facts": ["Mathematicians are expert students of mathematics.", "Hodor was a dimwitted giant of a man that served House Stark in Game of Thrones.", "Hodor worked in the stables and could only utter the only word he ever said was his own name.", "Mathematicians frequently publish articles on theories and need to be able to read and write."], "decomposition": ["How proficient is Hodor at reading/writing and general intelligence?", "What skills would be required to be good at math?", "Could #1 satisfy #2?"], "evidence": [[[["Hodor (disambiguation)-1"], "no_evidence"], [["Mathematician-1", "Mathematician-12"]], ["operation"]], [["no_evidence"], [["Mathematics-2"], "no_evidence"], ["no_evidence", "operation"]], [["no_evidence"], [["Mathematics-2"], "no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "c4d0ceb86bb1e8faba5c", "term": "Communist Party of the Soviet Union", "description": "Ruling political party of the Soviet Union", "question": "Can the Communist Party of the Soviet Union get a perfect all kill?", "answer": false, "facts": ["The Communist Party of the Soviet Union is a political party", "A perfect all kill occurs when a South Korean recording artist hits number one simultaneously on every music chart"], "decomposition": ["Who can get a perfect all kill?", "Is the Communist Party of the Soviet Union a kind of #1?"], "evidence": [[[["Lisa (rapper)-5"]], [["Communist Party of the Soviet Union-1"], "operation"]], [[["Whistle (Blackpink song)-2"], "no_evidence"], ["no_evidence", "operation"]], [[["Love Scenario-4", "Musical ensemble-1", "Song-1"]], [["Communist Party of the Soviet Union-1"]]]]}
{"qid": "8ab34c769a8b1209b86f", "term": "Pea", "description": "species of plant", "question": "Does Soylent use Pea for their source of protein? ", "answer": false, "facts": ["Soylent is a meal replacement drink that offers 20mg protein.", "The protein in Soylent is derived from Soy."], "decomposition": ["What type of protein does Soylent use?", "Is #1 the same as pea protein?"], "evidence": [[[["Soylent (meal replacement)-1", "Soylent (meal replacement)-16"], "no_evidence"], ["no_evidence", "operation"]], [[["Soylent (meal replacement)-3"]], [["Pea-10"], "operation"]], [[["Soylent (meal replacement)-3"]], ["operation"]]]}
{"qid": "0dad98b7dde01ed9f144", "term": "Greyhound", "description": "Dog breed used in dog racing", "question": "Do people associate greyhounds with the movie 'Homeward Bound'?", "answer": false, "facts": ["The movie homeward bound features a golden retriever. ", "The movie homeward bound features a pit bull type dog.", "There are no greyhounds in homeward bound."], "decomposition": ["What are the two types of dogs that are lost in Homeward Bound?", "Is a greyhound listed in #1?"], "evidence": [[[["Homeward Bound: The Incredible Journey-2"]], [["Homeward Bound: The Incredible Journey-2"], "operation"]], [[["Homeward Bound: The Incredible Journey-2"]], ["operation"]], [[["Homeward Bound: The Incredible Journey-2"]], ["operation"]]]}
{"qid": "a87b94672fd08c0a2f0e", "term": "United States Military Academy", "description": "U.S. Army's federal service academy in West Point, New York", "question": "Would the United States Military Academy reject an applicant with multiple sclerosis?", "answer": true, "facts": ["Multiple Sclerosis is a progressive condition affecting the brain and spinal chord.", "The US Military Academy does not give waivers for serious progressive conditions."], "decomposition": ["What kind of condition is Multiple Sclerosis?", "Would the US Military Academy have to reject someone with #1?"], "evidence": [[[["Multiple sclerosis-5"]], [["United States Military Academy-36"], "no_evidence"]], [[["Multiple sclerosis-1"]], [["United States Naval Academy-99"], "operation"]], [[["Multiple sclerosis-59"], "operation"], ["no_evidence"]]]}
{"qid": "ef398edbb1efa0d9f33f", "term": "Parc des Princes", "description": "football stadium in Paris, France", "question": "Was the Parc des Princes fully operational during June of 2020?", "answer": false, "facts": ["June of 2020 was marked by a global pandemic.", "During a global pandemic, large events are not permitted to proceed fully."], "decomposition": ["What kind of events are usually held in the Parc des Princes?", "In light of recent developments, are such events as #1 still holding in full capacity as of July, 2020?"], "evidence": [[[["Parc des Princes-1"]], [["Coronavirus disease 2019-1", "Social distancing-15"], "no_evidence", "operation"]], [[["Parc des Princes-1"]], [["Impact of the COVID-19 pandemic on sports-23"], "operation"]], [[["Parc des Princes-1", "Parc des Princes-2"]], ["operation"]]]}
{"qid": "ab1703ed82cc14252501", "term": "Edward II of England", "description": "14th-century King of England and Duke of Aquitaine", "question": "Was Edward II crucial to England's victory at Battle of Falkirk?", "answer": false, "facts": ["The Battle of Falkirk was a battle between England and the Scots.", "King Edward I led English forces to victory against William Wallace at the Battle of Falkirk.", "The Battle of Falkirk took place in 1298.", "Edward II was born in 1284 and his first campaign with his father against Scotland happened in 1300.", "Edward II was knighted in 1306."], "decomposition": ["When did the Battle of Falkirk occur?", "When did Edward II start appearing at battles with his father?", "Did #2 occur before #1?"], "evidence": [[[["Battle of Falkirk-1"]], [["Edward II of England-9"], "no_evidence"], ["no_evidence", "operation"]], [[["Battle of Falkirk-1"]], [["Edward II of England-1"]], ["operation"]], [[["Battle of Falkirk-1"]], [["Edward II of England-14"]], ["operation"]]]}
{"qid": "363cf9e4f1ab45e05a4b", "term": "Cream", "description": "Dairy product", "question": "If you bottle your own milk, would there be cream on top of it?", "answer": true, "facts": ["Milk that has been bottled straight from a cow has not been homogenized. ", "Homogenization causes the fats in milk to become emulsified.", "Non-homogenized milk will feature fats that separate and float to the top.", "The fats in non-homogenized milk are cream."], "decomposition": ["When milk is taken directly from a cow, what appearance and position do the fats assume?", "Is #1 cream and at the top?"], "evidence": [[[["Cream-1"]], ["operation"]], [[["Milk-59"]], ["operation"]], [[["Milk-53", "Milk-59"]], [["Milk-59"]]]]}
{"qid": "18677e493ffd5cd35fa9", "term": "Kanji", "description": "adopted logographic Chinese characters used in the modern Japanese writing system", "question": "Can a person who knows only English read Kanji?", "answer": false, "facts": ["Kanji is a Japanese language.", "People who only know English can't read Japanese."], "decomposition": ["Is knowledge of Kanji included in English language?"], "evidence": [[[["Kanji-1"]]], [[["Kanji-1"]]], [[["Kanji-1"]]]]}
{"qid": "ff0c2df8c385ec5189dc", "term": "Sloth", "description": "tree dwelling animal noted for slowness", "question": "Could a sloth hypothetically watch an entire episode of Scrubs underwater?", "answer": true, "facts": ["Sloths can hold their breath underwater for up to 40 minutes.", "The running time of a Scrubs episode is between 20-23 minutes."], "decomposition": ["How long can sloths hold their breath underwater?", "How long is an episode of Scrubs?", "Is #1 greater than or equal to #2?"], "evidence": [[[["Sloth-20"]], [["Scrubs (TV series)-69"]], ["operation"]], [[["Sloth-20"]], ["no_evidence"], ["no_evidence"]], [[["Sloth-20"]], ["no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "b9e623a3ea2aa739facf", "term": "Chlorine", "description": "Chemical element with atomic number 17", "question": "Is it dangerous to consume chlorine when mixed with sodium?", "answer": false, "facts": ["Chlorine mixed with sodium is sodium chloride, also known as table salt.", "Table salt is one of the most commonly consumed seasonings among all cultures."], "decomposition": ["What do you make when you mix Chlorine with sodium?", "What is another name for #1?", "Is #2 dangerous to consume?"], "evidence": [[[["Sodium chloride-13"]], [["Sodium chloride-12"]], [["Salt-5"]]], [[["Sodium chloride-22"]], [["Sodium chloride-22"]], ["operation"]], [[["Sodium chloride-1"]], [["Salt-1"]], [["Salt-2", "Salt-5"]]]]}
{"qid": "668c900cd1405a15d60b", "term": "Guitarist", "description": "person who plays the guitar", "question": "Does being good at guitar hero make you a good guitarist?", "answer": false, "facts": ["Guitar Hero is a game that features a guitar-shaped controller with buttons that the player must hit in time with a song.", "Guitars as instruments do not have any buttons, but have strings that must be strummed in a particular way to create sound."], "decomposition": ["How is a guitar played?", "How is Guitar Hero played?", "Do the steps in #1 match those of #2?"], "evidence": [[[["Guitar-1"]], [["Guitar Hero-44"]], ["operation"]], [[["Guitar-1"]], [["Guitar controller-1"]], ["operation"]], [[["Guitar-1"]], [["Guitar Hero-1"]], ["operation"]]]}
{"qid": "4f286910705ee9e8aceb", "term": "Hypothermia", "description": "A human body core temperature below 35.0°C", "question": "Would hypothermia be a concern for a human wearing zoot suit on Triton?", "answer": true, "facts": ["A zoot suit was a man's suit of an exaggerated style popular in the 1940s.", "Triton is one of the coldest planets in the solar system.", "Triton is located about 2.8 billion miles from the warmth of the sun.", "Triton has an average temperature of -235.0°C", "A zoot suit is made of thin material such as cloth."], "decomposition": ["What is the average temperature on Triton?", "What material are zoot suits made of?", "Below which body temperature will hypothermia set in?", "Would clothes made of #2 be unable to keep body temperature above #3 in ambient temperature of #1?"], "evidence": [[[["Triton (moon)-3"]], [["Zoot Suit Riots-2"]], [["Hypothermia-1"]], ["operation"]], [[["Triton (moon)-3"]], [["Zoot Suit Riots-12", "Zoot Suit Riots-2"]], [["Human body temperature-30"]], ["operation"]], [[["Triton (moon)-3"]], [["Zoot suit-15"], "no_evidence"], [["Hypothermia-1"]], ["operation"]]]}
{"qid": "d57b4438cf31f3ca05fe", "term": "Roman numerals", "description": "Numbers in the Roman numeral system", "question": "Is MIX a word and a roman numeral?", "answer": true, "facts": ["\"Mix\" means to combine in english.", "M equals one thousand in roman numerals", "I equals one in roman numerals ", "I before X in roman numerals equals nine.", "MIX equals one thousand nine in roman numerals. "], "decomposition": ["What does Mix mean in english language?", "Is Mix a number in Roman numerals?", "Based on #1 and #2, is mix both a word and a roman numeral?"], "evidence": [[[["Audio mixing (recorded music)-1"]], [["Roman numerals-5"]], [["Audio mixing (recorded music)-1", "Roman numerals-5"]]], [[["Mix (magazine)-1", "Mixing (process engineering)-38"], "no_evidence"], [["1009-1", "Roman numerals-1"]], ["operation"]], [[["DJ mix-1"]], [["Roman numerals-5"]], ["operation"]]]}
{"qid": "316ea9032a8d63df7c91", "term": "Sea otter", "description": "A species of marine mammal from the northern and eastern coasts of the North Pacific Ocean", "question": "Does a sea otter eat spiders?", "answer": false, "facts": ["Sea otters prey mostly on marine invertebrates and other aquatic creatures.", "Spiders are not aquatic creatures and they reside on land."], "decomposition": ["What are sea otters known to feed on?", "Are spiders included in #1?"], "evidence": [[[["Sea otter-49"]], ["operation"]], [[["Sea otter-2"]], ["operation"]], [[["Sea otter-2"]], ["operation"]]]}
{"qid": "0a84eaea4d26d46c7c30", "term": "Rainbow", "description": "meteorological phenomenon", "question": "Are flag of Gabon colors found in rainbow?", "answer": true, "facts": ["Rainbows contain the following colors:  red, orange, yellow, green, blue, indigo and violet.", "The flag of Gabon is green, yellow, and blue."], "decomposition": ["What colors are found in a rainbow?", "What colors are in the flag of the country Gabon?", "Are all the colors in #2 found in #1?"], "evidence": [[[["ROYGBIV-1"]], [["Flag of Gabon-3"]], ["operation"]], [[["ROYGBIV-1"]], [["Flag of Gabon-5"]], ["operation"]], [[["ROYGBIV-1"]], [["Flag of Gabon-1"]], ["operation"]]]}
{"qid": "fe5428059eda37cc96c2", "term": "Mount Sharp", "description": "mountain on Mars", "question": "Are human footprints absent from Mount Sharp?", "answer": true, "facts": ["Mount Sharp is located on Mars.", "Human beings have not traveled to Mars.", "Human footprints could only be present if human feet touched down on Mount Sharp."], "decomposition": ["Where is Mount Sharp?", "What would produce a human footprint?", "Have #2 never traveled to #1?"], "evidence": [[[["Mount Sharp-1"]], [["Footprint-1"]], ["operation"]], [[["Mount Sharp-1"]], [["Footprint-1"]], [["Human mission to Mars-73"], "operation"]], [[["Mount Sharp-1"]], [["Footprint-1"]], [["Human mission to Mars-2"]]]]}
{"qid": "3871d7a05a729494ecd9", "term": "Guitarist", "description": "person who plays the guitar", "question": "Do guitarist's have fingers that can handle pain better than average?", "answer": true, "facts": ["Guitarists typically have calloused fingertips. ", "Callouses are formed of layers of dead skin and usually lack sensation."], "decomposition": ["What typically forms on a Guitarists' finger?", "Does #1 usually cause a lack of sensation?"], "evidence": [[[["Callus-3"]], [["Callus-12"], "no_evidence", "operation"]], [[["Callus-3"]], ["no_evidence", "operation"]], [[["Callus-3"]], [["Callus-13", "Callus-6"]]]]}
{"qid": "b72204fd58a0bfaa5283", "term": "Gulf of Mexico", "description": "An Atlantic Ocean basin extending into southern North America", "question": "Is a Halloween cruise in the Gulf of Mexico likely to be safe from storms?", "answer": false, "facts": ["Hurricanes often strike the Gulf of Mexico", "Hurricane season in the gulf lasts until the end of November", "Halloween is October 31"], "decomposition": ["Which storms are a common occurrence in the Gulf of Mexico?", "What time of the year is Halloween celebrated?", "According to known patterns, are any of #1 likely to happen during #2?"], "evidence": [[[["Atlantic hurricane-35"]], [["Halloween-1"]], [["Tropical cyclone-46"], "operation"]], [[["Gulf of Mexico-26"]], [["Halloween-1"]], [["Atlantic hurricane season-2"], "operation"]], [[["Tropical cyclone-46", "Tropical cyclone-60", "Tropical cyclone-86"]], [["All Hallows' Eve (disambiguation)-1"]], ["operation"]]]}
{"qid": "c7b343171ca9bce49241", "term": "Sainsbury's", "description": "chain of supermarkets in the United Kingdom", "question": "Could Sainsbury's buy Tesco?", "answer": false, "facts": ["Sainsbury is a business worth £29.007 billion in 2019.", "Tesco is a business worth £63.911 billion in 2019.", "63 billion is more than 29 billion.", "A business needs to have enough revenue to buy another business."], "decomposition": ["What is the total value of Sainsbury's?", "What is the total value of Tesco?", "Is #1 greater than #2?"], "evidence": [[[["Sainsbury's-3"], "no_evidence"], [["Tesco-5"], "no_evidence"], ["operation"]], [[["Sainsbury's-1", "Sainsbury's-56"], "no_evidence"], [["Tesco-5"]], ["operation"]], [[["Sainsbury's-1"], "no_evidence"], [["Tesco-5"], "no_evidence"], ["operation"]]]}
{"qid": "2c774c2108bfaef1032c", "term": "Internet slang", "description": "Slang languages used by different people on the Internet", "question": "Did Alfred Hitchcock include internet slang in his films?", "answer": false, "facts": ["Alfred Hitchcock died in 1908.", "The internet began developing slang in the 1990's."], "decomposition": ["What year did Alfred Hitchcock die?", "When did internet become available for people?", "Is #1 after #2?"], "evidence": [[[["Alfred Hitchcock-1"]], [["History of the World Wide Web-11"]], ["operation"]], [[["Alfred Hitchcock-1"]], [["World Wide Web-2"]], ["operation"]], [[["Alfred Hitchcock-70"]], [["Internet-10"]], ["operation"]]]}
{"qid": "b6c4ef03511c60d02183", "term": "Holy Grail", "description": "Cup, dish or stone with miraculous powers, important motif in Arthurian literature", "question": "Has the Holy Grail been featured in at least five films?", "answer": true, "facts": ["1981's Excalibur film features King Arthur and his knights looking for the Holy Grail.", "Monty Python and the Holy Grail spoofs Arthurian legend.", "Indiana Jones and the Last Crusade features a search for the Holy Grail.", "Prince Killian and the Holy Grail focuses on retrieval of the grail.", "The Silver Chalice focuses on a man that has to sculpt the Holy Grail."], "decomposition": ["What movies have featured the Holy Grail?", "Are at least 5 movies listed in #1?"], "evidence": [[[["Indiana Jones and the Last Crusade-1", "Lancelot du Lac (film)-3", "Monty Python and the Holy Grail-2", "The Fisher King-4", "The Light in the Dark-4"]], ["operation"]], [[["Holy Grail-32"]], [["Holy Grail-32"], "operation"]], [[["Holy Grail-32"]], ["operation"]]]}
{"qid": "a60e5f73700b47a5f34a", "term": "Boat", "description": "vessel for transport by water", "question": "Does rock star Keith Richards play a captain of a boat in a movie?", "answer": true, "facts": ["Keith Richards has a cameo appearance in two of the Pirates of the Caribbean movies.", "He plays Captain Teague, the elderly father of famous pirate Captain Jack Sparrow.", "In At World's End, he is the member of the council of Pirate Lords who is responsible for keeping the Pirate Code, and there is a brief shot of him and his crew aboard their ship during the sequence where the pirates are raising their banners in preparation to fight."], "decomposition": ["What role did Keith Richards play in the Pirates of the Caribbean movies?", "Can #1 be considered a captain of a boat?"], "evidence": [[[["Keith Richards-47"]], [["Captain-1"], "operation"]], [[["Keith Richards-47"]], [["Captain-1"]]], [[["Keith Richards-47"]], ["operation"]]]}
{"qid": "1dce60cffcb066e212b8", "term": "Anchovy", "description": "Family of fishes", "question": "Would a pescatarian be unable to eat anchovy pizza?", "answer": false, "facts": ["Pescatarians do not eat red meat or chicken but do eat fish.", "Pescatarians have no restrictions with eating cheese."], "decomposition": ["What do pediatricians eat for source of meat?", "Is anchovy not included in #1?"], "evidence": [[[["Pescetarianism-1"]], [["Anchovy-1"]]], [[["Pescetarianism-1"]], [["Anchovy-1", "Seafood-1"]]], [[["Pescetarianism-1"]], [["Anchovy-3"]]]]}
{"qid": "673be9f6d35f74ae8e91", "term": "Vitamin C", "description": "nutrient found in citrus fruits and other foods", "question": "Did pirates who had scurvy need more Vitamin C?", "answer": true, "facts": ["Pirates were known for having poor teeth and deteriorated gums.", "Gum deterioration and tooth decay is a symptom of scurvy.", "Scurvy is caused by a lack of dietary vitamin C."], "decomposition": ["What causes scurvy?", "Is #1 the same as insufficient vitamin C intake?"], "evidence": [[[["Scurvy-1"]], ["operation"]], [[["Scurvy-1"]], ["operation"]], [[["Scurvy-1"]], ["operation"]]]}
{"qid": "947a089ce6992869815a", "term": "Swallow", "description": "family of birds", "question": "Did the swallow play a role in a famous film about King Arthur?", "answer": true, "facts": ["Monty Python and the Holy Grail was a famous film about King Arthur", "In Monty Python and the Holy Grail, swallows are mentioned several times"], "decomposition": ["What Monty Python film is about King Arthur?", "Are swallows mentioned several times in #1?"], "evidence": [[[["Monty Python and the Holy Grail-1"]], ["no_evidence", "operation"]], [[["Monty Python and the Holy Grail-1"]], [["Monty Python and the Holy Grail-4"]]], [[["Monty Python and the Holy Grail-2", "Monty Python and the Holy Grail-4", "Monty Python and the Holy Grail-9"]], ["operation"]]]}
{"qid": "80b3ba19b90c340ea5cc", "term": "Surveillance", "description": "monitoring of behavior, activities, or other changing information", "question": "Is video surveillance of a room possible without an obvious camera or new item?", "answer": true, "facts": ["Surveillance cameras can be built into light socket covers that look no different from a normal one.", "Surveillance cameras can be installed in special light bulbs to document activity in a room."], "decomposition": ["What are the various types of surveillance cameras based on installation?", "Are some of installed so as to be #1 hidden from view?"], "evidence": [[[["Closed-circuit television-2", "Closed-circuit television-3", "Closed-circuit television-4"]], [["Hidden camera-2"]]], [[["Hidden camera-1"], "no_evidence"], ["operation"]], [[["Hidden camera-1"]], [["Hidden camera-2"]]]]}
{"qid": "9642838ebb5c1c382ade", "term": "Holy Saturday", "description": "Saturday before Easter Sunday", "question": "Did Holy Saturday 2019 have special significance to pot smokers?", "answer": true, "facts": ["Holy Saturday 2019 took place on April 20th.", "April 20th, known as 4/20 day, National Pot Smokers Day, Weed Day or National Weed Day, is a holiday for pot smokers."], "decomposition": ["What date was Holy Saturday in 2019?", "What date is an unofficial holiday for pop smokers?", "Is #1 the same as #2?"], "evidence": [[[["Holy Saturday-3"], "no_evidence"], [["420 (cannabis culture)-1"]], ["operation"]], [["no_evidence"], [["420 (cannabis culture)-1"]], ["no_evidence", "operation"]], [[["2019 Australian federal election-38"], "no_evidence"], [["420 (cannabis culture)-15"]], ["operation"]]]}
{"qid": "ad3fef8d0670d91eff56", "term": "Railroad engineer", "description": "person who operates a train on a railroad or railway", "question": "Is a railroad engineer needed during NASCAR events?", "answer": false, "facts": ["Railroad engineers work on trains and railway systems", "NASCAR events feature automobile races"], "decomposition": ["On what kind of transportation do railroad engineers work?", "NASCAR involves what kind of transportation?", "Is #1 and #2 the same?"], "evidence": [[[["Edward Banfield (railroad engineer)-1"]], [["Safety car-34"]], ["operation"]], [[["Train driver-1"]], [["NASCAR-1"]], ["operation"]], [[["Train driver-1"]], [["NASCAR-1"]], ["operation"]]]}
{"qid": "a202af46315d9970d768", "term": "University of Pittsburgh", "description": "American state-related research university located in Pittsburgh, Pennsylvania", "question": "Did University of Pittsburgh founder have great deal in common with Judith Sheindlin?", "answer": true, "facts": ["Hugh Henry Brackenridge founded University of Pittsburgh in 1787.", "Judith Sheindlin is a judge, lawyer, and author.", "Hugh Henry Brackenridge was a writer, lawyer, judge, and Justice of the Supreme Court of Pennsylvania."], "decomposition": ["Who was the founder of University of Pittsburgh?", "What are the major things #1 is known for?", "What are the major things Judith Sheindlin is known for?", "Is there an overlap between #2 and #3?"], "evidence": [[[["History of the University of Pittsburgh-2"]], [["Hugh Henry Brackenridge-4"]], [["Judy Sheindlin-1"]], [["Judge-5"], "operation"]], [[["University of Pittsburgh-1"]], [["Hugh Henry Brackenridge-1"]], [["Judy Sheindlin-1"]], ["operation"]], [[["History of the University of Pittsburgh-2"]], [["Hugh Henry Brackenridge-1"]], [["Judy Sheindlin-1"]], ["operation"]]]}
{"qid": "01e796e851a77dae22bc", "term": "Joker (character)", "description": "Fictional character in the DC Universe", "question": "Was the Joker an enemy of the Avengers?", "answer": false, "facts": ["The Joker is a DC Comics villain.", "The Avengers are a group of heroes from Marvel Comics.", "Being from different publishers, they do not meet."], "decomposition": ["Which world does the Joker exist in?", "The Avengers are from which universe?", "Is #1 the same as #2?"], "evidence": [[[["Joker (2019 film)-46"]], [["The Avengers (2012 film)-37"]], [["The Avengers (2012 film)-45"], "operation"]], [[["Joker (character)-1"]], [["Avengers (comics)-1"]], ["operation"]], [[["Joker (character)-1"]], [["Avengers (comics)-1"]], ["operation"]]]}
{"qid": "c027d949f7b4a6af5869", "term": "Jujutsu", "description": "Japanese martial art", "question": "Could a Jujutsu expert hypothetically defeat a Janissary?", "answer": false, "facts": ["Jujutsu is a form of unarmed combat.", "Janissaries were the elite infantry of the Ottoman Empire.", "Janissaries wore chain mail and armor and wielded sharp swords."], "decomposition": ["What equipment does Jujutsu use?", "What equipment does Janissary use?", "Would someone with #1 likely defeat someone with #2?"], "evidence": [[[["Jujutsu-1"]], [["Janissaries-25"]], ["no_evidence"]], [[["Jujutsu-1"]], [["Janissaries-1", "Janissaries-12"]], ["operation"]], [[["Jujutsu-1"]], [["Janissaries-25"]], ["operation"]]]}
{"qid": "7fc117f83a13b80e0e09", "term": "Hippopotamus", "description": "A large, mostly herbivorous, semiaquatic mammal native to sub-Saharan Africa", "question": "Can you only see hippopotamus in Africa?", "answer": false, "facts": ["The United States has several zoos featuring hippopotamus.", "In the UK, you can see hippopotamus at the Marwell Zoo."], "decomposition": ["Where are animals kept for recreation/sightseeing?", "Can #1 that has hippopotamus be found only inside Africa?"], "evidence": [[[["Zoo-1"]], [["Hippopotamus-44", "Toledo, Ohio-1"]]], [[["Hippopotamus-5"]], [["Hippopotamus-13"]]], [[["Zoo-1"]], [["Hippopotamus-43"], "operation"]]]}
{"qid": "0431a3fc727855c8ad83", "term": "Dalai Lama", "description": "Tibetan Buddhist spiritual teacher", "question": "Can the Dalai Lama fit in a car?", "answer": true, "facts": ["The Dalai Lama is a person.", "Cars are designed for people to sit in them."], "decomposition": ["What type of being is the Dalai Lama?", "Who are cars designed for?", "Is #1 the same as #2?"], "evidence": [[[["Dalai Lama-1"]], [["Car controls-23"]], ["operation"]], [[["Dalai Lama-1"]], [["Car-42"]], ["operation"]], [[["Dalai Lama-1", "Person-1"]], [["Car-1"]], ["operation"]]]}
{"qid": "a2dfceff60d5b18fc70d", "term": "Salsa (sauce)", "description": "Sauce", "question": "Would Carolina Reaper decrease sales if added to all US salsa?", "answer": true, "facts": ["On average, Americans prefer milder salsa than Europeans.", "The Carolina Reaper is the hottest pepper in the world. ", "The Carolina Reaper is rated as 2,200,000 Scoville Heat Units."], "decomposition": ["On average, what level of spice do Americans prefer for their salsa?", "Compared to other peppers, how hot is the Carolina Reaper?", "Would adding #2 to salsa create a salsa that is #1?"], "evidence": [[[["Salsa (sauce)-2"]], [["Carolina Reaper-2"]], ["operation"]], [["no_evidence"], [["Carolina Reaper-1"]], ["no_evidence", "operation"]], [[["Salsa (sauce)-2"], "no_evidence"], [["Carolina Reaper-2"]], [["Salsa (sauce)-6"], "no_evidence"]]]}
{"qid": "8079e0f884664d724347", "term": "Hornet", "description": "Genus of eusocial wasp", "question": "Do hornets provide meaningful data for oceanographers?", "answer": false, "facts": ["Hornets live on land", "Oceanographers study oceans"], "decomposition": ["Where do hornets live?", "What do oceanographers study?", "Is #1 the same as #2?"], "evidence": [[[["Hornet-2", "Hornet-8"]], [["Oceanography-1"]], ["operation"]], [[["Hornet-2"]], [["Oceanography-1"]], ["operation"]], [[["Hornet-2"]], [["Oceanography-1"]], ["operation"]]]}
{"qid": "8cc7153ec5a527748adc", "term": "Firewall (computing)", "description": "Software or hardware-based network security system", "question": "Can a firewall protect against a short circuit?", "answer": false, "facts": ["A firewall is a computer program that protects unwanted attacks from penetrating a computer.", "Firewalls are installed on computers and conduct routine background maintenance.", "A short circuit is an electrical failure resulting from wires unable to conduct currents.", "Short circuits, especially during updates can lead to the dreaded Windows Blue Screen of Death in which a computer is unable to restart."], "decomposition": ["What kind of threats does a firewall protect a computer system against?", "What are the possible causes and results of a short circuit as concerning computers?", "Is any of #2 included in #1?"], "evidence": [[[["Firewall (computing)-13"]], [["Short circuit-7", "Short circuit-9"]], ["operation"]], [[["Windows Firewall-2"]], [["Short circuit-7"]], [["Short circuit-7"], "operation"]], [[["Firewall (computing)-1"]], [["Short circuit-1", "Short circuit-10", "Short circuit-7"]], ["operation"]]]}
{"qid": "b200ff0fb5d8380edb14", "term": "Europa (moon)", "description": "The smallest of the four Galilean moons of Jupiter", "question": "Could the surface of Europa fry an egg?", "answer": false, "facts": ["Europa is known for having an icy surface.", "For an egg to become firm, the ground must be at least 158 degrees Fahrenheit. ", "Ice forms at 32 degrees Fahrenheit.", "Europa's temperatures are all in the negatives on the Fahrenheit scale."], "decomposition": ["At what temperature will an egg become fried?", "What is the temperature on the surface of Europa?", "Is #2 greater than or equal to #1?"], "evidence": [[[["Egg as food-28"]], [["Europa (moon)-22"]], ["operation"]], [[["Frying-3"], "no_evidence"], [["Europa (moon)-22"]], ["operation"]], [[["Boiled egg-4"], "no_evidence"], [["Europa (moon)-22"]], ["operation"]]]}
{"qid": "e3481f169664aa561368", "term": "Louvre", "description": "Art museum and Historic site in Paris, France", "question": "Is the Louvre in billionaire George Soros's price range?", "answer": false, "facts": ["The Louvre including all of its paintings has a value of around 45 billion.", "George Soros has a net worth around 8 billion as of 2020."], "decomposition": ["What is the estimated value of the Louvre?", "What is George Soros' estimated 2020 net worth?", "Is #2 greater than or equal to #1?"], "evidence": [[[["Louvre-1"], "no_evidence"], [["George Soros-1"]], ["no_evidence", "operation"]], [[["Louvre-16"], "no_evidence"], [["George Soros-1"]], ["operation"]], [["no_evidence"], [["George Soros-113"], "no_evidence"], ["no_evidence"]]]}
{"qid": "0013d38e0568f48acdc0", "term": "Voyager 2", "description": "Space probe and the second-farthest man-made object from Earth", "question": "Could a Hwasong-15 missile hypothetically reach Voyager 2?", "answer": false, "facts": ["Voyager 2 was a probe that traveled to the interstellar medium of space.", "The interstellar medium is over 12,161,300,000 miles away from earth.", "The Hwasong-15 missile is a North Korean missile with a range of 8,000 miles."], "decomposition": ["How far away from Earth has Voyager 2 traveled?", "What is the range of a Hwasong-15 missile?", "Is #2 greater or equal to #1?"], "evidence": [[[["Voyager 2-3"]], [["Hwasong-15-3"]], ["operation"]], [[["Voyager 2-3"]], [["Hwasong-15-1"]], ["operation"]], [[["Voyager 2-3"]], [["Hwasong-15-3"]], ["operation"]]]}
{"qid": "3756f2a4b805deba01b6", "term": "Breakdancing", "description": "Style of street dance", "question": "Is breakdancing safe for people with tendonitis?", "answer": false, "facts": ["Tendonitis is a condition where the joints are inflamed.", "Strong motions in joints suffering from tendonitis can result in damage to nerves.", "Breakdancing is a style of dance that involves many vigorous motions.", "The downrock breakdancing maneuver involves balancing the body weight on the floor using one arm."], "decomposition": ["What are the symptoms of tendonitis?", "Which kind of movements are involved in breakdancing?", "Are #2 safe when experiencing #1?"], "evidence": [[[["Tendinopathy-1"], "no_evidence"], [["Breakdancing-27"], "no_evidence"], ["no_evidence", "operation"]], [[["Tendinopathy-1"]], [["Breakdancing-1", "Power move-3"], "no_evidence"], ["operation"]], [[["Tendinopathy-4"]], [["Breakdancing-27"]], [["Tendinopathy-5"], "operation"]]]}
{"qid": "1b29d402c3e17cb3b435", "term": "Pound sterling", "description": "Official currency of the United Kingdom and other territories", "question": "Is a pound sterling valuable?", "answer": false, "facts": ["A pound sterling is fiat money.", "Fiat money is backed by government decree and has no intrinsic value.", "One pound sterling is worth about 1.24 US dollars by May of 2020."], "decomposition": ["What is the value of the Pound Sterling based on?", "Is #1 the material used in making it?"], "evidence": [[[["Pound sterling-16"]], [["Pound sterling-16"]]], [[["Pound sterling-1", "Pound sterling-12"]], [["Pound sterling-71"]]], [[["Pound sterling-16"]], [["One pound (British coin)-3"], "operation"]]]}
{"qid": "5f89881767cac98c56d6", "term": "Seven Years' War", "description": "Global conflict between 1756 and 1763", "question": "Could the Austrian casualties from Seven Years' War fit in Indianapolis Motor Speedway?", "answer": true, "facts": ["There were 373,588 Austrian casualties during the Seven Years' War.", "The infield seating at the Indianapolis Motor Speedway raises capacity to an approximate 400,000 people."], "decomposition": ["How many casualties did the Austrian's have in the Seven Year War?", "What is the seating capacity for the Indianapolis Motor Speedway?", "Is #1 less than #2?"], "evidence": [[[["Battle of Prague (1757)-1"], "no_evidence"], [["Indianapolis Motor Speedway-3"]], ["operation"]], [["no_evidence"], [["Indianapolis Motor Speedway-3"]], ["operation"]], [[["Seven Years' War-36"], "no_evidence"], [["Indianapolis Motor Speedway-3"]], ["no_evidence", "operation"]]]}
{"qid": "268b7bf55b10eeab7a7e", "term": "USB", "description": "Industry standard", "question": "Is 500GB USB device enough to save 10 hours of Netflix shows a day?", "answer": false, "facts": ["5 hours of Netflix programming uses up approximately 1 TB of data.", "1 TB is equal to 1000 GB of data."], "decomposition": ["How many terabytes of data does 5 hours of Netflix use up?", "What is #1 multiplied by 2?", "How many GB are in a TB?", "What is #3 multiplied by #2?", "Is #4 less than 500?"], "evidence": [[["no_evidence"], ["no_evidence", "operation"], [["Terabyte-2"]], ["no_evidence", "operation"], ["no_evidence", "operation"]], [[["TiVo-46"], "no_evidence"], ["operation"], [["Terabyte-2"]], ["operation"], ["operation"]], [[["Streaming media-39"], "no_evidence", "operation"], ["no_evidence", "operation"], ["no_evidence", "operation"], ["no_evidence", "operation"], ["no_evidence", "operation"]]]}
{"qid": "97f9a0a30c9dc2e77d42", "term": "5", "description": "Natural number", "question": "Does Homer Simpson need two hands worth of fingers to count to 5?", "answer": true, "facts": ["Homer Simpson is a character of the long running comedy animated series \"The Simpsons\".", "All characters in \"The Simpsons\" have 4 fingers on each hand."], "decomposition": ["How many fingers does Homer Simpson have on each hand?", "Is #1 less than 5?"], "evidence": [[[["Trilogy of Error-1"], "no_evidence"], ["operation"]], [["no_evidence"], ["no_evidence", "operation"]], [[["Homer Simpson-1"], "no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "a2dd0493fc87bb64e1fa", "term": "Hundred Years' War", "description": "Series of conflicts and wars between England and France during the 14th and 15th-century", "question": "Did the first Duke of Valentinois play a key role in the Hundred Years' War?", "answer": false, "facts": ["The Hundred Years' War was a conflict between England and France from 1337-1453", "Cesare Borgia, the son of Pope Alexander VI, was the first Duke of Valentinois.", "Cesare Borgia was born in 1475."], "decomposition": ["When did the Hundred Years' War end?", "Who was the first Duke of Valentinois?", "When was #2 born?", "Is #3 before #1?"], "evidence": [[[["Hundred Years' War (1415–1453)-1"]], [["Duke of Valentinois-6"]], [["Honoré II, Prince of Monaco-1"]], ["operation"]], [[["Hundred Years' War-1"]], [["Cesare Borgia-7"]], [["Cesare Borgia-1"]], ["operation"]], [[["Hundred Years' War-1"]], [["Cesare Borgia-7"]], [["Cesare Borgia-1"]], ["operation"]]]}
{"qid": "5a20b692ab755caf4ae9", "term": "Paratrooper", "description": "Military parachutists functioning as part of an airborne force", "question": "Are paratroopers good at mountain rescue?", "answer": true, "facts": ["A paratrooper is a member of a military unit that deploys parachutes. ", "A PJ is the acronym name for a military parachute jumper.", "PJs are an elite mountain rescue unit. "], "decomposition": ["What military unit do paratroopers belong to?", "Do #1 use equipment that makes them suitable for mountain rescue?"], "evidence": [[[["Paratrooper-1"]], [["Paratrooper-2"], "no_evidence"]], [[["Paratrooper-1"]], ["no_evidence", "operation"]], [[["Paratrooper-74"]], [["Paratrooper-1"], "no_evidence"]]]}
{"qid": "6b7feff09dde2f64fdd5", "term": "Ronda Rousey", "description": "American professional wrestler, actress, author, mixed martial artist and judoka", "question": "Will Ronda Rousey hypothetically defeat X-Men's Colossus in a fight?", "answer": false, "facts": ["Ronda Rousey is a mixed martial artist and wrestler.", "Ronda Rousey relies on striking moves and submission tactics to dominate her opponents.", "X-Men's Colossus has the ability to change his appearance.", "Colossus's mutation allows him to create an organic steel layer, that acts as an impenetrable external shell."], "decomposition": ["What type of profession is Ronda Rousey in?", "What moves do #1 use to beat their opponents?", "What special ability does X-men have?", "Can someone with #2 easily beat someone with #3?"], "evidence": [[[["Ronda Rousey-1"]], [["Ronda Rousey-43"]], [["X-Men-2"]], ["no_evidence"]], [[["Ronda Rousey-1"]], [["Professional wrestling-1"]], [["Colossus (comics)-55"]], ["operation"]], [[["Ronda Rousey-1"]], [["Grappling position-5"], "no_evidence"], [["Colossus (comics)-2"]], ["operation"]]]}
{"qid": "5c969a7fccde48210ec8", "term": "Dolce & Gabbana", "description": "Italian fashion house", "question": "Would a Dolce & Gabbana suit wearer be shunned by their Amish cousins?", "answer": true, "facts": ["Dolce & Gabbana is an Italian luxury fashion design company.", "The Amish, who value plain clothes, frown upon buttons and have banned velcro and zippers", "The Two Tone Dolce & Gabbana suit has several buttons.", "The Amish cease interactions with sinners by avoiding, or shunning them."], "decomposition": ["What type of clothing do the Amish prefer?", "What happens if an Amish person wears clothes going against #1?", "What clothing pieces are Dolce & Gabbana known for?", "If Amish cousins wore #3, would #2 happen to them?"], "evidence": [[[["Amish-27"]], [["Excommunication-39"]], [["Dolce & Gabbana-1"]], ["operation"]], [[["Plain dress-3"]], [["Amish-6"]], [["Dolce & Gabbana-1"]], ["operation"]], [[["Amish-1"]], [["Amish-6"]], [["Dolce & Gabbana-1", "Dolce & Gabbana-32"]], [["Amish-6"], "operation"]]]}
{"qid": "fc3a305f513090432212", "term": "Rash", "description": "skin condition", "question": "Is CAS number 8009-03-8 harmful for a rash?", "answer": false, "facts": ["Some common substances that help rashes are creams, oils, and petroleum based products.", "CAS number 8009-03-8 is the identifier number for petroleum jelly."], "decomposition": ["What is CAS number 8009-03-8 the identifier number for?", "Is #1 harmful to put on a rash?"], "evidence": [[[["Petroleum jelly-1"]], [["Petroleum jelly-2"]]], [[["Petroleum jelly-1"]], [["Petroleum jelly-2"], "operation"]], [[["Petroleum jelly-1"]], [["Petroleum jelly-2"]]]]}
{"qid": "08a7de56c14143be3535", "term": "Quran", "description": "The central religious text of Islam", "question": "Would an adherent of Zoroastrianism consult the Quran for religious guidance?", "answer": false, "facts": ["The Quran is the central religious text of Islam", "Zoroastrianism is an ancient religion predating Islam by several centuries"], "decomposition": ["Which religious group mainly uses the Quran for their consultation?", "Is Zoroastrianism closely related to #1?"], "evidence": [[[["Quran-1"]], [["Zoroastrianism-1"], "operation"]], [[["Quran-20"]], [["Zoroastrianism-48"], "operation"]], [[["Quran-1"]], [["Zoroastrianism-1"]]]]}
{"qid": "e12a00a2c45fcb4f38e7", "term": "Othello", "description": "play by Shakespeare", "question": "Would Othello be Shakespeare's play to buy Scheherazade most time with king?", "answer": false, "facts": ["Scheherazade was a character in Middle Eastern folklore that delayed her execution by telling the king long stories.", "Shakespeare's play Othello contained 26,450 words.", "Hamlet is Shakespeare's longest play consisting of 4000 lines and 30,000 words."], "decomposition": ["How long is Othello?", "Are all of Shakespeare's other plays shorter than #1?"], "evidence": [[[["Othello-41"], "no_evidence"], [["Shakespeare's plays-1"], "no_evidence", "operation"]], [[["Othello-20"], "no_evidence"], [["Hamlet-2", "The Comedy of Errors-1"], "no_evidence", "operation"]], [[["Othello-1"], "no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "810d006c5cb0e27081c8", "term": "Goldstone Deep Space Communications Complex", "description": "United States historic place", "question": "Do the telescopes at Goldstone Deep Space Communications Complex work the night shift?", "answer": true, "facts": ["The night shift is considered to be the hours of 11pm - 7am.", "The telescopes at Goldstone Deep Space Communications Complex are running 24 hours a day."], "decomposition": ["What hours are typically considered the night shift?", "What hours do the telescopes at Goldstone Deep Space Communications Complex run?", "Is there any overlap between #1 and #2?"], "evidence": [[[["Shift work-11"]], [["Goldstone Deep Space Communications Complex-2"], "no_evidence"], ["no_evidence", "operation"]], [[["Shift work-11"], "no_evidence"], ["no_evidence"], ["operation"]], [["no_evidence"], [["Astronomy-2", "Goldstone Deep Space Communications Complex-1"], "no_evidence"], ["no_evidence"]]]}
{"qid": "3996ee99b488820ea4fe", "term": "Eighth Amendment to the United States Constitution", "description": "prohibits cruel and unusual punishment and excessive bail", "question": "Does the Eighth Amendment to the United States Constitution protect freedom of speech?", "answer": false, "facts": ["The Eighth Amendment (Amendment VIII) of the United States Constitution prohibits the federal government from imposing excessive bail, excessive fines, or cruel and unusual punishments.", "The First Amendment (Amendment I) to the United States Constitution protects freedom of speech."], "decomposition": ["What changes were made by the Eighth Amendment to the United States Constitution?", "Is the protection of freedom of speech among #1?"], "evidence": [[[["Eighth Amendment to the United States Constitution-1"]], ["operation"]], [[["Eighth Amendment to the United States Constitution-1"]], ["operation"]], [[["Eighth Amendment to the United States Constitution-5"]], ["operation"]]]}
{"qid": "230f706be3c42e680d12", "term": "Autumn", "description": "one of the Earth's four temperate seasons, occurring between summer and winter", "question": "Does American Independence Day occur during autumn?", "answer": false, "facts": ["Autumn runs from about September 20 to about December 20.", "American Independence Day is July 4, over two months before autumn begins."], "decomposition": ["When does autumn occur in North America?", "When is American Independence Day celebrated?", "Is #2 within the range of #1?"], "evidence": [[[["Autumn-1"], "no_evidence"], [["Independence Day (United States)-3"], "no_evidence"], ["operation"]], [[["Autumn-3"]], [["Independence Day (United States)-1"]], ["operation"]], [[["Autumn-1"]], [["Independence Day (United States)-1"]], ["operation"]]]}
{"qid": "dfdc7f7197f90ec78844", "term": "Pharmacology", "description": "Branch of biology concerning drugs", "question": "Did Julius Caesar read books on Pharmacology?", "answer": false, "facts": ["Pharmacology has its origins in the Middle Ages.", "The Middle Ages took place from 476 AD-1453 AD.", "Julius Caesar lived from 100 BC-44 BC."], "decomposition": ["When did Julius Caesar die?", "When did Pharmacology emerge as a field of study?", "Is #1 after or within #2?"], "evidence": [[[["Assassination of Julius Caesar-1"]], [["Pharmacology-7"]], ["operation"]], [[["Julius Caesar-1"]], [["Pharmacology-4"]], ["operation"]], [[["Julius Caesar-1"]], [["Pharmacology-7"]], ["operation"]]]}
{"qid": "7a90cbd4a6c6f4c78f31", "term": "Solo (music)", "description": "musical piece or part of musical piece performed by a single musician", "question": "Can the Department of Defense perform a solo?", "answer": false, "facts": ["A solo is the part of a musical piece performed by a single musician", "The Department of Defense is a US government agency composed of many individuals and unrelated to music"], "decomposition": ["How many are part of a solo performance? ", "What is the Department of Defense?", "How many people are part of #2?", "Is #1 the same as #3?"], "evidence": [[[["First solo flight-1"]], [["United States Department of Defense-1"]], [["United States Department of Defense-1"]], ["operation"]], [[["Solo (music)-1"]], [["United States Department of Defense-1"]], [["United States Department of Defense-1"]], ["operation"]], [[["Solo (music)-1"]], [["United States Department of Defense-2"]], [["United States Department of Defense-1"]], ["operation"]]]}
{"qid": "9d277acbb432c3ddab16", "term": "Morris County, New Jersey", "description": "County in New Jersey", "question": "Was Morris County named after a chief justice?", "answer": true, "facts": ["The Morris County was named after Colonel Lewis Morris.", "Colonel Lewis Morris was the chief justice of New York."], "decomposition": ["Who was Morris County, New Jersey named after?", "Did #1 serve as a chief justice?"], "evidence": [[[["Morris County, New Jersey-4"]], [["Lewis Morris (governor)-1"]]], [[["Morris County, New Jersey-4"]], [["Lewis Morris (governor)-1"]]], [[["Morris County, New Jersey-4"]], [["Lewis Morris (governor)-1"]]]]}
{"qid": "8fe1b7912f41e5653e88", "term": "Tonsure", "description": "hairstyle related to religious devotion", "question": "Would Christopher Hitchens be very unlikely to engage in tonsure?", "answer": true, "facts": ["Tonsure is the practice of cutting or shaving some or all of the hair on the scalp as a sign of religious devotion or humility.", "Christopher Hitchens was an anti-theist, and he regarded all religions as false, harmful, and authoritarian."], "decomposition": ["What were Christopher Hitchens' views on religion?", "What is the purpose of tonsure?", "Would a proponent of #1 have a negative opinion of #2?"], "evidence": [[[["Christopher Hitchens-2"]], [["Tonsure-1"]], ["operation"]], [[["Christopher Hitchens-2"]], [["Tonsure-1"]], ["operation"]], [[["Christopher Hitchens-32"]], [["Tonsure-5"]], [["Christopher Hitchens-33"]]]]}
{"qid": "18553c3fc528f6a38e5f", "term": "Kingdom of Hungary", "description": "former Central European monarchy (1000–1946)", "question": "Were Walkman's used in the Kingdom of Hungary?", "answer": false, "facts": ["The Kingdom of Hungary ended in 1946. ", "The Walkman was invented in 1979."], "decomposition": ["When did the Kingdom of Hungary come to an end?", "When was Walkman invented?", "Is #2 before #1?"], "evidence": [[[["Kingdom of Hungary-1"]], [["Walkman-1"]], ["operation"]], [[["Kingdom of Hungary-1"]], [["Walkman-5"]], ["operation"]], [[["Kingdom of Hungary-1"]], [["Walkman-2"]], ["operation"]]]}
{"qid": "3413c919d24c59eadde3", "term": "Potato", "description": "plant species producing the tuber used as a staple food", "question": "Can someone with celiac disease have potato vodka?", "answer": true, "facts": ["Celiac disease makes it unsafe for someone to eat gluten.", "Potato vodka is a gluten free product."], "decomposition": ["For people with celiac disease, what must they avoid?", "Does Potato Vodka contain #1?"], "evidence": [[[["Gluten-15"]], [["Grey Goose (vodka)-7"]]], [[["Coeliac disease-2"]], [["Vodka-24"], "no_evidence", "operation"]], [[["Coeliac disease-2"]], [["Potato-1"], "operation"]]]}
{"qid": "55a0154c4a5dd692c046", "term": "Mercedes-Benz", "description": "automobile brand of Daimler AG", "question": "Was Mercedes-Benz associated with the Nazis?", "answer": true, "facts": ["During the 1930s, Mercedes-Benz produced the 770 model.", "The 770 was popular with Nazis, and Adolf Hitler used them as his personal vehicle."], "decomposition": ["Which Mercedes-Benz model was made during the 1930s?", "Was #1 popular among the Nazis?"], "evidence": [[[["Mercedes-Benz-6"]], ["operation"]], [[["Mercedes-Benz 770-1"]], [["Mercedes-Benz 770-1"]]], [[["Mercedes-Benz 770-6"]], [["Mercedes-Benz-6"], "operation"]]]}
{"qid": "0c90fc4f1a55004ea832", "term": "Bull shark", "description": "Species of fish", "question": "Is the bull shark more bull than shark?", "answer": false, "facts": ["The bull shark is a fish species that lives in warm shallow waters along coasts and rivers.", "Bull sharks feed on bony fish and other smaller sharks.", "A bull is an adult male mammal that lives on land.", "Bulls feed on plants located on land."], "decomposition": ["What is the main diet of bulls and where do they find their food?", "What is the main diet of sharks and where do they find their food?", "What is the main diet of bull sharks and where do they find their food?", "Is #3 more similar to #1 than to #2?"], "evidence": [[[["Cattle feeding-1"], "no_evidence"], [["Fish jaw-31"], "no_evidence"], [["Bull shark-23"]], ["operation"]], [[["Cattle-43"]], [["Shark-59"]], [["Bull shark-21"]], ["operation"]], [[["Bull-1", "Cattle-19"]], [["Shark-59", "Shark-60", "Shark-62"]], [["Bull shark-21"]], ["operation"]]]}
{"qid": "363a55b705110a878be1", "term": "Goofy", "description": "Disney cartoon character", "question": "If Goofy were a pet, would he need heartworm prevention?", "answer": true, "facts": ["Goofy is an anthropomorphic dog character. ", "Dogs require regular heartworm prevention. "], "decomposition": ["What kind of animal is Goofy?", "Does a #1 require regular heartworm prevention?"], "evidence": [[[["Goofy-1"]], [["Dog-18"]]], [[["Goofy-1"]], [["Dog health-50"]]], [[["Goofy-1"]], ["operation"]]]}
{"qid": "b92b31f0e7124066eb48", "term": "Porch", "description": "a room or gallery at the front entrance of a building forming a low front", "question": "In Hey Arnold, did any characters stay on a porch all the time?", "answer": true, "facts": ["Hey Arnold was an animated children's series.", "Hey Arnold featured 'Stoop Kid', a character who never left the front stoop of his home.", "A stoop is the city equivalent of a porch."], "decomposition": ["Where is 'Stoop Kid' in Hey Arnold known to never leave?", "Is #1 in the series equivalent to a porch in real life?"], "evidence": [[[["Hey Arnold!-7"], "no_evidence"], [["Porch-1", "Stoop (architecture)-1"], "no_evidence", "operation"]], [["no_evidence"], [["Stoop (architecture)-2"]]], [[["Hey Arnold!-1"], "no_evidence"], [["Stoop (architecture)-2"]]]]}
{"qid": "4bb58d0456bfea654c0f", "term": "Compact disc", "description": "Optical disc for storage and playback of digital audio", "question": "Did John Lennon listen to Compact discs?", "answer": false, "facts": ["The Compact disc was released in 1982 by Philips and Sony.", "John Lennon was killed on December 8, 1980."], "decomposition": ["When were Compact Discs first available for use?", "When did John Lennon die?", "Is #1 before #2?"], "evidence": [[[["Compact disc-1"]], [["John Lennon-1"]], ["operation"]], [[["Compact disc-1"]], [["John Lennon-1"]], ["operation"]], [[["Compact disc-1"]], [["John Lennon-36"]], ["operation"]]]}
{"qid": "33f7f8c55b4acedb061a", "term": "Lolcat", "description": "image combining a photograph of a cat with text intended to contribute humour", "question": "Is purchasing food for a Lolcat unnecessary?", "answer": true, "facts": ["An image macro is a piece of digital media featuring a picture, or artwork, superimposed with some form of text.", "Food is any substance consumed to provide nutritional support for an organism.", "An organism is any individual entity that embodies the properties of life.", "Digital media does not embody the properties of life."], "decomposition": ["Which kind of entities require food?", "Is a lolcat excluded from #1?"], "evidence": [[[["Eating-1"]], [["Lolcat-2"]]], [[["Food-1", "Organism-1", "Organism-2"]], [["Image macro-1", "Lolcat-1", "Media (communication)-1"]]], [[["Food-1"]], [["Lolcat-2"], "operation"]]]}
{"qid": "f3e238989015dd72bfda", "term": "Queen Elizabeth The Queen Mother", "description": "Queen consort of King George VI, mother of Queen Elizabeth II", "question": "Did Queen Elizabeth The Queen Mother and her daughter share name with Tudor queen?", "answer": true, "facts": ["Queen Elizabeth the Queen Mother gave birth to Queen Elizabeth II in 1926.", "The Tudor dynasty had a number of Queens including: Mary I of England, Elizabeth I of England, and Margaret Tudor, Queen of Scots."], "decomposition": ["Which name did the Queen Mother and Queen Elizabeth have in common?", "What are the names of some queens from the Tudor dynasty?", "Is #1 included in any of #2?"], "evidence": [[[["Elizabeth II-1", "Queen Elizabeth The Queen Mother-1"]], [["House of Tudor-1"]], ["operation"]], [[["Queen Elizabeth The Queen Mother-1"]], [["Elizabeth I of England-1", "Mary I of England-1"]], ["operation"]], [[["Queen Elizabeth The Queen Mother-1"]], [["House of Tudor-1"]], ["operation"]]]}
{"qid": "6c6d1853b7e97e66ef46", "term": "Red hair", "description": "Hair color", "question": "If you have black hair and want red hair, do you need bleach?", "answer": true, "facts": ["You cannot dye hair to be lighter than the starting color.", "To make hair a color lighter than the starting color, you need to bleach the hair."], "decomposition": ["Why would someone need bleach when dying their hair?", "Is red hair #1 than black hair?"], "evidence": [[[["Hair coloring-11"]], [["Hair coloring-11"]]], [[["Bleach-22"], "no_evidence"], [["Red hair-2"], "operation"]], [[["Hair coloring-26"]], ["no_evidence", "operation"]]]}
{"qid": "39764cc9679c2e0e6435", "term": "2000", "description": "Year", "question": "Was there fear leading up to the year 2000?", "answer": true, "facts": ["Many computer programs were not designed with the year 2000 in mind.", "People were worried that computers would crash all over the world when the year 2000 arrived.", "Financial and electrical systems require computers to function.", "Without financial and electrical systems there could be global chaos."], "decomposition": ["What concerns did people have about computing systems as 2000 approached?", "Did #1 involve a widespread fear of malfunction?"], "evidence": [[[["Year 2000 problem-1"]], [["Year 2000 problem-23"], "operation"]], [[["Year 2000 problem-1"]], [["Year 2000 problem-15"], "operation"]], [[["Year 2000 problem-1"]], [["Year 2000 problem-23"]]]]}
{"qid": "71711173efbb350885b3", "term": "New Brunswick", "description": "province in Canada", "question": "Can Burundi's communicate with citizens of New Brunswick?", "answer": true, "facts": ["French and English are the official languages of New Brunswick.", "French is one of the official languages of Burundi."], "decomposition": ["What are the official languages of New Brunswick, Canada?", "What are the official languages of Burundi?", "Are some elements of #2 also in #1?"], "evidence": [[[["New Brunswick-36"]], [["Burundi-87"]], ["operation"]], [[["Official language-14"]], [["Burundi-6"]], ["operation"]], [[["Languages of Canada-58"], "operation"], [["Languages of Burundi-1"], "operation"], ["no_evidence"]]]}
{"qid": "b0ee9781a2840b582d9d", "term": "Nicole Kidman", "description": "Australian-American actress and film producer", "question": "Is Nicole Kidman ideal choice to play Psylocke based on height and weight?", "answer": true, "facts": ["Psylocke is a Marvel super hero whose real name is Betsy Braddock.", "Betsy Braddock is 5'11 and 155 lbs.", "Actress Nicole Kidman is 5'11 and weighs 137 lbs.", "Actresses gain weight all the time for roles, such as Charlize Theron who gained 30 pounds for the movie Monster."], "decomposition": ["What is Psylocke's height?", "What is Psylocke's wieght?", "Does Nicole Kidman have similar attributes as #1 and #2?"], "evidence": [[[["Psylocke-2"], "no_evidence"], ["no_evidence"], [["Nicole Kidman-1"], "no_evidence", "operation"]], [[["Psylocke-2"], "no_evidence"], [["Psylocke-2"], "no_evidence"], ["no_evidence", "operation"]], [[["Psylocke-4"], "no_evidence"], [["Psylocke-4"], "no_evidence"], [["Model (person)-19", "Model (person)-20", "Nicole Kidman-1"], "no_evidence", "operation"]]]}
{"qid": "64fbc620641915a4a6b4", "term": "Robotics", "description": "Design, construction, operation, and application of robots", "question": "Did the Wall Street Crash of 1929 hurt the stocks of robotics companies?", "answer": false, "facts": ["The first robotics company was formed in the 1950s", "The crash of 1929 was a single event, not one that lasted decades"], "decomposition": ["When did the first robotic company form?", "When did the crash of 1929 last till?", "Is there any overlap between #1 and #2?"], "evidence": [[[["History of robots-41"]], [["Wall Street Crash of 1929-1"]], ["operation"]], [[["Unimate-2"], "no_evidence"], [["Great Depression-1"]], ["operation"]], [[["Robotics-7"]], [["Wall Street Crash of 1929-1"]], ["operation"]]]}
{"qid": "0a95811a52c939156796", "term": "Shrimp", "description": "Decapod crustaceans", "question": "Do shrimp taste best when cooked for a long time?", "answer": false, "facts": ["Shrimp becomes tough and rubbery if cooked for a long time.", "The ideal texture for shrimp is soft and easily chewed."], "decomposition": ["What happens when shrimp is cooked for a long time?", "What is the ideal texture for shrimp?", "Are #1 and #2 the same?"], "evidence": [[[["Shrimp and prawn as food-11"], "no_evidence"], [["Shrimp and prawn as food-8"], "no_evidence"], ["operation"]], [[["Shrimp and prawn as food-10"]], [["Longjing prawns-1"]], ["operation"]], [[["Shrimp and prawn as food-9"]], ["no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "c5aabbea64966b4f2d42", "term": "Chevrolet Corvette", "description": "Sports car by the Chevrolet division of General Motors (GM)", "question": "Does selling a 2020 Chevrolet Corvette almost pay for a year at Columbia University?", "answer": true, "facts": ["The price of a 2020 Chevrolet Corvette is $58,900.", "Columbia University cost $59,430 during the 2018-2019 school year."], "decomposition": ["How much does a 2020 Chevrolet Corvette cost?", "How much does a year at Columbia University cost?", "Is #1 almost as much as #2?"], "evidence": [[[["Chevrolet Corvette-1"], "no_evidence"], [["Columbia University-28"]], ["no_evidence", "operation"]], [["no_evidence"], [["Columbia University-28"]], ["no_evidence", "operation"]], [["no_evidence"], [["Columbia University-28"], "no_evidence"], ["operation"]]]}
{"qid": "a1493f4a007aa2d7ca24", "term": "Super Mario", "description": "platform video game series from Nintendo's Mario franchise", "question": "Does Super Mario mainly focus on a man in green?", "answer": false, "facts": ["Super Mario follows the adventures of a plumber named Mario.", "Mario wears a red shirt and plumber's overalls."], "decomposition": ["Who is the main character of the game Super Mario?", "Does #1 wear green?"], "evidence": [[[["Super Mario-1"]], [["Mario-29"]]], [[["Super Mario-2"]], [["Mario-6"], "operation"]], [[["Super Mario-1"]], [["Mario-6"]]]]}
{"qid": "3e1f787a59396deeb88c", "term": "Southern United States", "description": "Cultural region of the United States", "question": "Can you hunt Iberian wolves in the Southern United States?", "answer": false, "facts": ["The Iberian wolf inhabits northern Portugal and northwestern Spain.", "Portugal and Spain are not located in the Southern United States."], "decomposition": ["What is the range of the Iberian wolf?", "Is #1 located in the Southern United States?"], "evidence": [[[["Iberian wolf-1"]], ["operation"]], [[["Iberian wolf-1"]], [["United States-1", "Western Europe-1"]]], [[["Iberian wolf-1"]], [["Iberian Peninsula-64", "United States-1"]]]]}
{"qid": "f1fec95172ebcbdf1fb8", "term": "Felicity Huffman", "description": "American actress", "question": "Would Felicity Huffman vote for Mike DeWine?", "answer": false, "facts": ["Mike DeWine is Governor of Ohio", "Felicity Huffman is a resident of California"], "decomposition": ["What elected office is held by Mike DeWine?", "What state is Mike DeWine #1 of?", "What state does Felicity Huffman live in?", "Are #2 and #3 the same state?"], "evidence": [[[["Mike DeWine-24"]], [["Mike DeWine-24"]], [["Felicity Huffman-24"]], [["Felicity Huffman-24"]]], [[["Mike DeWine-1"]], [["Mike DeWine-1"]], [["Felicity Huffman-24"]], ["operation"]], [[["Mike DeWine-1"]], [["Mike DeWine-1"]], [["Felicity Huffman-24"]], ["operation"]]]}
{"qid": "ff3811735ededd8ec3a7", "term": "Asparagus", "description": "species of plant", "question": "Are slime lilies in a different scientific family than asparagus?", "answer": false, "facts": ["Asparagus is a species of plants of the Asparagaceae family.", "Slime lilies are the common name for the flowering albuca plant.", "The albuca plant belongs to the scientific family of Asparagaceae."], "decomposition": ["Which family does the asparagus belong to?", "Which plants are commonly referred to as slime lilies?", "Which family does #2 belong to?", "Is #1 different from #3?"], "evidence": [[[["Asparagaceae-1"]], [["Albuca-1"]], [["Albuca-1"]], ["operation"]], [[["Asparagus-2"]], [["Albuca-1"]], [["Albuca-1"]], ["operation"]], [[["Asparagaceae-1"]], [["Albuca-1"]], [["Albuca-1"]], ["operation"]]]}
{"qid": "38ef97eb7cdd4200fd00", "term": "Latino", "description": "A group of people in the United States with ties to Latin America", "question": "Is blonde hair green eyed Sara Paxton considered a Latino?", "answer": true, "facts": ["Sara Paxton is an American actress.", "Latino's are people with ancestral ties to Latin America.", "Sara Paxton was born to an Irish/English father and a Mexican/Spanish/Chilean mother.", "Mexico is a country that is part of Latin America."], "decomposition": ["Latinos are people with which nationality?", "Which countries are Sara Paxton's parents from?", "Is any of #2 included in #1?"], "evidence": [[[["Latino (demonym)-1", "Latino (demonym)-2"]], [["Sara Paxton-3"]], ["operation"]], [[["Latin America-12", "Latino (demonym)-1", "Mexico-1"]], [["Sara Paxton-3"]], ["operation"]], [[["Latino (demonym)-18"]], [["Sara Paxton-3"]], ["operation"]]]}
{"qid": "5a2e62e3c0ded7a4bddd", "term": "Monogamy", "description": "Relationship form where each individual has only one partner during their lifetime or at any one time", "question": "Did Thomas Greenhill's parents violate the concept of monogamy?", "answer": false, "facts": ["Thomas Greenhill was a surgeon born to William and Elizabeth Greenhill.", "William and Elizabeth Greenhill had 39 children.", "Monogamy is a committed relationship between two people where usually they remain together for life.", "Thomas Greenhill was the last of his parents 39 children and was born shortly after his father died."], "decomposition": ["Who was Thomas Greenhill's father?", "How many wives did #1 marry in his lifetime?", "Is #2 greater than one?"], "evidence": [[[["Thomas Greenhill (surgeon)-4"]], [["Thomas Greenhill (surgeon)-5"]], ["operation"]], [[["Thomas Greenhill (surgeon)-4"]], [["Thomas Greenhill (surgeon)-7"]], ["operation"]], [[["Thomas Greenhill (surgeon)-1"]], [["William Greenhill-5"], "no_evidence"], ["operation"]]]}
{"qid": "7d310e9ebc2025febdd6", "term": "Winter", "description": "one of the Earth's four temperate seasons, occurring between autumn and spring", "question": "Is winter solstice in Northern Hemisphere closer to July than in Southern Hemisphere? ", "answer": false, "facts": ["The winter solstice in the Northern Hemisphere happens in December.", "The winter solstice in the Southern Hemisphere happens in June."], "decomposition": ["When does the winter solstice occur in the Northern Hemisphere?", "When does the winter solstice occur in the Southern Hemisphere?", "How many days are in between #1 and July?", "How many days are between #2 and July?", "Is #4 greater than #3?"], "evidence": [[[["Winter solstice-2"]], [["Winter solstice-2"]], ["operation"], ["operation"], ["operation"]], [[["Winter solstice-2"]], [["Winter solstice-2"]], ["no_evidence", "operation"], ["no_evidence", "operation"], ["no_evidence", "operation"]], [[["Winter solstice-2"]], [["Winter solstice-2"]], ["no_evidence"], ["no_evidence"], ["operation"]]]}
{"qid": "01786fe2b099fd7fb504", "term": "Minor League Baseball", "description": "hierarchy of professional baseball leagues affiliated with Major League Baseball", "question": "Were weather phenomena avoided when naming minor league baseball teams?", "answer": false, "facts": ["Weather phenomena refers to types of weather caused conditions such as cyclones, storms, and tsunamis.", "Minor league baseball teams include the Brooklyn Cyclones and Lake Elsinore Storm."], "decomposition": ["What are some names of weather phenomena?", "What are the name of minor league baseball teams?", "Are any terms in #1 also present in #2?"], "evidence": [[[["Weather-5"], "no_evidence"], [["Omaha Storm Chasers-1"], "no_evidence"], ["operation"]], [[["Glossary of meteorology-1"], "no_evidence"], [["Minor League Baseball-40"], "no_evidence"], ["no_evidence", "operation"]], [[["Thunder-1"]], [["Trenton Thunder-1"]], ["operation"]]]}
{"qid": "b0ab236d19fec61c0111", "term": "Gorilla", "description": "Genus of mammals", "question": "Is it expected that Charla Nash would be anxious near a gorilla?", "answer": true, "facts": ["In 2009, Charla Nash was attacked and nearly killed by a chimpanzee. ", "While a different species, Gorillas and Chimpanzees have similar physical appearances and are both primates."], "decomposition": ["Which animal attacked Charla Nash in 2009?", "Does #1 bear significant similarity to a gorilla?"], "evidence": [[[["Travis (chimpanzee)-8"]], ["operation"]], [[["Travis (chimpanzee)-8"]], [["Hominidae-1"]]], [[["Travis (chimpanzee)-8"]], [["Gorilla-1"], "operation"]]]}
{"qid": "b94f96243e515dba1dac", "term": "Stoning", "description": "execution method", "question": "Will a celibate cleric likely suffer a stoning in Somalia?", "answer": false, "facts": ["A cleric is the term for a Muslim priest.", "Celibate people remain chaste and do not engage in relations with others.", "Stoning is a penalty in Somalia used to punish adulterers.", "Many Islamic militants have been in control of various parts of Somalia."], "decomposition": ["Which crime is punishable by stoning in Somalia?", "What relationship must a person guilty of #1 be in in order to be deemed guilty?", "Would a celibate cleric be involved in #2?"], "evidence": [[[["Sharia-16", "Sharia-4", "Somalia-158"]], [["Adultery-1"]], [["Celibacy-1"], "operation"]], [[["Stoning-65"]], [["Adultery-1"]], [["Celibacy-1"], "operation"]], [[["Stoning-83"]], [["Stoning-83"]], [["Stoning-83"]]]]}
{"qid": "e5f9336ceb74622c14c0", "term": "Model (person)", "description": "person employed to display, advertise and promote products, or to serve as a visual aid", "question": "Would a model be likely to frequently enjoy the menu at Cookout?", "answer": false, "facts": ["Models are known for being very thin on average.", "Cookout serves high calorie American style barbecue food.", "Models often have pressure put on them to maintain a slim figure."], "decomposition": ["What is the typical body shape of a model?", "What kind of food does a cookout typically have?", "Are #2 foods high in calories?", "In order to maintain #1, what kinds of food must a person eat?", "Does #3 match with #4?"], "evidence": [[[["Model (person)-22"]], [["Cook Out (restaurant)-1"]], [["Food energy-4"]], [["Model (person)-24"], "no_evidence"], ["operation"]], [[["The Thin Ideal-21"]], [["Cook Out (restaurant)-1"]], ["operation"], [["Dieting-13"]], ["operation"]], [[["Model (person)-24"]], [["Cook Out (restaurant)-1"]], [["Fast food-6"]], [["Dieting-1"]], ["operation"]]]}
{"qid": "307c3ae5cff437eee937", "term": "Rush Limbaugh", "description": "American radio talk show host, commentator, author, and television personality", "question": "Does Coast to Coast AM have more longevity than the Rush Limbaugh show?", "answer": true, "facts": ["As of 2020, The Rush Limbaugh Show has been on the airwaves since 1988.", "As of 2020, Coast to Coast AM has been on the airwaves since 1984."], "decomposition": ["When did the Rush Limbaugh show first air?", "When did Coast to Coast AM first air?", "Is #2 before #1?"], "evidence": [[[["The Rush Limbaugh Show-1"]], [["Coast to Coast AM-2"]], ["operation"]], [[["The Rush Limbaugh Show-1"]], [["Coast to Coast AM-2"]], ["operation"]], [[["Rush Limbaugh-1"]], [["Coast to Coast AM-2"]], ["operation"]]]}
{"qid": "4bbf4b169b4981ad5a34", "term": "Miami", "description": "", "question": "Can you swim to Miami from New York?", "answer": false, "facts": ["The longest distance swam by a person is 139.8 miles.", "It is over 1,000 miles from New York to Miami."], "decomposition": ["What is the longest distance that a human has ever swum?", "How far does one need to swim to get from New York to Miami?", "Is #1 more than #2?"], "evidence": [[[["Veljko Rogošić-1"]], [["Silver Meteor-19"]], ["operation"]], [[["Veljko Rogošić-1"]], [["Miami River (New York)-1"], "no_evidence"], ["operation"]], [[["Long-distance swimming-1"]], [["Miami-1", "New York City-1"], "no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "267609f49ccd3c0839c3", "term": "Swiss Guard", "description": "Military of Vatican City", "question": "Can the Swiss Guard fill the Virginia General Assembly chairs?", "answer": false, "facts": ["The Virginia General Assembly has 140 seats.", "The Swiss Guard is an honour guard of Vatican City that consists of 135 men."], "decomposition": ["What is the size of the Swiss Guard?", "What is the seating capacity of the Virginia General Assembly?", "Is #1 equal to or greater than #2?"], "evidence": [[[["Swiss Guards-18"], "no_evidence"], [["Virginia General Assembly-1"]], ["no_evidence", "operation"]], [[["Swiss Guard-31"]], [["Virginia General Assembly-1"]], ["operation"]], [[["Swiss Guard-9"]], [["Virginia General Assembly-1"]], ["operation"]]]}
{"qid": "ec71dcb7d6ace3e73ef9", "term": "Soup", "description": "primarily liquid food", "question": "Is shoe soup innocuous?", "answer": true, "facts": ["Soup is a primarily liquid food containing various meats and beans.", "Director Werner Herzog lost a bet and cooked his shoe into a soup and ate it in 1980.", "Werner Herzog turned 77 in 2019 and had a role in the hit TV series the Mandalorian."], "decomposition": ["What film director ate shoe soup in the year 1980?", "Is #1 still alive?"], "evidence": [[[["Werner Herzog Eats His Shoe-1"]], [["Werner Herzog-1"], "operation"]], [[["Werner Herzog-12"]], [["Werner Herzog-30"], "operation"]], [[["Werner Herzog Eats His Shoe-1"]], [["Werner Herzog-1"]]]]}
{"qid": "b8976035f0804cbd356e", "term": "Philippine–American War", "description": "Armed conflict between the First Philippine Republic and the United States", "question": "Would a veteran of the Phillippine-American War come home craving SPAM?", "answer": false, "facts": ["War veterans are often used to the rations they eat during war and crave similar items at home.", "The Philippine-American war took place before World War II, in 1899.", "Soldiers in World War II were given SPAM in their rations. ", "SPAM was released in 1937."], "decomposition": ["The Philippine-American war took place in what year?", "What year was SPAM invented in?", "Is #1 after #2?"], "evidence": [[[["Philippine–American War-1"]], [["Spam (food)-3"]], ["operation"]], [[["Philippine–American War-1"]], [["Spam (food)-1"]], ["operation"]], [[["Philippine–American War-1"], "operation"], ["no_evidence"], ["no_evidence"]]]}
{"qid": "961b257f0eb8f704b247", "term": "Euro", "description": "European currency", "question": "Will a Euro sink in water?", "answer": true, "facts": ["The smallest Euro paper bill is Five Euro.", "One Euro is only available as a coin.", "Coins sink in water. ", "A metal coin is more dense than water"], "decomposition": ["What is the density of water?", "What material is an Euro coin made of?", "Is the density of #2 usually higher than #1?"], "evidence": [[[["Properties of water-14"]], [["Euro coins-50"]], [["Euro coins-50", "Properties of water-14"]]], [[["Properties of water-14"]], [["Euro coins-27"]], ["no_evidence", "operation"]], [[["Buoyancy-2", "Water-7"], "no_evidence"], [["Euro coins-50"]], [["Alloy-13"], "no_evidence", "operation"]]]}
{"qid": "e32511f311bfd294ebf1", "term": "John Key", "description": "38th Prime Minister of New Zealand", "question": "Could John Key issue an executive order in the USA?", "answer": false, "facts": ["An executive order is a means of issuing federal directives in the United States, used by the president of the United States.", "To serve as president of the United States, one must be a natural-born citizen of the United States.", "John Key was born in Auckland, New Zealand."], "decomposition": ["Who can issue executive orders in the USA?", "What are the requirements to become #1?", "Does John Key satisfy all of #2?"], "evidence": [[[["Executive order-1"]], [["President of the United States-37"], "no_evidence"], [["John Key-1"], "no_evidence"]], [[["Federal government of the United States-18"]], [["President of the United States-38"]], [["John Key-1"]]], [[["Executive order-1"]], [["President of the United States-38"]], [["John Key-5"]]]]}
{"qid": "40eb6c9c236c77164794", "term": "The Doctor (Doctor Who)", "description": "fictional character from Doctor Who", "question": "Would Marvel's Gateway be envious of the Doctor (Doctor Who)'s TARDIS machine?", "answer": false, "facts": ["The Doctor (Doctor Who) used the TARDIS, a largely unreliable time traveling machine, to travel through time and space.", "Gateway is a Marvel comic character linked to the X-Men comics.", "Gateway has the power to create wormholes that allow him to travel through time and space."], "decomposition": ["What is the TARDIS's special power?", "What is Gateway's special power?", "Is #1 different than #2?"], "evidence": [[[["TARDIS-13", "TARDIS-14"]], [["Gateway (comics)-15"]], ["operation"]], [[["TARDIS-1"]], [["Gateway (comics)-15"]], ["operation"]], [[["TARDIS-1"]], [["Gateway (comics)-1"]], ["operation"]]]}
{"qid": "867a5425c26092b30fbf", "term": "Snow White", "description": "fairy tale", "question": "Are Disney's seven dwarves the original ones?", "answer": false, "facts": ["In the original fairy tale, the dwarves were unnamed, but first named in a 1912 stage version: Blick, Flick, Glick, Snick, Plick, Whick, and Quee.", "In Disney's version, the dwarves are named Happy, Sleepy, Sneezy, Grumpy, Dopey, Bashful, and Doc."], "decomposition": ["What were the original names of the seven dwarfs?", "What are the names of the seven dwarfs in Disney films?", "Is #1 identical to #2?"], "evidence": [[[["Seven Dwarfs-6"]], [["Snow White and the Seven Dwarfs (1937 film)-7"]], ["operation"]], [["no_evidence"], [["Snow White and the Seven Dwarfs (1937 film)-7"]], ["no_evidence", "operation"]], [[["Seven Dwarfs-6"]], [["Snow White and the Seven Dwarfs (1937 film)-7"]], [["Seven Dwarfs-6"], "operation"]]]}
{"qid": "45605f9dbc0cf85f668f", "term": "Atlantic salmon", "description": "species of fish", "question": "Would Atlantic Salmon be within David Duchovny's dietary guidelines?", "answer": true, "facts": ["David Duchovny is a pescatarian. ", "Pescatarians do not eat chicken, pork, or beef, but will eat fish."], "decomposition": ["What kind of diet does David Duchovny follow?", "What type of food is Atlantic Salmon?", "Do people who follow #1 diets eat #2?"], "evidence": [[[["David Duchovny-12"]], [["Atlantic salmon-1"]], [["Pescetarianism-1"]]], [[["David Duchovny-12"]], [["Atlantic salmon-1", "Seafood-1"]], [["Pescetarianism-1"]]], [[["David Duchovny-3"], "no_evidence"], [["Atlantic salmon-1"]], ["operation"]]]}
{"qid": "06adc3a703c49b96a7e5", "term": "Artillery", "description": "Heavy ranged guns or weapons", "question": "Would a slingshot be improperly classified as artillery?", "answer": true, "facts": ["Artillery refers to ranged weaponry that is predominantly used in breaching fortifications.", "Examples of artillery include: howitzers, mortars, and rockets.", "Mortars can have a range up to 4,680m.", "A slingshot is a string weapon that propels a rock or other small projectile.", "Some slingshots can fire projectiles up to 9m."], "decomposition": ["What are the basic characteristics of a weapon considered artillery?", "Does a slingshot fail to possess all of #1?"], "evidence": [[[["Artillery-9"]], [["Slingshot-8"]]], [[["Artillery-1"]], [["Slingshot-1"], "operation"]], [[["Artillery-1"]], ["operation"]]]}
{"qid": "7a096b2fc559fd5c7919", "term": "Green", "description": "Additive primary color visible between blue and yellow", "question": "Is a paleo dieter unlikely to color beverages green for St. Patrick's Day?", "answer": true, "facts": ["There is no natural source for green food coloring approved by the FDA", "A paleo diet avoids artificial colors and flavors"], "decomposition": ["What are some common FDA approved sources of green color applied to beverages?", "What kind of foods would a paleo dieter avoid?", "Is #1 included in #2?"], "evidence": [[[["Food coloring-11"]], [["Paleolithic diet-3"]], ["operation"]], [[["Food coloring-15"]], [["Paleolithic diet-12"]], [["Paleolithic diet-12"], "operation"]], [[["Fast Green FCF-1"]], [["Paleolithic diet-3"]], ["operation"]]]}
{"qid": "ce2336a5272765f263c4", "term": "Harry Potter and the Philosopher's Stone", "description": "1997 fantasy novel by J. K. Rowling", "question": "Would characters in Harry Potter and the Philosopher's Stone be persecuted as pagans?", "answer": true, "facts": ["Pagans are defined as people that hold beliefs other than those of the major world religions (Christianity, Islam, and Judaism).", "The characters in Harry Potter and the Philosopher's Stone practice magic.", "Islam explicitly forbid the practice of magic and has harsh consequences for it.", "Jezebel in Hebrew scripture was a worshiper of pagan Baal and was thrown from a window for her beliefs.", "Women accused of being witches were burned alive by Christians during the Salem Witch Trials."], "decomposition": ["What are the characters in Harry Potter and the Philosopher's Stone known to perform?", "What would performers of #1 be considered by Christians?", "What have Christians done to #2 in the past?", "Are #2 pagans and #3 a form of persecution?"], "evidence": [[[["Harry Potter and the Philosopher's Stone-1"]], [["Witchcraft-1"]], [["Witchcraft-5"]], [["Persecution-1"]]], [[["Harry Potter and the Philosopher's Stone-1"]], [["Magic (supernatural)-2", "Paganism-24"]], [["Witch trials in the early modern period-1"], "no_evidence"], ["operation"]], [[["Harry Potter-1"]], [["Witchcraft-2"]], [["Death by burning-18"]], ["operation"]]]}
{"qid": "82e32a0627566be76a90", "term": "Friday", "description": "day of the week", "question": "Did goddess Friday is named after despise felines?", "answer": false, "facts": ["Felines are a species of animals that include lions, tigers, and domestic cats.", "Friday is named after the Norse goddess Freya. ", "Freya is often depicted in art with cats.", "Freya had two cats that pulled her magical chariot."], "decomposition": ["Which goddess is Friday named after?", "Which animals pulled #1's chariots?", "Are felines excluded from #2?"], "evidence": [[[["Friday-3"]], [["Frigg-27"]], ["operation"]], [[["Friday-3"]], [["Venus (mythology)-1"]], [["Venus (mythology)-1"]]], [[["Friday-3"]], ["no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "3ca5966b88394e62271e", "term": "University of Pennsylvania", "description": "Private Ivy League research university in Philadelphia, Pennsylvania", "question": "Could Brooke Shields succeed at University of Pennsylvania?", "answer": true, "facts": ["Brooke Shields graduated from Princeton University.", "Princeton is ranked as the number 1 national college by US news.", "University of Pennsylvania is ranked as number 6 national college by US news.", "Princeton only admits around 6 percent of applicants as of 2018.", "University of Pennsylvania accepts around 9% of applicants as of 2018."], "decomposition": ["What college did Brooke Shields go to?", "Out of all colleges in the US, how is #1 ranked?", "Is the ranking of University of Pennsylvania similar to #2?"], "evidence": [[[["Brooke Shields-6"]], [["Princeton University-59"]], [["University of Pennsylvania-48"]]], [[["Brooke Shields-6"]], [["Princeton University-59"]], [["University of Pennsylvania-48"], "operation"]], [[["Brooke Shields-6"]], [["Princeton University-3"], "operation"], [["University of Pennsylvania-47"], "no_evidence"]]]}
{"qid": "a0ab5b0fc9bb188bcc99", "term": "Nickel", "description": "Chemical element with atomic number 28", "question": "Is nickel dominant material in US 2020 nickels?", "answer": false, "facts": ["Nickels have been made of various materials including silver in the 1940s.", "Nickels in 2020 are made from a mix of copper and nickel.", "2020 nickels are 25% nickel and 75% copper."], "decomposition": ["What is the composition of the US 2020 nickel?", "Of the elements listed in #1, do any of them make up more than 50% of the US 2020 Nickel?", "If #2 is yes, is that element nickel?"], "evidence": [[[["Jefferson nickel-14"], "no_evidence"], ["no_evidence"], ["no_evidence", "operation"]], [[["Nickel (United States coin)-1"], "no_evidence"], [["Nickel (United States coin)-1"]], ["operation"]], [[["Nickel-5"]], ["operation"], ["operation"]]]}
{"qid": "88016d1d8b284aa9113c", "term": "Nickel", "description": "Chemical element with atomic number 28", "question": "If your skin was turning the color of a zombie, could it be because of nickel?", "answer": true, "facts": ["Zombies are often depicted as green in pallor. ", "Nickel in jewelry often turns skin a greenish color."], "decomposition": ["What color skin are zombies typically depicted with?", "Does Nickel turn a person's skin #1?"], "evidence": [[[["Zombie-3"]], [["Nickel allergy-12"]]], [["no_evidence"], [["Glass coloring and color marking-3"], "no_evidence"]], [[["Zombie-3"], "no_evidence"], [["Pallor mortis-1"], "no_evidence", "operation"]]]}
{"qid": "a0d0c2ac289c7a59911d", "term": "Lactobacillus", "description": "genus of bacteria", "question": "Is overfeeding Lactobacillus unwise for people without dental insurance?", "answer": true, "facts": ["Lactobacillus species convert sugars they digest to lactic acid ", "The lactic acid of some Lactobacillus species is associated with tooth decay", "Dental procedures can be expensive without insurance"], "decomposition": ["What are the products of Lactobacillus?", "What conditions are caused by #1?", "What medical procedures would be required to fix #2?", "Would #3 be more affordable with dental insurance?"], "evidence": [[[["Lactobacillus-1"]], [["Lactic acid-5"]], [["Tooth decay-77"]], [["Dental insurance-1"]]], [[["Lactobacillus-1", "Lactobacillus-2"]], [["Lactic acid bacteria-14"]], [["Tooth decay-77"]], [["Dental insurance-1"]]], [[["Lactobacillus-10"]], [["Lactobacillus-10"]], [["Tooth decay-76"]], [["Dental insurance-1"]]]]}
{"qid": "30e2cf44640c4fe81d80", "term": "Illuminati", "description": "A name given to several groups, both real and fictitious", "question": "Is the Illuminati card game still popular?", "answer": false, "facts": ["The original version of the game was released in 1982.", "A collectible card game version was released in 1995 but only had one set.", "The most recent edition of the base game was published in 2007."], "decomposition": ["When was the last Illuminati card game published?", "Was #1 with the last few years?"], "evidence": [[[["Illuminati (game)-1"], "no_evidence"], ["no_evidence"]], [[["Illuminati (game)-2", "Illuminati (game)-4"], "no_evidence"], ["no_evidence", "operation"]], [[["Illuminati (game)-13"]], ["operation"]]]}
{"qid": "aefa59c255bf15e90f58", "term": "Naruto", "description": "Japanese manga and anime series", "question": "Would the historic Hattori Hanzō admire Naruto?", "answer": false, "facts": ["Naruto is a ninja", "Ninja tactics were considered dishonorable by samurai", "Hattori Hanzō is a famous historical samurai "], "decomposition": ["What was Naruto's profession?", "What was Hattori Hanzō's profession? ", "Did #2 respect the actions of #1?"], "evidence": [[[["Naruto-1"]], [["Hattori Hanzō-1"]], [["Hattori Hanzō-6"], "no_evidence", "operation"]], [[["Naruto-1"]], [["Hattori Hanzō-1"]], [["Ninja-1"], "operation"]], [[["Naruto-7"], "no_evidence"], [["Hattori Hanzō-10"], "operation"], ["no_evidence"]]]}
{"qid": "3e9e3ccc9fc4d44a3eb4", "term": "Astronaut", "description": "Person who commands, pilots, or serves as a crew member of a spacecraft", "question": "Can actress Danica McKellar skip astronaut education requirements?", "answer": true, "facts": ["Astronaut's are required to have a bachelor's degree in engineering, biological science, physical science, computer science, or mathematics.", "Actress Danica McKellar graduated summa cum laude from UCLA with a degree in Mathematics."], "decomposition": ["Astronauts can have any one of which degrees?", "What degree does Danica McKellar have?", "Is #2 included in #1?"], "evidence": [[[["NASA Astronaut Corps-10"]], [["Danica McKellar-5"]], ["operation"]], [[["NASA Astronaut Corps-10"]], [["Danica McKellar-5"]], ["operation"]], [[["NASA Astronaut Corps-10"]], [["Danica McKellar-5"]], ["operation"]]]}
{"qid": "8e073418da1eab499775", "term": "Islamophobia", "description": "Fear, hatred of, or prejudice against the Islamic religion or Muslims generally,", "question": "Is Islamophobia against Cyprus majority religion misdirected?", "answer": true, "facts": ["Islamophobia is prejudice and fear against Muslims.", "Cyprus is a country in the Middle East, which is a predominantly Muslim region.", "Cyprus is the only Christian majority country in the Middle East, with Christians forming between 76% and 78% of the country's total population, and most of them adhere to Eastern Orthodox Christianity."], "decomposition": ["What religion is targeted by Islamophobia?", "What is the most common religion in Cyprus?", "Is #1 different than #2?"], "evidence": [[[["Islamophobia-1"]], [["Cyprus-100"]], ["operation"]], [[["Islamophobia-54"], "no_evidence"], [["Religion in Cyprus-1"], "operation"], ["no_evidence"]], [[["Islamophobia-1"]], [["Religion in Cyprus-1"]], ["operation"]]]}
{"qid": "aeea08d186f49c455038", "term": "T-Mobile", "description": "global telecommunication company", "question": "Can you use the T-Mobile tuesdays app if you aren't a T-Mobile customer?", "answer": false, "facts": ["T-Mobile tuesdays is a rewards app for T-Mobile subscribers.", "T-Mobile Tuesdays verifies users by making sure they have a T-Mobile phone number."], "decomposition": ["Who can use the T-Mobile tuesdays app?", "Does T-Mobile allow use of the app if you aren't #1?"], "evidence": [[[["Un-carrier-22"]], [["Un-carrier-22"]]], [[["T-Mobile-1"], "no_evidence"], ["no_evidence", "operation"]], [[["Un-carrier-22"]], [["Un-carrier-22"]]]]}
{"qid": "54128d7439105554c9e3", "term": "ABBA", "description": "Swedish pop group", "question": "Is calling ABBA the Swedish Beatles a preposterous claim?", "answer": true, "facts": ["ABBA was a Swedish band that had 1 Billboard number 1 hit and 4 top 10 hits.", "The Beatles had 20 Billboard number 1 hits and 34 top 10 hits."], "decomposition": ["How many Billboard number ones did ABBA have?", "How many Billboard number ones did the Beatles have?", "Is #1 lower than #2?"], "evidence": [[[["ABBA-38"]], [["Billboard 200-25"]], ["operation"]], [[["ABBA-120"]], [["The Beatles-111", "The Beatles-4"], "no_evidence"], ["operation"]], [[["ABBA-121"]], [["Billboard 200-26"]], [["Billboard 200-26"], "operation"]]]}
{"qid": "b418ba4e11aee26faabc", "term": "Jason", "description": "Greek mythological hero", "question": "Does Jason have anything in common with Dr. Disrespect?", "answer": true, "facts": ["Jason cheated on Medea with Creusa", "Dr. Disrespect cheated on his wife with another woman"], "decomposition": ["Was Jason faithful or unfaithful?", "Was Dr. Disrespect faithful or unfaithful?", "Are #1 and #2 the same?"], "evidence": [[[["Medea-10"], "no_evidence"], [["Dr DisRespect-1"], "no_evidence"], ["no_evidence", "operation"]], [[["Jason-3"]], ["no_evidence"], ["operation"]], [[["Jason-18"]], [["Dr DisRespect-5"]], ["operation"]]]}
{"qid": "4ba19380524bb1f05786", "term": "Year", "description": "Orbital period of the Earth around the Sun", "question": "Can you listen to the entire Itunes song catalog in one year?", "answer": false, "facts": ["Itunes has around 43 million songs as of 2017.", "The average length of a song is 3 minutes.", "There are 525,600 minutes in a year."], "decomposition": ["How many songs are on iTunes?", "What is the average song length?", "What is #1 multiplies by #2?", "How many minutes are in a year?", "Is #4 greater than #3?"], "evidence": [[[["ITunes Store-2"]], [["Popular music-19"]], ["operation"], [["Year-57"]], ["operation"]], [[["ITunes-20"]], ["no_evidence"], ["no_evidence", "operation"], [["Seasons of Love-1"]], ["no_evidence", "operation"]], [[["ITunes Store-2"]], [["Justin Bieber-29"], "no_evidence"], ["operation"], [["Year-19"], "no_evidence"], ["operation"]]]}
{"qid": "33d65a4b34005b4ddd62", "term": "Fever", "description": "common medical sign characterized by elevated body temperature", "question": "Is a fever cured by listening to a cowbell?", "answer": false, "facts": ["A fever is an increase in body temperature above the normal range", "Fever can be treated with medication or will usually disappear if left alone", "A cowbell is a musical instrument"], "decomposition": ["What are some common ways of treating a fever?", "Is listening to a cowbell included in #1?"], "evidence": [[[["Fever-2"]], [["Cowbell-1"], "operation"]], [[["Fever-37"]], [["Cowbell-1"]]], [[["Fever-2"]], ["operation"]]]}
{"qid": "34146f5ebddcb370c29a", "term": "New Year's Eve", "description": "holiday celebrated on 31 December", "question": "Should you ask a neighbor for candy on New Year's Eve?", "answer": false, "facts": ["Halloween is a holiday where children knock on doors of houses in their neighborhood asking for treats", "Halloween falls on October 31st", "New Year's Eve is a celebration of the end of the year held on December 31st"], "decomposition": ["On which holiday do children go trick-or-treating?", "What is the date of #1?", "When is New Year's Eve celebration?", "Are #2 and #3 the same?"], "evidence": [[[["Halloween-3"]], [["Halloween-1"]], [["New Year's Eve-1"]], ["operation"]], [[["Trick-or-treating-1"]], [["Halloween-11"]], [["New Year's Eve-36"]], ["operation"]], [[["Trick-or-treating-1"]], [["Halloween-1"]], [["New Year's Eve-1"]], ["operation"]]]}
{"qid": "bb3737083669e10c889f", "term": "Gallic Wars", "description": "Wars in which the Roman Republic conquered Gaul", "question": "Would Roman Gallic Wars army struggle to build the pyramids faster?", "answer": false, "facts": ["The pyramids were built by an estimated 30,000 workers.", "The Roman Gallic war army had around 75,000 soldiers."], "decomposition": ["How many people worked on the pyramids?", "How many soldiers were in the Roman Gallic war army?", "Is #1 greater than or equal to #2?"], "evidence": [[[["Giza pyramid complex-19"]], ["no_evidence"], ["no_evidence", "operation"]], [[["Egyptian pyramid construction techniques-2", "Egyptian pyramid construction techniques-28"], "no_evidence"], [["Roman legion-24", "Size of the Roman army-7"]], ["operation"]], [[["Giza pyramid complex-31"]], [["Gallic Wars-4", "Size of the Roman army-3"], "no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "05e9cdc44f1b066badd7", "term": "Moustache", "description": "Facial hair grown on the upper lip", "question": "Is it common for women to have moustaches?", "answer": false, "facts": ["Facial hair doesn't normally grow on women like it does on men.", "A little bit of hair can grow between the upper lip and nose but it's a very small amount and generally not enough to be noticeable."], "decomposition": ["Which gender grows sizable moustaches more commonly?", "Is #1 the same as women?"], "evidence": [[[["Moustache-9"]], ["operation"]], [[["Beard-27"]], [["Beard-27"], "operation"]], [[["Facial hair-2"]], ["operation"]]]}
{"qid": "b8677742616fef051f00", "term": "Genghis Khan", "description": "founder and first Great Khan of the Mongol Empire", "question": "Are more people today related to Genghis Khan than Julius Caesar?", "answer": true, "facts": ["Julius Caesar had three children.", "Genghis Khan had sixteen children.", "Modern geneticists have determined that  out of every 200 men today has DNA that can be traced to Genghis Khan."], "decomposition": ["How many kids did Julius Caesar have?", "How many kids did Genghis Khan have?", "Is #2 greater than #1?"], "evidence": [[[["Caesarion-2", "Julia (daughter of Caesar)-1"]], [["Alakhai Bekhi-1", "Tolui-1"], "no_evidence"], ["operation"]], [[["Julius Caesar-75"]], [["Genghis Khan-17"]], ["operation"]], [[["Gaius Julius Caesar-7"]], [["Genghis Khan-15"], "no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "cc6e607ec6b68023be26", "term": "Auburn, New York", "description": "City in New York, United States", "question": "Can you fit every resident of Auburn, New York, in Tropicana Field?", "answer": true, "facts": ["The capacity of Tropicana Field is 36,973", "The population of Auburn, NY is 27,687"], "decomposition": ["What is the capacity of Tropicana Field?", "What is the population of Auburn, NY?", "Is #1 greater than #2?"], "evidence": [[[["Tropicana Field-31"]], [["Auburn, New York-1"]], [["Tropicana Field-31"], "operation"]], [[["Tropicana Field-31"]], [["Auburn, New York-1"]], ["operation"]], [[["Tropicana Field-31"]], [["Auburn, New York-1"]], ["operation"]]]}
{"qid": "db1a2626dae69bdecb34", "term": "Fiat Chrysler Automobiles", "description": "Multinational automotive manufacturing conglomerate", "question": "Is Fiat Chrysler associated with Japanese cars?", "answer": false, "facts": ["Fiat Chrysler is composed of the two merged automobile companies Fiat and Chrysler.", "Fiat is an Italian company with headquarters in Amsterdam.", "Chrysler is based in the United States of America.", "Together they own 10 car brands but none are Asian in origin."], "decomposition": ["Which companies merged to form Fiat Chrysler?", "Is any of #1 based in Japan", "Which cars have been produced by Fiat Chrysler?", "Is any of #3 Japanese in origin?", "Is #2 or #4 positive?"], "evidence": [[[["Fiat Chrysler Automobiles-1"]], [["Chrysler-1", "Fiat S.p.A.-1"], "operation"], [["Alfa Romeo 4C-12", "Fiat Chrysler Automobiles-27"], "no_evidence"], ["operation"], ["operation"]], [[["Fiat Chrysler Automobiles-1"]], ["operation"], [["Kid Brands-1"]], ["operation"], ["operation"]], [[["Fiat S.p.A.-1"]], [["Fiat Chrysler Automobiles-1"]], [["Fiat S.p.A.-3"]], ["no_evidence"], ["no_evidence"]]]}
{"qid": "748150aac686d4aac256", "term": "Panthéon", "description": "mausoleum in Paris", "question": "Does Pantheon in Paris have a unique name?", "answer": false, "facts": ["The Pantheon in Paris is a historical monument.", "The Pantheon was a former Roman temple in antiquity.", "The Pantheon is a mythical or imaginary creature used in heraldry, particularly in Britain often depicted as white deer with the tail of a fox with purple stars along their back."], "decomposition": ["What is referred to as the Pantheon in Paris?", "What other concepts are named Pantheon?", "Is #1 differently-named from #2?"], "evidence": [[[["Panthéon-1"]], [["Pantheon, Rome-1"]], ["operation"]], [[["Panthéon-1"]], [["Pantheon (mythical creature)-1", "Pantheon (religion)-1", "Pantheon (software)-1"]], ["operation"]], [[["Panthéon-1"]], [["Pantheon (religion)-1", "Pantheon, Rome-1"]], ["operation"]]]}
{"qid": "9eb2815f7551d7ea8b25", "term": "Lexus", "description": "luxury vehicle division of Toyota", "question": "Did George Washington drive a Lexus?", "answer": false, "facts": ["Lexus was established in 1989", "George Washington died in 1799"], "decomposition": ["In what year did George Washington die?", "What year was Lexus founded in?", "Is #1 after #2?"], "evidence": [[[["George Washington-1"]], [["Lexus-2"]], ["operation"]], [[["George Washington-1"]], [["Lexus-2"]], ["operation"]], [[["George Washington-121"]], [["Lexus-16"]], ["operation"]]]}
{"qid": "60e2540a5e07213eeca1", "term": "Pancake", "description": "Thin, round cake made of eggs, milk and flour", "question": "Are pancakes typically prepared in a pot?", "answer": false, "facts": ["Pancakes are usually fried on a shallow flat surface.", "Pots typically have high walls.", "Griddles and skillets are low, shallow flat pans appropriate for pancakes."], "decomposition": ["What kind of surface are pancakes usually made on?", "Does a pot have #1?"], "evidence": [[[["Pancake-1", "Pancake-57"], "no_evidence"], [["Cookware and bakeware-52"], "operation"]], [[["Pancake-1"]], [["Pancake-1"]]], [[["Pancake-1"]], [["Cookware and bakeware-4"], "operation"]]]}
{"qid": "ee757afd1a9e0e96cbc7", "term": "Sable", "description": "Species of marten", "question": "Are Sable's a good choice of Mustelidae to weigh down a scale?", "answer": false, "facts": ["Mustelidae is the scientific designation for animals that share similarities including polecats, sables, and ferrets.", "Polecats weigh between 2.2 and 3.3 pounds.", "Sable's weigh around 2.4 pounds.", "Ferrets can weigh up to 44 pounds.", "Sable's have sharp teeth and a painful bite and are outlawed in many states."], "decomposition": ["How much does a sable weigh?", "What are the weights of other common members of Mustelidae?", "Is #1 greater than all #2?"], "evidence": [[[["Sable-4"]], [["Mustelidae-2"]], ["operation"]], [[["Sable-4"]], [["Mustelidae-2"], "no_evidence"], ["operation"]], [[["Sable-4"], "operation"], [["Mustelidae-4"], "no_evidence"], ["no_evidence"]]]}
{"qid": "0a8bb20dbdb99d68127e", "term": "Clove", "description": "species of plant", "question": "Do people who smoke Djarum's like cloves?", "answer": true, "facts": ["Djarum is a brand of cigarette popular around the world.", "Djarum cigarettes are made with a blend of cloves and tobacco."], "decomposition": ["What are Djarum cigarettes made of?", "Does #1 include cloves?"], "evidence": [[[["Djarum-1"]], ["operation"]], [[["Djarum-1"]], ["operation"]], [[["Djarum-1", "Kretek-1"]], ["operation"]]]}
{"qid": "265dd54c248f8b048851", "term": "Rede Globo", "description": "Brazilian commercial television network", "question": "Do the anchors on Rede Globo speak Chinese?", "answer": false, "facts": ["Rede Globo is a Brazilian television network.", "The official language of Brazil is Portuguese."], "decomposition": ["What country broadcasts Rede Globo?", "What is the official language of #1?", "Is #2 Chinese?"], "evidence": [[[["Rede Globo-1"]], [["Brazil-1"]], ["operation"]], [[["Rede Globo-1"]], [["Brazil-1"]], ["operation"]], [[["Rede Globo-1"]], [["Portuguese language-1"]], ["operation"]]]}
{"qid": "6a756a5734139bfce297", "term": "Emu", "description": "Large flightless bird endemic to Australia", "question": "Can an emu chase a bogan?", "answer": true, "facts": ["Emus are endemic to the continent of Australia", "Bogan is a pejorative term for certain citizens of Australia"], "decomposition": ["Where are emus endemic to?", "Where is a \"bogan\" found?", "Do areas #1 and #2 overlap?"], "evidence": [[[["Emu-1"]], [["Bogan-2"]], ["operation"]], [[["Emu-1"]], [["Bogan-25"]], ["operation"]], [[["Emu-1"]], [["Bogan-1"]], ["operation"]]]}
{"qid": "f7d66ea2a1fcc7473f48", "term": "Bengal cat", "description": "Breed of cat", "question": "Can a Bengal cat survive eating only pancakes?", "answer": false, "facts": ["Bengal cats are carnivores.", "Pancakes contain no meat.", "Carnivores eat only meat to survive. "], "decomposition": ["What type of diet does a Bengal cats follow?", "What do #1 mainly eat?", "Do pancakes contain #2?"], "evidence": [[[["Bengal cat-1"]], [["Cat food-9"]], ["operation"]], [[["Bengal cat-1", "Cat-1"]], [["Carnivore-1"]], [["Pancake-1"], "operation"]], [[["Bengal cat-1", "Carnivore-7"]], [["Carnivore-7"]], [["Pancake-1"]]]]}
{"qid": "d8ef42c2c54f93d5eb78", "term": "Strawberry", "description": "edible fruit", "question": "Would an owl monkey enjoy a strawberry?", "answer": true, "facts": ["Owl monkeys are frugivores, and they prefer small, ripe fruit when available.", "Strawberries vary in size but are generally under 2 inches across and an inch in diameter.", "Strawberries are a kind of fruit."], "decomposition": ["What food group does an owl monkey's diet mainly consist of?", "Is a strawberry a #1?"], "evidence": [[[["Night monkey-8"]], [["Strawberry-1"]]], [[["Night monkey-8"]], [["Strawberry-1"]]], [[["Night monkey-1", "Night monkey-8"]], [["Strawberry-1"]]]]}
{"qid": "66a3c0af3141c7c7d215", "term": "QWERTY", "description": "keyboard layout where the first line is \"QWERTYUIOP\"", "question": "Can monkeys use QWERTY keyboards?", "answer": true, "facts": ["QWERTY keyboards are an alphabet key layout that were first used on typrwriters. ", "Monkeys can be trained to push buttons.", "Typewriter key's are buttons.", "Monkeys can press keys on keyboards."], "decomposition": ["What kind of keys are found on QWERTY keyboards?", "Can #1 be likened to buttons?", "Can monkeys be trained to push buttons?", "Are #2 and #3 positive?"], "evidence": [[[["QWERTY-17"]], ["operation"], ["no_evidence", "operation"], ["no_evidence", "operation"]], [[["QWERTY-12"]], [["Keyboard layout-3"]], [["Pet monkey-4"]], ["operation"]], [[["QWERTY-16", "QWERTY-17"]], [["Push-button-1"], "no_evidence"], [["Tool use by animals-21"], "no_evidence"], ["operation"]]]}
{"qid": "67c5305550f1612a2f49", "term": "Rahul Dravid", "description": "Indian cricketer", "question": "Is it hard for Rahul Dravid to order food at a restaurant in Aurangabad?", "answer": false, "facts": ["Aurangabad is located in Maharashtra.", "Marathi is an Indo-Aryan language spoken predominantly by around 100 million Marathi people of Maharashtra, India.", "Rahul Dravid is fluent in Marathi."], "decomposition": ["What languages can Rahul Dravid speak fluently?", "In which state is Aurangabad located?", "What is the official language of #2?", "Is #1 exclusive of #3?"], "evidence": [[[["Rahul Dravid-9"]], [["Aurangabad-1"]], [["Maharashtra-2"]], ["operation"]], [[["Rahul Dravid-9"]], [["Aurangabad-1"]], [["Marathi language-1"]], ["operation"]], [[["Rahul Dravid-9"]], [["Aurangabad district, Maharashtra-1"]], [["Maharashtra-2"]], ["operation"]]]}
{"qid": "613f8af5655a31bda1a5", "term": "Bluetooth", "description": "Short distance wireless technology standard", "question": "Does a dentist treat Bluetooth problems?", "answer": false, "facts": ["A dentist is a surgeon who specializes in dentistry, the diagnosis, prevention, and treatment of diseases and conditions of the oral cavity.", "Technological problems are typically handled by IT professionals.", "Bluetooth is not a physical entity."], "decomposition": ["What type of professional would handle bluetooth problems?", "Are dentists trained in #1?"], "evidence": [[[["Bluetooth-1", "Computer repair technician-1"], "no_evidence"], [["Dentist-1"], "operation"]], [[["Technical support-3"]], [["Dentist-1"]]], [[["Bluetooth-1"], "no_evidence"], [["Dentist-1"]]]]}
{"qid": "1515242f123df1362ad7", "term": "Elk", "description": "Large antlered species of deer from North America and east Asia", "question": "Would a body builder prefer an elk burger over a beef burger?", "answer": true, "facts": ["Bodybuilders want to build muscle and keep fat low", "Elk meat is leaner than beef", "Elk meat has higher protein than beef", "Protein helps build muscle"], "decomposition": ["Which nutrients are more important for a body builder's diet?", "How is an elk burger different from a beef burger in terms of nutrients?", "Considering #1 and #2 would an elk burger be a better source of #1?"], "evidence": [[[["Bodybuilding-31", "Bodybuilding-41"]], [["Elk-3"]], [["Bodybuilding-31", "Elk-3"]]], [[["Bodybuilding-41"]], [["Elk-3"]], ["operation"]], [[["Bodybuilding-39"]], [["Elk-3"]], [["Elk-3"], "operation"]]]}
{"qid": "7bb579fa94d5f0d58ae1", "term": "Blues", "description": "Musical form and music genre", "question": "Were Depeche Mode heavily influenced by blues music?", "answer": false, "facts": ["Blues incorporated spirituals, work songs, field hollers, shouts, chants, and rhymed simple narrative ballads and was derived from African-Americans.", "Blues music uses instruments like slide guitar, harmonica, piano, and bass drums.", "Depeche Mode are a British pop synth group.", "Depeche Mode uses computer synthesizers to create their unique sound as well as heavy rock guitars.", "Depeche Mode was influenced by The Cure, and Ultravox, new wave rock bands."], "decomposition": ["What kind of songs and instruments are associated with Blues?", "What kind of musical instruments does the Depeche Mode use to create music?", "Is #2 very similar to #1?"], "evidence": [[[["Blues-37"]], [["Depeche Mode-35"]], ["operation"]], [[["Blues-1"]], [["Depeche Mode-1"]], ["operation"]], [[["Blues-1"], "no_evidence"], [["Depeche Mode-6"]], ["operation"]]]}
{"qid": "1675495e9a3ed30329bd", "term": "Rabbi", "description": "teacher of Torah in Judaism", "question": "Would a rabbi worship martyrs Ranavalona I killed?", "answer": false, "facts": ["Rabbis are teachers of Judaism.", "Ranavalona I, ruler of Madagascar, killed many Christians that were later determined by the church to be martyrs.", "Judaism does not have a group of saints and martyrs that are prayed to like Christianity.."], "decomposition": ["Which religion are rabbis teachers of?", "Which religion were the matyrs killed by Ranavalona I adherents of?", "Do adherent of #1 worship matyrs like those of #2?"], "evidence": [[[["Rabbi-1"]], [["Christianity in Madagascar-13"]], ["operation"]], [[["Rabbi-1"]], [["Christianity in Madagascar-13"]], ["operation"]], [[["Rabbi-1"]], [["Christianity in Madagascar-13"]], ["no_evidence"]]]}
{"qid": "3e70c2ee8dd1ed87cc09", "term": "Kidney", "description": "internal organ in most animals, including vertebrates and some invertebrates", "question": "Does an organ donor need to be dead to donate a kidney?", "answer": false, "facts": ["The average human has two kidneys.", "Only one kidney is required to function as a healthy person.", "Living organ donors will sometimes donate their spare kidney to someone experiencing failure of both their kidneys."], "decomposition": ["How many kidneys does the average person have?", "How many kidneys does a person require to function?", "Is #1 the same as #2?"], "evidence": [[[["Kidney-1"]], [["Kidney-33"]], ["operation"]], [[["Kidney-1"]], [["Organ donation-3"], "no_evidence"], ["no_evidence", "operation"]], [[["Kidney-1"]], [["Kidney-33"]], ["operation"]]]}
{"qid": "833413ca3a67a6d1c572", "term": "Garfield", "description": "Comic strip created by Jim Davis", "question": "Is Garfield known for hating italian cuisine?", "answer": false, "facts": ["Garfield is well known for loving lasagna.", "Lasagna is a traditional Italian dish."], "decomposition": ["What food is Garfield known for loving?", "What country does #1 come from?", "Is #2 where Italian cuisine comes from?"], "evidence": [[[["Garfield (character)-2"]], [["Lasagne-4"]], [["Lasagne-2"]]], [[["Garfield-2"]], [["Lasagne-3"]], [["Italian cuisine-1"]]], [[["Garfield (character)-1"]], [["Garfield (character)-2"], "no_evidence"], ["operation"]]]}
{"qid": "598be3dcddbd7775a827", "term": "Bob Marley", "description": "Jamaican singer-songwriter", "question": "Could Bob Marley's children hypothetically win tug of war against Kublai Khan's children?", "answer": false, "facts": ["Bob Marley had 9 children.", "Kublai Khan had 23 children.", "Many of Bob Marley's children became singers, and followed his themes of peace and love.", "The children of Kublai Khan followed in his footsteps and were fierce warlords."], "decomposition": ["How many children did Bob Marley have?", "How many children did Kublai Khan have?", "Is #1 greater than #2?"], "evidence": [[[["Bob Marley-42"]], [["Kublai Khan-71", "Toghon (son of Kublai)-1"], "no_evidence"], ["no_evidence", "operation"]], [[["Bob Marley-42"]], [["Kublai Khan-71", "Kublai Khan-76"], "no_evidence"], ["operation"]], [[["Bob Marley-42"]], [["Kublai Khan-76"]], ["operation"]]]}
{"qid": "d439d1a70c443691145d", "term": "Daytona 500", "description": "Auto race held in Daytona, Florida, United States", "question": "Will electric car struggle to finish Daytona 500?", "answer": true, "facts": ["The Daytona 500 is a 2.5 mile long race.", "The Daytona 500 requires 200 laps to complete.", "The best electric car engines last around 390 miles."], "decomposition": ["How long (in miles) is the Daytona 500 race?", "What is the maximum electric range (in miles) of the world's best selling electric car?", "Is #2 less than #1?"], "evidence": [[[["Daytona 500-1"]], [["Tesla Model 3-1"]], ["operation"]], [[["Daytona 500-7"]], [["Electric car-20"]], ["operation"]], [[["Daytona 500-7"]], [["Electric car-3"]], ["operation"]]]}
{"qid": "cac0fdde384da0c11524", "term": "Royal Society", "description": "National academy of science in the United Kingdom", "question": "Can numerologists become members of Royal Society?", "answer": false, "facts": ["The royal society fulfills a number of roles: promoting science and its benefits, recognizing excellence in science, supporting outstanding science, providing scientific advice for policy.", "Numerology is a superstition and a pseudoscience that uses numbers to give the subject a veneer of scientific authority."], "decomposition": ["What is the primary basis for being selected as a member of the Royal Society?", "What do numerologists do?", "Is #2 included in #1?"], "evidence": [[[["Royal Society-24"]], [["Numerology-3"]], ["operation"]], [[["Royal Society-24"]], [["Numerology-1"]], ["operation"]], [[["Royal Society-17"]], [["Numerology-3"]], ["operation"]]]}
{"qid": "27368c21e50b6af694ab", "term": "Ethics", "description": "branch of philosophy that systematizes, defends, and recommends concepts of right and wrong conduct", "question": "Would an ethics professor teach a class on Cezanne?", "answer": false, "facts": ["Cezanne was an Impressionist painter", "Aesthetics is the branch of philosophy that deals with the arts"], "decomposition": ["What was Cezanne known for?", "What branch of philosophy would deal with #1?", "Is #2 the same as ethics? "], "evidence": [[[["Paul Cézanne-1"]], [["Paul Cézanne-33"], "no_evidence"], [["Ethics-1"], "operation"]], [[["Paul Cézanne-1"]], [["Aesthetics-1"]], [["Ethics-1"], "operation"]], [[["Paul Cézanne-1"]], [["Paul Cézanne-33"]], ["operation"]]]}
{"qid": "0688bd3291c81ffcfea1", "term": "Radioactive waste", "description": "wastes that contain nuclear material", "question": "Does the United States Navy create radioactive waste?", "answer": true, "facts": ["Radioactive waste is created by nuclear material processing", "The United States Navy uses many nuclear submarines"], "decomposition": ["Radioactive waste is a byproduct of what process?", "Does the US Navy engage in any of the activities in #1?"], "evidence": [[[["Radioactive waste-1"]], [["Nuclear submarine-4"]]], [[["Radioactive waste-1"]], [["United States Navy Nuclear Propulsion-1"], "operation"]], [[["Radioactive waste-1"]], [["United States Navy-5"], "no_evidence", "operation"]]]}
{"qid": "409f6134b00905dba32c", "term": "Paralympic Games", "description": "Major international sport event for people with disabilities", "question": "Can Josh Blue participate in Paralympics Games? ", "answer": true, "facts": ["Josh Blue has cerebral palsy. ", "People with cerebral palsy can compete in the Paralympic Games."], "decomposition": ["What chronic illness does Josh Blue have?", "What conditions make one eligible to compete in the Paralympic Games?", "Is #1 included in #2?"], "evidence": [[[["Josh Blue-1"]], [["Paralympic Games-4"]], [["Ataxia-1", "Cerebral palsy-1"], "operation"]], [[["Josh Blue-4"], "no_evidence"], [["Paralympic Games-40"], "no_evidence"], ["no_evidence"]], [[["Josh Blue-1"]], [["Paralympic Games-1", "Paralympic Games-40"], "no_evidence"], ["operation"]]]}
{"qid": "089b0eb6cdf0fe53a863", "term": "Scottish people", "description": "ethnic inhabitants of Scotland", "question": "Are Scottish people descended from Mary, Queen of Scots part French?", "answer": true, "facts": ["Mary, Queen of Scots was Queen of Scotland in the 1500s.", "Mary, Queen of Scots was the daughter of Mary of Guise.", "Mary of Guise was born to a French nobleman, and her mother was French as well."], "decomposition": ["Who was the mother of Mary, Queen of Scots?", "Who were the parents of #1?", "Were #2 French?"], "evidence": [[[["Mary of Guise-1"]], [["Antoinette de Bourbon-1", "Claude, Duke of Guise-1"]], ["operation"]], [[["Mary, Queen of Scots-5"]], [["Mary of Guise-2"]], [["Claude, Duke of Guise-1"], "operation"]], [[["Mary, Queen of Scots-5"]], [["Mary of Guise-2"]], [["Antoinette de Bourbon-1", "Claude, Duke of Guise-1"]]]]}
{"qid": "c426b03932f052ae91af", "term": "Moon Jae-in", "description": "President of South Korea", "question": "Was Moon Jae-in born outside of Khanbaliq?", "answer": true, "facts": ["Khanbaliq was the winter capital of the Mongol Empire. ", "Khanbaliq was located at the center of what is now modern day Beijing, China.", "Moon Jae-In was born in Geoje, South Korea."], "decomposition": ["Where was Moon Jae-in born?", "What is the modern day location of Khanbaliq?", "Is #1 different from #2?"], "evidence": [[[["Moon Jae-in-5"]], [["Khanbaliq-1"]], ["operation"]], [[["Moon Jae-in-2"]], [["Khanbaliq-1"]], ["operation"]], [[["Moon Jae-in-5"]], [["Khanbaliq-1"]], ["operation"]]]}
{"qid": "b3c8f537cfb900ba92e5", "term": "Salsa (sauce)", "description": "Sauce", "question": "Would the chef at La Grenouille find salsa to be a strange request?", "answer": true, "facts": ["La Grenouille is a classic French cuisine restaurant in NYC.", "Salsa is a staple food in Mexican cuisine."], "decomposition": ["What type of cuisine does La Grenouille serve?", "Would you typically find salsa in #1?"], "evidence": [[[["La Grenouille (restaurant)-3"], "operation"], ["no_evidence"]], [[["La Grenouille (restaurant)-1"]], [["Mexican cuisine-28"]]], [[["La Grenouille (restaurant)-3"]], [["La Grenouille (restaurant)-1", "Salsa-1"]]]]}
{"qid": "69ccc55206ac47a0d312", "term": "Seinfeld", "description": "American sitcom", "question": "Could you watch a new Seinfeld episode every day for a year?", "answer": false, "facts": ["There are 365 days in a year.", "There are a total of 180 Seinfeld episodes."], "decomposition": ["How many days are there in a year?", "How many Seinfeld episodes are there?", "Is #2 greater than or equal to #1?"], "evidence": [[[["Seinfeld-31"]], [["Year-3"]], ["operation"]], [[["Seinfeld-1"]], [["Year-4"]], ["operation"]], [[["Year-3"]], ["no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "f353cbd3286ea1e452aa", "term": "Telescope", "description": "Optical instrument that makes distant objects appear magnified", "question": "Can telescopes hear noise?", "answer": false, "facts": ["Telescopes are used to view things far away.", "Telescopes are an optical instrument. "], "decomposition": ["What are the uses of a telescope?", "Does #1 include detecting noise?"], "evidence": [[[["Telescope-1"]], ["operation"]], [[["Telescope-5"]], [["Telescope-5"]]], [[["Telescope-1"]], [["Telescope-1"], "operation"]]]}
{"qid": "d2af3c2b2eee3ce311ea", "term": "Organ transplantation", "description": "moving of an organ from one body or body region to another", "question": "Can a carrot receive an organ transplant?", "answer": false, "facts": ["Organs are groups of tissues that perform a similar function.", "The whole of a carrot is a root.", "A root is a plant organ.", "You cannot transplant the entire carrot into another carrot."], "decomposition": ["What part of the plant is the carrot?", "Does #1 have organs?"], "evidence": [[[["Carrot-1"]], [["Organ (anatomy)-1", "Taproot-1"]]], [[["Carrot-1"]], ["operation"]], [[["Carrot-1"]], ["operation"]]]}
{"qid": "c2c6e32ccdd81e5df7f6", "term": "Paralympic Games", "description": "Major international sport event for people with disabilities", "question": "Would Jimmy Vee be eligible to compete in the Paralympic Games?", "answer": true, "facts": ["Jimmy Vee is a dwarf.", "Dwarfism is defined as someone who is medically short-statured.", "Short stature due to a bone deficiency is one of the categories for paralympic athletes."], "decomposition": ["What disability does Jimmy Vee suffer from?", "What is the medical definition of #1?", "Is #2 one of the categories for the paralympic athletes?"], "evidence": [[[["Jimmy Vee-5"]], [["Dwarfism-1"]], [["Paralympic Games-1"]]], [[["Jimmy Vee-5"]], [["Dwarfism-2"]], [["Paralympic Games-42"], "operation"]], [[["Jimmy Vee-5"]], [["Dwarfism-1"]], [["Paralympic Games-4"]]]]}
{"qid": "6e939983f45cfcba8caa", "term": "Jean-Paul Sartre", "description": "French existentialist philosopher, playwright, novelist, screenwriter, political activist, biographer, and literary critic", "question": "Did Sartre write a play about Hell?", "answer": true, "facts": ["In 1944, Sartre released No Exit.", "No Exit is a play about three people mysteriously locked in a room together.", "Late in the play, it is revealed the room is a version of Hell."], "decomposition": ["What is Jean-Paul Sartre's most famous play?", "What is the plot of #1?", "Is Hell a critical element of #2?"], "evidence": [[[["No Exit-1"]], [["No Exit-3"], "no_evidence"], ["operation"]], [[["No Exit-1"]], [["No Exit-3"]], ["operation"]], [[["Jean-Paul Sartre-62"]], [["No Exit-3"]], [["No Exit-3"]]]]}
{"qid": "5e2d9519c7c521411817", "term": "Pizza", "description": "Usually savory dish of flattened bread and toppings", "question": "Would a TMNT coloring book have pizza in it?", "answer": true, "facts": ["TMNT is an abbreviation for 'Teenage Mutant Ninja Turtles'.", "The Teenage Mutant Ninja Turtles canonically only ever ate pizza in the animated series. "], "decomposition": ["What cartoon does TMNT stand for?", "In the animated series, did #1 canonically eat only pizza?"], "evidence": [[[["Teenage Mutant Ninja Turtles-1"]], [["Teenage Mutant Ninja Turtles-9"], "operation"]], [[["Teenage Mutant Ninja Turtles-1"]], [["Teenage Mutant Ninja Turtles-19"], "operation"]], [[["Teenage Mutant Ninja Turtles-1"]], [["Teenage Mutant Ninja Turtles-19"]]]]}
{"qid": "4a0e604f174af36e3ace", "term": "Globalization", "description": "process of international integration arising from the interchange of world views, products, ideas, and other aspects of culture", "question": "Are System of a Down opposed to globalization?", "answer": true, "facts": ["In Boom!, System of a Down condemns globalization.", "The lead vocalist of the band System of a Down is outspoken against globalization. "], "decomposition": ["What is globalization?", "Is the lead vocalist of the band System of a Down against #1?"], "evidence": [[[["Globalization-1"]], [["Serj Tankian-38"], "no_evidence", "operation"]], [[["Globalization-1"]], [["Serj Tankian-1", "Serj Tankian-16"], "no_evidence", "operation"]], [[["Globalization-1"]], [["System of a Down-32"]]]]}
{"qid": "17fc5cdda68b55351597", "term": "Amy Winehouse", "description": "English singer and songwriter", "question": "Would Amy Winehouse's death have been prevented with Narcan?", "answer": false, "facts": ["Narcan is a medication that save the life of someone overdosing on opiates.", "Amy Winehouse died from alcohol poisoning.", "Narcan cannot work on alcohol overdoses."], "decomposition": ["What was the cause of Amy Winehouse's death?", "What are the indications/symptoms that can be treated with Narcan?", "Is #1 included in #2?"], "evidence": [[[["Amy Winehouse-4"]], [["Naloxone-1"]], ["operation"]], [[["Amy Winehouse-92"]], [["Naloxone-4", "Naloxone-7"]], ["operation"]], [[["Amy Winehouse-92"]], [["Naloxone-1"]], ["operation"]]]}
{"qid": "e4a065a8ea3691b12e6f", "term": "Bulk carrier", "description": "merchant ship specially designed to transport unpackaged bulk cargo", "question": "Is the average bulk carrier ideal for transporting bromine at room temperature?", "answer": false, "facts": ["Bulk carriers are defined as a ship that carries nonliquid cargoes such as grain or ore in bulk.", "Bromine is a liquid at room temperature.", "The average bulk carrier is used for unpackaged bulk cargo, such as grains, coal, ore, steel coils and cement."], "decomposition": ["What are the kinds of cargo that a typical bulk carrier can transport?", "What kind of substance is bromine at room temperature?", "Can any of #1 be classified as #2?"], "evidence": [[[["Bulk carrier-1"]], [["Bromine-1"]], ["operation"]], [[["Bulk carrier-4"], "operation"], [["Bromine-26"]], ["no_evidence"]], [[["Bulk carrier-1"]], [["Bromine-1"]], ["operation"]]]}
{"qid": "fabf020bf07e0445c50c", "term": "Sea shanty", "description": "work song sung to accompany labor on board large merchant sailing vessels", "question": "Does Jack Sparrow know any sea shantys?", "answer": true, "facts": ["Jack Sparrow is the main character of the popular 'Pirates of the Caribbean' movie franchise.", "Jack Sparrow is the captain of a pirate ship.", "Jack Sparrow sings many songs while on the sea."], "decomposition": ["Which movie is Jack Sparrow a main character in?", "Which activity is associated with singing of sea shantys?", "As portrayed in #1, is Jack Sparrow in a position to engage in #2?"], "evidence": [[[["Jack Sparrow-1"]], [["Sea shanty-1"]], ["operation"]], [[["Jack Sparrow-1"]], [["Sea shanty-119"]], [["Sea shanty-119"]]], [[["Jack Sparrow-1"]], [["Sea shanty-39", "Sea shanty-4"]], [["Jack Sparrow-1"]]]]}
{"qid": "3bd6c0cff096123cc207", "term": "Will Ferrell", "description": "American actor, comedian, producer, writer and businessman", "question": "Does Dean Cain have less days to birthday than Will Ferrell every 4th of July?", "answer": false, "facts": ["Will Ferrell was born on July 16th.", "Dean Cain was born on July 31st."], "decomposition": ["What day of the year was Will Ferrell born?", "What day of the year was Dean Cain born?", "How many days away from July fourth is #1?", "How many days away from July fourth is #2?", "Is #4 less than #3?"], "evidence": [[[["Will Ferrell-1"]], [["Dean Cain-1"]], ["operation"], ["operation"], ["operation"]], [[["Will Ferrell-1"]], [["Dean Cain-1"]], ["operation"], ["operation"], ["operation"]], [[["Will Ferrell-1"]], [["Dean Cain-1"]], ["operation"], ["operation"], ["operation"]]]}
{"qid": "b978c4051673fd21035b", "term": "Aldi", "description": "Germany-based supermarket chain", "question": "Are Aldi's foods discounted due to being out of date?", "answer": false, "facts": ["Aldi cuts costs by charging for bags, buying in bulk, and by avoiding brand name items. ", "Aldi removes spoiled or expired foods from their shelves immediately upon identification."], "decomposition": ["How does Aldi cut cost?", "Is selling discounted food part of #1?"], "evidence": [[[["Aldi-33"]], [["Aldi-25", "Aldi-27"], "operation"]], [[["Aldi-5"]], ["operation"]], [[["Aldi-27"]], [["Aldi-27"]]]]}
{"qid": "98f8a80a3a83d0951176", "term": "Curiosity (rover)", "description": "American robotic rover exploring the crater Gale on Mars", "question": "Can Curiosity (rover) kill a cat?", "answer": true, "facts": ["Cats weigh on average between 7 to 10 pounds.", "Curiosity (rover), a space vehicle that explores Mars, weighs 1,982 pounds.", "As mass falls, it picks up acceleration and adds to the force of impact."], "decomposition": ["How much does a cat weigh?", "How much does Curiosity (rover) weigh?", "Is #2 more than #1?"], "evidence": [[[["Cat-28"], "no_evidence"], [["Curiosity (rover)-33"]], ["operation"]], [[["Cat-29"]], [["Curiosity (rover)-33"]], ["operation"]], [[["Meow (cat)-2"], "no_evidence"], [["Curiosity (rover)-6"], "no_evidence"], ["operation"]]]}
{"qid": "3b62e4e18ce9ec7015c0", "term": "Citrus", "description": "genus of fruit-bearing plants (source of fruit such as lemons and oranges)", "question": "Can citrus grow in Ulaanbaatar?", "answer": false, "facts": ["Citrus can withstand short periods down to as cold as −10 °C (14 °F), but realistically temperatures not falling below −2 °C (28 °F) are required for successful cultivation.", "Ulaanbaatar has an average annual temperature of −0.4 °C or 31.3 °F."], "decomposition": ["What climates are suitable for growing citrus?", "What is the climate of Ulaanbaatar?", "Is #2 similar to #1?"], "evidence": [[[["Citrus-34"]], [["Ulaanbaatar-39"]], [["Citrus-34"]]], [[["Citrus-26", "Citrus-31"]], [["Ulaanbaatar-39"]], ["operation"]], [[["Citrus-31"]], [["Ulaanbaatar-40"]], ["operation"]]]}
{"qid": "e43424acbaf3f64feefd", "term": "Brazilian Navy", "description": "Naval warfare branch of Brazil's military forces", "question": "Are some Brazilian Navy ships built in Britian?", "answer": true, "facts": ["The Brazilian Navy stated in 2018 that they had purchased the helicopter carrier ship HMS Ocean.", "HMS stands for \"His/Her Majesty's Ship\", which is emblazoned on ships of the British Royal Navy. ", "Some of the ships in the Brazilian Navy are guided missile frigates built in Britian."], "decomposition": ["Which helicopter carrier ship did the Brazilian Navy announce that they had acquired in 2018?", "Was #1 built in Britain?"], "evidence": [[[["Brazilian Navy-62"]], [["HMS Ocean (L12)-1"]]], [[["HMS Ocean (L12)-2"]], [["HMS Ocean-1"]]], [[["Aircraft carrier-43"]], ["operation"]]]}
{"qid": "669b3c6a48f494a5d74e", "term": "Kurt Cobain", "description": "American singer, composer, and musician", "question": "Was Kurt Cobain's death indirectly caused by Daniel LeFever?", "answer": true, "facts": ["Kurt Cobain committed suicide with a shotgun.", "Daniel LeFever was the inventor of the American hammerless shotgun."], "decomposition": ["What object caused the death of Kurt Cobain?", "Was #1 invented by Daniel LeFever?"], "evidence": [[[["Suicide of Kurt Cobain-1"]], ["operation"]], [[["Kurt Cobain-3"]], [["Daniel Myron LeFever-1"]]], [[["Kurt Cobain-55"]], [["Shotgun-38"]]]]}
{"qid": "5170cfed313d2de67942", "term": "The Tonight Show Starring Jimmy Fallon", "description": "American late-night talk show", "question": "On August 20, 2020,  does The Tonight Show Starring Jimmy Fallon air after moonset EST?", "answer": true, "facts": ["On August 20th, The Tonight Show Starring Jimmy Fallon airs at 11:35PM", "On August 20th, the moon on the east coast of the USA will set around 9PM"], "decomposition": ["The Tonight Show Starring Jimmy Fallon airs at 11:35 p.m. ET/PT.", "On August 20th, the moon on the east coast of the USA  set 9PM", "Does #1 occur after #2?"], "evidence": [[[["The Tonight Show Starring Jimmy Fallon-2"]], [["Moonlight-1", "Sunset-1"], "no_evidence"], ["operation"]], [[["The Tonight Show Starring Jimmy Fallon-2"]], [["Lunar phase-16"]], [["Lunar phase-16", "The Tonight Show Starring Jimmy Fallon-2"], "no_evidence"]], [[["The Tonight Show-30"], "no_evidence"], [["Moonrise-1"], "no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "bcf47774877e8bdd07a4", "term": "Warsaw Ghetto", "description": "Ghetto in Nazi occupied Poland", "question": "Did the population of the Warsaw Ghetto record secret police on cell phones?", "answer": false, "facts": ["The Warsaw Ghetto existed during the second world war.", "Cell phones with video recording capability did not exist until the 2000s."], "decomposition": ["When was the Warsaw Ghetto in existence?", "When was the first cell phone capable of recording developed?", "Is #2 before the end of #1?"], "evidence": [[[["Warsaw Ghetto-6"]], [["Digital electronics-11"]], [["Digital electronics-11", "Warsaw Ghetto-6"], "operation"]], [[["Warsaw Ghetto-1"]], [["Camera phone-22"]], ["operation"]], [[["Warsaw Ghetto-3"]], [["Mobile phone-4"]], [["Mobile phone-4"], "operation"]]]}
{"qid": "03c467f12c3fcc1d91fe", "term": "Clouded leopard", "description": "species of mammal found from the Himalayan foothills through mainland Southeast Asia into China", "question": "Can Clouded leopards chase down many Pronghorn antelopes?", "answer": false, "facts": ["The top speed of a Clouded leopard is 40 MPH.", "The top speed of a Pronghorn antelope is 61 MPH."], "decomposition": ["What is the top speed for a Clouded leopard ?", "What is the top speed for a Pronghorn antelope ?", "Is #1 greater then or equal to #2?"], "evidence": [[[["Clouded leopard-31"], "no_evidence"], [["Pronghorn-12"]], ["operation"]], [["no_evidence"], [["Pronghorn-12"]], ["operation"]], [[["Leopard-4"], "no_evidence"], [["Pronghorn-12"]], ["operation"]]]}
{"qid": "72e87f1268a08de8f84d", "term": "Aloe", "description": "genus of plants", "question": "Do all parts of the aloe vera plant taste good?", "answer": false, "facts": ["There is a layer of yellow latex liquid between the outside of an aloe leaf and the gel inside.", "The latex inside aloe tastes very bitter."], "decomposition": ["How do the various parts of the Aloe vera taste?", "Is all of #1 pleasant?"], "evidence": [[[["Aloe vera-1"], "no_evidence"], [["Aloe vera-16"], "no_evidence", "operation"]], [[["Aloe vera-21"], "no_evidence"], ["operation"]], [[["Aloe vera-17"], "no_evidence"], [["Aloe vera-21"], "no_evidence", "operation"]]]}
{"qid": "4f08d9a0fba58ad9ca73", "term": "Taco Bell", "description": "American fast-food chain", "question": "Will more people go in and out of Taco Bell than a Roy Rogers each year?", "answer": true, "facts": ["Taco Bell has over 7,072 restaurants as of 2018.", "Roy Rogers had over 600 restaurants at its peak.", "Roy Rogers has 48 locations as of 2019."], "decomposition": ["How many restaurants does Taco Bell have?", "How many restaurants does Roy Rogers have?", "Is #1 significantly greater than #2?"], "evidence": [[[["Taco Bell-1"]], [["Roy Rogers Restaurants-1"]], ["operation"]], [["no_evidence"], [["Roy Rogers Restaurants-1"]], ["operation"]], [["no_evidence"], [["Roy Rogers Restaurants-1"]], ["no_evidence", "operation"]]]}
{"qid": "881286dcdded13a96e3b", "term": "Bob Marley", "description": "Jamaican singer-songwriter", "question": "Can you find Bob Marley's face in most smoke shops?", "answer": true, "facts": ["Bob Marley's face is on the packaging of a popular brand of rolling papers.", "Bob Marley is a popular graphic to print on t-shirts for sale to smokers."], "decomposition": ["Where can one find Bob Marley's face printed on?", "Are any items from #1 commonly found in smoke shops?"], "evidence": [[[["Bob Marley-1"], "no_evidence"], [["Head shop-1", "Head shop-2"], "no_evidence", "operation"]], [[["Marley Natural-2"]], ["operation"]], [[["Bob Marley-48"]], ["operation"]]]}
{"qid": "691c8df42c886d6db9d4", "term": "John the Baptist", "description": "1st-century Jewish preacher and later Christian saint", "question": "Would John the Baptist be invited to a hypothetical cephalophore reunion in heaven?", "answer": false, "facts": ["John the Baptist was a preacher that became a Catholic Saint.", "John the Baptist was beheaded by king Herod.", "A cephalophore is a Saint martyred by beheading, and is depicted in art as carrying their own head.", "Saint Denis was one of several beheaded saints that is said to have carried his own head and is depicted as such in art.", "John the Baptist did not carry his head, since it was on a plate owned by King Herod's stepdaughter."], "decomposition": ["What does one carry for one to be considered a cephalophore?", "Did John the Baptist carry #1?"], "evidence": [[[["Cephalophore-1"]], [["Cephalophore-4"], "operation"]], [[["Cephalophore-1"]], [["Cephalophore-5"], "operation"]], [[["Cephalophore-1"]], [["John the Baptist-188"], "no_evidence", "operation"]]]}
{"qid": "43e2fe43169c07b5ab49", "term": "Karachi", "description": "Megacity in Sindh, Pakistan", "question": "Karachi was a part of Alexander the Great's success?", "answer": true, "facts": ["Karachi is a city in modern day Pakistan.", "Krokola was an ancient port located in what is now Karachi.", "Alexander the Great stationed his fleet in Krokola on his way to Babylon.", "Alexander the Great defeated Darius and conquered Babylon before expanding his empire."], "decomposition": ["What is Karachi?", "What was the name of the ancient port that was once located in #1?", "Before expanding his empire, what city did Alexander the Great conquer?", "Did Alexander the Great station his fleet at #2 prior to #3?"], "evidence": [[[["Karachi-1"]], [["Karachi-8"]], [["Achaemenid Assyria-41"]], ["operation"]], [[["Karachi-1"]], [["Karachi-8"]], ["no_evidence"], ["operation"]], [[["Karachi-1"]], [["Port of Karachi-2"]], [["Alexander the Great-51"], "no_evidence"], [["Karachi-8"], "no_evidence", "operation"]]]}
{"qid": "ad97256b5f0ab80b948a", "term": "Parody", "description": "Imitative work created to mock, comment on or trivialise an original work", "question": "Are parodies of the President of the United States illegal?", "answer": false, "facts": ["Parody in the US is protected under fair use in regards to copyright.", "Criticism of political leaders is protected under the 1st Amendment."], "decomposition": ["Is parody illegal in the US?", "Is criticism of the government against the US constitution?", "Is #1 or #2 positive?"], "evidence": [[[["Fair use-1", "Parody-30"], "no_evidence"], [["Freedom of speech in the United States-1", "Human rights in the United States-2"]], ["operation"]], [[["Parody-30"]], [["Freedom of speech in the United States-1", "Freedom of speech in the United States-34"]], ["operation"]], [[["Parody-30"]], [["First Amendment to the United States Constitution-1"]], ["operation"]]]}
{"qid": "4c088a5366459f2256c6", "term": "Mental disorder", "description": "Distressing thought or behavior pattern", "question": "Did Van Gogh suffer from a mental disorder?", "answer": true, "facts": ["Mental disorders can be characterized by psychotic episodes and delusions", "Van Gogh suffered from psychotic episodes and delusions"], "decomposition": ["What are mental disorders characterized as?", "What issues did Van Gogh suffer from?", "Is #1 the same as #2?"], "evidence": [[[["Mental disorder-40"]], [["Vincent van Gogh-3"]], ["operation"]], [[["Mental disorder-1"]], [["Vincent van Gogh-3"]], ["operation"]], [[["Causes of mental disorders-58"], "operation"], [["Van Gogh syndrome-4"], "no_evidence"], ["no_evidence"]]]}
{"qid": "a8f96cb3309095eeadc6", "term": "All Nippon Airways", "description": "Japanese Airline", "question": "Are the headquarters of All Nippon Airways near a beach?", "answer": false, "facts": ["The headquarters of All Nippon Airways are located in Shiodome City Center in the Shiodome area of the Minato ward of Tokyo.", "Tokyo is a metropolitan area.", "A beach is a landform alongside a body of water.", "Metropolitan areas typically do not have bodies of water in the surrounding area."], "decomposition": ["Where city are the headquarters of All Nippon Airways?", "What kind of development area is #1?", "What is a beach characterized as?", "Do #2 areas typically have #3?"], "evidence": [[[["All Nippon Airways-1"]], [["Shiodome-2"]], [["Beach-1"]], ["operation"]], [[["All Nippon Airways-1"]], [["Shiodome-7"]], [["Beach-1"]], ["operation"]], [[["All Nippon Airways-1"]], [["Shiodome-1"]], [["Beach-1"]], ["operation"]]]}
{"qid": "3554b8a182555f759b9f", "term": "Twin", "description": "One of two offspring produced in the same pregnancy. Use with P31 on items for one twin", "question": "Are twins always born during the same year?", "answer": false, "facts": ["Some twins are born right before the New Year, and right after the New Year.", "There are some twins, implanted through IVF, who are born decades apart."], "decomposition": ["What external fertilization processes can result in twins?", "What process can split embryo twins from #1?", "What process is used to preserve embryos from #1?", "Is it impossible to apply #2 and #3 to embryo twins created from #1?"], "evidence": [[[["In vitro fertilisation-32"]], [["Twin-16"]], [["Embryo cryopreservation-1"]], [["Embryo cryopreservation-2"], "operation"]], [[["Twin-39"]], [["In vitro fertilisation-32"]], [["In vitro fertilisation-71"]], ["operation"]], [[["In vitro fertilisation-32"], "no_evidence"], ["no_evidence"], [["Oocyte cryopreservation-1"], "no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "3a61dcbed7e358b3aee8", "term": "Great Pyramid of Giza", "description": "Largest pyramid in the Giza Necropolis, Egypt", "question": "Can 200 men end to end cover Great Pyramid of Giza's base?", "answer": true, "facts": ["The base of the Great Pyramid of Giza is 756 feet long.", "The average height of a man is 5 foot 9."], "decomposition": ["What is the height in inches of the average man?", "What is length in inches of the base of The Great Pyramid of Giza?", "What is 200 times #1?", "Is #3 more than #2?"], "evidence": [[[["Dinka people-3"], "no_evidence"], [["Great Pyramid of Giza-4"]], ["operation"], ["operation"]], [[["Dinka people-3"], "no_evidence"], [["Great Pyramid of Giza-4"], "no_evidence"], ["no_evidence", "operation"], ["no_evidence", "operation"]], [[["Human height-46"]], [["Great Pyramid of Giza-4"]], [["Foot (unit)-1"], "operation"], ["operation"]]]}
{"qid": "2e95e20da8a6cfacaa83", "term": "Dessert", "description": "A course that concludes a meal; usually sweet", "question": "Would an ancient visitor to Persia probably consume crocus threads?", "answer": true, "facts": ["Ancient Persians would have several desserts after a simple meal", "Saffron is made from crocus styles or threads", "Saffron is a common ingredient in Persian desserts"], "decomposition": ["What would Ancient Persians typically have after a simple meal?", "What was a common ingredient in #1?", "Is #2 made from crocus threads?"], "evidence": [[[["History of saffron-16"]], [["History of saffron-16"]], [["Saffron-1"]]], [[["Tahchin-1"], "no_evidence"], [["Saffron (color)-1"]], ["operation"]], [["no_evidence"], ["no_evidence"], [["Crocus sativus-6"], "no_evidence", "operation"]]]}
{"qid": "f1c38036ed44c2422c7b", "term": "Watergate scandal", "description": "Political scandal that occurred in the United States in the 1970s", "question": "Would Hannah Nixon be proud of Richard Nixon following the Watergate scandal?", "answer": false, "facts": ["Hannah Nixon was the mother of Richard Nixon.", "Richard Nixon resigned due to the unethical actions that he committed during the Watergate scandal.", "Parents are typically not proud of their children when they act immorally or unethically."], "decomposition": ["What is Hannah Nixon relation to Richard Nixon?", "What happened to Richard Nixon as a result of the Watergate scandal?", "Why did Richard Nixon have to #2?", "Are #1's usually proud if their child does #3?"], "evidence": [[[["Hannah Milhous Nixon-1"]], [["Richard Nixon-94", "Richard Nixon-95"]], [["Richard Nixon-94"], "operation"], ["operation"]], [[["Hannah Milhous Nixon-1"]], [["Richard Nixon-4"]], [["Richard Nixon-4"]], ["operation"]], [[["Hannah Milhous Nixon-1"]], [["Watergate scandal-66"]], [["Watergate scandal-65"]], ["operation"]]]}
{"qid": "f46ccce500df67cd8f56", "term": "2008 Summer Olympics", "description": "Games of the XXIX Olympiad, held in Beijing in 2008", "question": "Did Boris Yeltsin watch the 2008 Summer Olympics?", "answer": false, "facts": ["The 2008 Summer Olympics were held Aug 08 - 24, 2008", "Boris Yeltsin died on Apr 23, 2007"], "decomposition": ["What were the date of the 2008 Summer Olympics?", "When did Boris Yeltsin die?", "is #2 before #1?"], "evidence": [[[["2008 Summer Olympics-1"]], [["Boris Yeltsin-77"]], ["operation"]], [[["2008 Summer Olympics-1"]], [["Boris Yeltsin-77"]], ["operation"]], [[["2008 Summer Olympics-1"]], [["Boris Yeltsin-1"]], ["operation"]]]}
{"qid": "042101b10af2b128df10", "term": "Brooklyn", "description": "Borough in New York City and county in New York state, United States", "question": "Can DRL Racer X drone get across Brooklyn Bridge in 18 seconds?", "answer": false, "facts": ["The Brooklyn Bridge is 1.1 miles long.", "The DRL Racer X drone can fly at a top speed of 179.6 MPH.", "The DRL Racer X drone can cover around 3 miles a minute."], "decomposition": ["What is the top speed of the  DRL Racer X drone?", "How long is the Brooklyn Bridge?", "What is #2 multiplied by 60 and then divided by #1?", "is #3 less than or equal to 18?"], "evidence": [[[["Drone Racing League-22"]], [["Brooklyn Bridge-1"]], ["operation"], ["operation"]], [[["Drone Racing League-22"]], [["Brooklyn Bridge-5", "Mile-1"]], ["operation"], ["operation"]], [[["Drone Racing League-22"]], [["Brooklyn Bridge-1"]], ["no_evidence", "operation"], ["operation"]]]}
{"qid": "1e0f0676ee91a330262a", "term": "Lapidary", "description": "gemstone cutter", "question": "Does a lapidary work with items that are studied by geologists?", "answer": true, "facts": ["Some of the things geologists study include gemstones, minerals, and stone", "Lapidarists work with stone, minerals and gemstones"], "decomposition": ["What are the materials a lapidary works with?", "What do geologists study?", "Is any of #1 derived from #2?"], "evidence": [[[["Lapidary-1"]], [["Geologist-9"]], ["operation"]], [[["Lapidary-1"]], [["Geology-1"]], ["operation"]], [[["Lapidary-1"]], [["Geology-1"]], ["operation"]]]}
{"qid": "1a65b1ecd37a63767bf7", "term": "Persian Gulf", "description": "An arm of the Indian Ocean in western Asia", "question": "Can the Persian Gulf fit in New Jersey?", "answer": false, "facts": ["The Persian Gulf has an area of 96,912 square miles.", "New Jersey has a land area of 7,417 square miles."], "decomposition": ["How much area does the Persian Gulf cover?", "How much area does New Jersey cover?", "Is #2 greater than #1?"], "evidence": [[[["Persian Gulf-6"]], [["New Jersey-1"]], ["operation"]], [[["Persian Gulf-6"]], [["New Jersey-1"]], ["operation"]], [[["Persian Gulf-6"]], [["New Jersey-1"]], ["operation"]]]}
{"qid": "9e7b4c746b598d1521e0", "term": "Geometry", "description": "Branch of mathematics that studies the shape, size and position of objects", "question": "Do carpenters understand geometry?", "answer": true, "facts": ["Carpenters work in building and maintaining structures such as homes, buildings, and gazebos.", "In order to build a home, one must be able to follow the geometry in the blueprints. "], "decomposition": ["What kind of buildings/structures do carpenters help in constructing?", "Do #1 require knowledge of geometry to carry out?"], "evidence": [[[["Carpentry-1"]], [["Geometry-38"], "operation"]], [[["Carpentry-1"]], [["Geometry-1"], "operation"]], [[["Carpentry-1"]], [["Geometry-1"]]]]}
{"qid": "b995e9731d1488cc1241", "term": "Cancer", "description": "group of diseases", "question": "Do all cancer patients get disability?", "answer": false, "facts": ["All forms of cancer qualify as diagnoses that can result in disability.", "Disability is not determined by diagnosis, but by degree of impairment.", "Some cancer patients do not experience major impairment."], "decomposition": ["What is disability determined by?", "Do all patients of cancer have the same degree of #1?"], "evidence": [[[["Disability-1"]], [["Disability-4"]]], [[["Disability-2"], "no_evidence"], [["Cancer-99"], "no_evidence", "operation"]], [[["Disability Determination Services-18"]], [["Cancer rehabilitation-3"], "operation"]]]}
{"qid": "49cd2c594e9715899734", "term": "Golden Gate Bridge", "description": "suspension bridge on the San Francisco Bay", "question": "Do depressed people travel to the Golden Gate Bridge often?", "answer": true, "facts": ["The Golden Gate Bridge is one of the most popular suicide spots in the USA.", "Suicide is often caused by severe depression."], "decomposition": ["What is the ultimate end that severe depression can lead to?", "Is the Golden Gate Bridge a place where #1 is known to often happen?"], "evidence": [[[["Major depressive disorder-22"]], [["Suicides at the Golden Gate Bridge-4"], "operation"]], [[["Suicide-7"]], [["Golden Gate Bridge-50"]]], [[["Suicide-1"]], [["Suicides at the Golden Gate Bridge-4"]]]]}
{"qid": "05e69c19a536222d90db", "term": "Anorexia nervosa", "description": "Eating disorder characterized by refusal to maintain a healthy body weight, and fear of gaining weight due to a distorted self image", "question": "Did Jon Brower Minnoch suffer from anorexia nervosa?", "answer": false, "facts": ["Jon Brower Minnoch was an American man who, at his peak weight, was the heaviest human being ever recorded, weighing 1,400 lb.", "Anorexia nervosa,Anorexia nervosa is an eating disorder, characterized by low weight, food restriction, fear of gaining weight, and a strong desire to be thin. Many people with anorexia see themselves as overweight even though they are, in fact, underweight."], "decomposition": ["What are characteristics of anorexia nervosa?", "How much did Jon Brower Minnoch weigh?", "Is #2 a weight that would be considered #1?"], "evidence": [[[["Anorexia nervosa-1"]], [["Jon Brower Minnoch-1"]], [["Anorexia nervosa-2", "Jon Brower Minnoch-5"]]], [[["Anorexia nervosa-1"]], [["Jon Brower Minnoch-1"]], ["operation"]], [[["Anorexia nervosa-4"]], [["Jon Brower Minnoch-1"]], [["Jon Brower Minnoch-1"], "operation"]]]}
{"qid": "a6bf045651f7b6b64035", "term": "Macaque", "description": "genus of Old World monkeys", "question": "Could an elephant easily defeat a male macaque?", "answer": true, "facts": ["Male macaques range from 16 to 28 inches tall with a weight between 12.13 to 39.7 pounds.", "Elephants are between 7 to 11 feet tall and weigh several thousand pounds.", "Elephants contain large, sharp tusks that can injure or kill other animals."], "decomposition": ["How much does a male macaques weigh?", "How much can an elephant weigh?", "How tall is a male macaque?", "How tall is an elephant?", "Is #2 more than #1 and is #4 more than #3?"], "evidence": [[[["Macaque-4"]], [["Elephant-14"]], [["Macaque-4"]], [["Elephant-12"]], ["operation"]], [[["Macaque-4"]], [["Elephant-15"]], [["Macaque-4"]], [["Elephant-15"]], ["operation"]], [[["Macaque-4"]], [["Elephant-15", "Elephantidae-1"], "no_evidence"], [["Macaque-4"]], [["Elephant-15"]], ["operation"]]]}
{"qid": "c4a9e56df5b83e483769", "term": "Brazilian Navy", "description": "Naval warfare branch of Brazil's military forces", "question": "Could modern Brazilian Navy have hypothetically turned the tide in Battle of Actium?", "answer": true, "facts": ["The Battle of Actium saw Mark Antony's army lose to Octavian.", "Octavian's army had 400 ships, 16000 infantry, and 3,000 archers.", "The Brazilian Navy has over 80,000 personnel, including 16,000 marines.", "Several Brazilian Navy ships are armed with explosive torpedoes. "], "decomposition": ["What was the result of the Battle of Actium?", "In #1, how many resources did the Octavian's army have?", " How many resources does the Brazilian Navy have? ", "Is #3 significantly more than #2?"], "evidence": [[[["Battle of Actium-26"]], [["Battle of Actium-14"]], [["Brazilian Navy-55", "Brazilian Navy-56"]], ["operation"]], [[["Battle of Actium-2"]], [["Battle of Actium-12"]], [["Brazilian Navy-55"]], ["operation"]], [[["Battle of Actium-2"]], [["Battle of Actium-12"]], [["Brazilian Navy-56"], "no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "ec77d443ba555a906316", "term": "Taco Bell", "description": "American fast-food chain", "question": "Does the Taco Bell kitchen contain cinnamon?", "answer": true, "facts": ["Taco Bell serves churros.", "Cinnamon is an ingredient in churros."], "decomposition": ["What dough pastry based snack does Taco Bell serve?", "Does #1 contain Cinnamon?"], "evidence": [[[["Taco Bell-1"]], ["no_evidence", "operation"]], [[["Taco Bell-21"]], [["Cinnabon-3"]]], [[["Taco Bell-21"]], [["Cinnabon-3"], "no_evidence"]]]}
{"qid": "4648058ffbc40905a042", "term": "Rupert Murdoch", "description": "Australian-born American media mogul", "question": "Does Rupert Murdoch's alma mater have more history than the USA?", "answer": true, "facts": ["Rupert Murdoch's alma mater is Worcester College.", "Worcester College was founded in 1714.", "The first documented use of the term the United States of America was in a January 2, 1776 letter."], "decomposition": ["What is Rupert Murdoch's alma mater?", "When was #1 founded?", "When was the United States founded?", "Is #2 prior to #3?"], "evidence": [[[["Rupert Murdoch-8"]], [["Worcester College, Oxford-1"]], [["United States Declaration of Independence-1"]], ["operation"]], [[["Rupert Murdoch-8"]], [["Worcester College, Oxford-1"]], [["United States Declaration of Independence-1"]], ["operation"]], [[["Rupert Murdoch-8"]], [["Worcester College, Oxford-1"]], [["United States-27"]], ["operation"]]]}
{"qid": "1ffe6c11a37f8e4e2542", "term": "Grey seal", "description": "species of seal", "question": "Can a grey seal swim in the same water as the subject of Moby Dick?", "answer": true, "facts": ["The range of gray seals is limited to parts of the northern hemisphere bordered by the Atlantic ocean", "The subject of Moby Dick was a sperm whale", "Sperm whales can be found in the north Atlantic, in addition to most other bodies of water on earth."], "decomposition": ["What kind of whale was Moby Dick?", "What is the range of #1?", "What is the range of gray seals?", "Is there an overlap between #2 and #3?"], "evidence": [[[["Moby-Dick-1"]], [["Sperm whale-2"], "no_evidence"], [["Grey seal-1"]], ["no_evidence", "operation"]], [[["Moby-Dick-1"]], [["Sperm whale-2"]], [["Grey seal-1"]], ["operation"]], [[["Moby-Dick-1"]], [["Sperm whale-2"]], [["Grey seal-7"]], ["operation"]]]}
{"qid": "d9a89b17f569834014a1", "term": "Daytona 500", "description": "Auto race held in Daytona, Florida, United States", "question": "Did Dale Jr hug his dad after their last Daytona 500 together?", "answer": false, "facts": ["Dale Jr. and his father Dale Sr. last raced together at the Daytona 500 in 2001.", "During the 2001 Daytona 500 Dale Sr. suffered a basilar skull fracture and died. "], "decomposition": ["Which race did Dale Jr and his father participate in last together?", "Which notable incident took place during #1?", "Was Dale Jr.'s father well enough to hug his son after #2?"], "evidence": [[[["Dale Earnhardt Jr.-6"]], [["Dale Earnhardt Jr.-6"]], ["no_evidence", "operation"]], [[["Dale Earnhardt-23"]], [["Dale Earnhardt-23"]], ["operation"]], [[["Dale Earnhardt Jr.-10"]], [["Dale Earnhardt-23"]], ["operation"]]]}
{"qid": "d640dea4e362ceaa2a64", "term": "Acetylene", "description": "chemical compound", "question": "Did Julio Gonzalez like acetylene?", "answer": true, "facts": ["Julio Gonzalez was an artist who welded metal to create sculptures", "Welding is achieved by using a blowtorch on metal", "Blowtorches use acetylene as fuel"], "decomposition": ["What technique did Julio Gonzalez use to create his scultures?", "What is the main tool used for #1?", "What is a common fuel for #2?"], "evidence": [[[["Julio González (sculptor)-5"], "no_evidence"], [["Welding-10"]], [["Acetylene-14"], "operation"]], [[["Julio González (sculptor)-4"]], [["Oxy-fuel welding and cutting-3"]], [["Oxy-fuel welding and cutting-30"]]], [[["Julio González (sculptor)-1", "Julio González (sculptor)-4"]], [["Welding-10"]], [["Acetylene-14"]]]]}
{"qid": "6574229a8596e013f8e6", "term": "Sesame", "description": "species of plant", "question": "Could white rice go rancid before sesame seeds?", "answer": false, "facts": ["Sesame seeds should last 6-12 months unopened.", "White rice can last 4-5 years in a pantry."], "decomposition": ["What is the shelf life of sesame seeds?", "What is the shelf life of white rice?", "Is #2 shorter than #1?"], "evidence": [[["no_evidence"], [["White rice-1"], "no_evidence"], ["operation"]], [[["Sesame-17"], "no_evidence"], [["Rice-84"], "no_evidence"], ["no_evidence", "operation"]], [["no_evidence"], ["no_evidence"], ["operation"]]]}
{"qid": "defd6e3da16a186503c0", "term": "Sophist", "description": "Specific kind of teacher in both Ancient Greece and in the Roman Empire", "question": "Would Sophist's have hypothetically made good lawyers?", "answer": true, "facts": ["Sophist's were teachers in ancient Greece that used rhetoric.", "Lawyers must persuade juries that their side of the case is correct.", "Rhetoric is the ancient art of persuasion that was meant to sway audiences in specific situations."], "decomposition": ["What were Sophist's role in Ancient Greece?", "What did #1 use in their position?", "What do lawyers do in their position?", "Would #3 find #2 to be helpful?"], "evidence": [[[["Sophist-1"]], [["Second Sophistic-3"], "no_evidence"], [["Lawyer-7"]], ["operation"]], [[["Sophist-1"]], ["no_evidence"], [["Lawyer-1"]], ["operation"]], [[["Sophist-1", "Sophist-9"]], [["Hellenistic philosophy-3"]], [["Lawyer-1"]], [["Practice of law-1"], "no_evidence"]]]}
{"qid": "a40dafa5d3114a101432", "term": "Darth Vader", "description": "fictional character in the Star Wars franchise", "question": "Can Darth Vader hypothetically outdunk Bill Walton without using The Force?", "answer": false, "facts": ["The Force allows a Jedi to move objects with their mind.", "Darth Vader is 6'2\" tall.", "Former basketball player Bill Walton is a towering 6'11\" tall.", "The NBA basketball rim is 10 feet high."], "decomposition": ["What characteristic determines someone's ability to dunk?", "What is Darth Vader's measurement of #1?", "What is Bill Walton's measurement of #1?", "Is #2 greater than #3?"], "evidence": [[[["Human height-1"]], [["Darth Vader-8"], "no_evidence"], [["Bill Walton-5"]], ["operation"]], [[["Slam dunk-5"]], [["Darth Vader-3", "David Prowse-2"], "no_evidence"], [["Bill Walton-5"]], ["operation"]], [[["Slam dunk-5"]], [["Darth Vader-8"], "no_evidence"], [["Bill Walton-5"]], ["operation"]]]}
{"qid": "5f267b7c20090236a2fb", "term": "Beauty and the Beast", "description": "traditional fairy tale", "question": "Were Beauty and the Beast adaptations devoid of Kurt Sutter collaborators?", "answer": false, "facts": ["Beauty and the Beast is a fairy tale adapted into several movie and TV shows.", "Kurt Sutter created the TV series Sons of Anarchy and The Shield.", "Charlie Hunnam and Ron Perlman starred in Sons of Anarchy.", "Ron Perlman starred in the TV series Beauty and the Beast which aired from 1987-1990."], "decomposition": ["Which characters were featured in Kurt Sutter's Sons of Anarchy and The Shield?", "Which characters were featured in TV series Beauty and the Beast?", "Is there no character common to #1 and #2?"], "evidence": [[[["Clay Morrow-1", "The Shield-1"], "no_evidence"], [["Beauty and the Beast (1987 TV series)-13"]], [["Ron Perlman-1"], "operation"]], [[["Clay Morrow-1"], "no_evidence"], [["Ron Perlman-5"], "no_evidence"], ["operation"]], [[["Ron Perlman-1", "The Shield-1"]], [["Beauty and the Beast (1987 TV series)-1"]], ["operation"]]]}
{"qid": "bcd77b200a2b90ca2ecc", "term": "Jackson Pollock", "description": "American painter", "question": "Is it understandable to compare a blood spatter pattern to a Jackson Pollock piece?", "answer": true, "facts": ["Jackson Pollock is well known for a style of art formed through splashing liquids on canvas.", "Blood spatter patterns are caused by a splash of blood onto a surface or multiple surfaces."], "decomposition": ["What kinds of work pieces is Jackson Pollock well known for?", "How does he form #1", "How is a blood splatter formed?", "Is #2 comparable to #3?"], "evidence": [[[["Jackson Pollock-1"]], [["Jackson Pollock-2"]], [["Bloodstain pattern analysis-5"]], ["operation"]], [[["Jackson Pollock-1"]], [["Jackson Pollock-2"]], [["Bloodstain pattern analysis-4"]], ["operation"]], [[["Jackson Pollock-10"]], [["Jackson Pollock-2"]], [["Blood squirt-1"]], ["operation"]]]}
{"qid": "fd5f22b8ed969a08eea5", "term": "Rick and Morty", "description": "Animated sitcom", "question": "Could Rich and Morty be triggered for children of alcoholics?", "answer": true, "facts": ["Rick, one of the titular characters of Rick and Morty, is often seen drunk and speaking abusively to Morty.", "Morty's mother Beth is depicted multiple times neglecting her children while getting drunk on wine. ", "Trauma triggers can occur when someone is exposed to something that reminds them of a traumatic situation. "], "decomposition": ["What depictions are common triggers for children of alcoholics?", "Do any of the characters from Rick and Morty exhibit the characteristics in #1?"], "evidence": [[[["Alcoholism-13"], "no_evidence"], [["Rick and Morty-5"], "operation"]], [[["Alcoholism-13"], "no_evidence"], [["Rick and Morty-5"], "no_evidence", "operation"]], [[["Adult Children of Alcoholics-4"]], [["Adult Children of Alcoholics-4", "Rick and Morty-4", "Rick and Morty-5"]]]]}
{"qid": "cee57fee546c1d7df94b", "term": "U.S. Route 66", "description": "Former US Highway between Chicago and Los Angeles", "question": "Is Route 66 generally unknown to Americans?", "answer": false, "facts": ["Route 66 was immortalized in the hit \"Route 66\" by Bobby Troupe.", "\"Route 66\" as a song has reached the Billboard Top Charts multiple times and is still played often."], "decomposition": ["In what hit song was Route 66 mentioned?", "Is #1 a little-known song in America?"], "evidence": [[[["(Get Your Kicks on) Route 66-1"]], [["(Get Your Kicks on) Route 66-3"]]], [[["(Get Your Kicks on) Route 66-1"]], [["(Get Your Kicks on) Route 66-2"]]], [[["U.S. Route 66-1"]], [["(Get Your Kicks on) Route 66-1", "(Get Your Kicks on) Route 66-3"], "operation"]]]}
{"qid": "040f15ccc61888c73b48", "term": "Apartheid", "description": "System of institutionalised racial segregation that existed in South Africa and South West Africa (Namibia) from 1948 until the early 1990s", "question": "Did Elle Fanning play an essential part in ending apartheid?", "answer": false, "facts": ["Apartheid lasted from 1948 until the early 1990s.", "Actress Elle Fanning was born on April 9, 1998."], "decomposition": ["When was Actress Elle Fanning born?", "Through which period did the Apartheid last?", "Is #1 before or within #2?"], "evidence": [[[["Elle Fanning-1"]], [["Apartheid-1"]], ["operation"]], [[["Elle Fanning-5"]], [["Apartheid-153"]], ["operation"]], [[["Elle Fanning-1"]], [["Apartheid-1"]], ["operation"]]]}
{"qid": "dd31908b73e958cfd678", "term": "Rurouni Kenshin", "description": "1994 Japanese manga series written and illustrated by Nobuhiro Watsuki", "question": "Is Rurouni Kenshin from same country as lead character in Nobunaga's Ambition?", "answer": true, "facts": ["Rurouni Kenshin is a manga series that comes from Japan.", "Nobunaga's Ambition is a video game series based on the experiences of Oda Nobunaga.", "Oda Nobunaga was a Japanese feudal lord."], "decomposition": ["Where is Rurouni Kenshin from?", "Where was Oda Nobunaga from?", "Is #1 the same as #2?"], "evidence": [[[["Rurouni Kenshin-1"]], [["Oda Nobunaga-1"]], ["operation"]], [[["Rurouni Kenshin-1"]], [["Nobunaga's Ambition-1", "Oda Nobunaga-4"]], ["operation"]], [[["Rurouni Kenshin-1"]], [["Oda Nobunaga-1"]], ["operation"]]]}
{"qid": "c565654d56d2c1bb3532", "term": "Water skiing", "description": "surface water sport", "question": "Can you go water skiing on Venus?", "answer": false, "facts": ["Water skiing requires sufficient area on a smooth stretch of water, one or two skis, a tow boat with tow rope, two or three people, and a personal flotation device.", "Venus has a mean surface temperature of 863 °F.", "There may have been substantial quantities of liquid water on the surface of Venus at one point, but after a period of 600 million to several billion years, a runaway greenhouse effect was caused by the evaporation of that original water."], "decomposition": ["What is the basic requirement for water skiing?", "Is #1 present on Venus in sufficient quantities?"], "evidence": [[[["Water skiing-1"]], [["Venus-20"], "operation"]], [[["Water skiing-1"]], [["Venus-2"], "operation"]], [[["Water skiing-1"]], [["Venus-2"]]]]}
{"qid": "86ead3f15417204affc2", "term": "Dustin Hoffman", "description": "American actor and director", "question": "Is Dustin Hoffman one of the B'nei Yisrael?", "answer": true, "facts": ["Dustin Hoffman was raised in a Jewish family.", "In modern Hebrew, b'nei yisrael (\"children of Israel\") can denote the Jewish people at any time in history."], "decomposition": ["What does B'nei Yisrael refer to?", "What religion was Dustin Hoffman family as he was growing up?", "Is #2 the same as #1?"], "evidence": [[[["Israelites-11"]], [["Dustin Hoffman-7", "Dustin Hoffman-8"]], ["operation"]], [[["Israelites-8"]], [["Dustin Hoffman-7"]], ["operation"]], [[["Indian Jews in Israel-7"]], [["Dustin Hoffman-7"]], ["operation"]]]}
{"qid": "dfaf734cc6f1016cbb0c", "term": "Aretha Franklin", "description": "American singer, songwriter, and pianist", "question": "Has Aretha Franklin ever collaborated with a suicidal person?", "answer": true, "facts": ["Donny Hathaway was a singer and session musician that worked with Staple Singers, Jerry Butler, Aretha Franklin, the Impressions  and Curtis Mayfield.", "Donny Hathaway jumped from his 15th floor room and his death was ruled a suicide."], "decomposition": ["What music artists has Aretha Franklin done collaborations with?", "Did any of the artists listed in #1 commit suicide?"], "evidence": [[[["Donny Hathaway-4"]], [["Donny Hathaway-17"]]], [[["Donny Hathaway-1"], "no_evidence"], [["Donny Hathaway-16"], "operation"]], [[["Donny Hathaway-4"], "no_evidence"], [["Donny Hathaway-17"]]]]}
{"qid": "9975870880bf73b8644e", "term": "Armageddon", "description": "according to the Book of Revelation, the site of a battle during the end times", "question": "Do some religions look forward to armageddon?", "answer": true, "facts": ["Evangelicals cite that we are living in the beginning of Armageddon and that the rapture will happen soon as a good thing.", "Jehova's Witnesses believe that destroying the present world system and Armageddon is imminent, and that the establishment of God's kingdom over the earth is the only solution for all problems faced by humanity"], "decomposition": ["Where does the concept of Armageddon has its roots?", "#1 is associated with which religion?", "Do adherents of #2 believe in and await the Armageddon?"], "evidence": [[[["Armageddon-5"]], [["Armageddon-4"]], [["Armageddon-4"], "operation"]], [[["Armageddon-1"]], [["New Testament-1"]], [["Armageddon-18", "Jehovah's Witnesses-30"], "operation"]], [[["Armageddon-1"]], [["Book of Revelation-1"]], [["Rapture-40"], "operation"]]]}
{"qid": "2c71f90e9c5656eb8edc", "term": "Black Sea", "description": "Marginal sea of the Atlantic Ocean between Europe and Asia", "question": "Could the moon fit inside the Black Sea?", "answer": false, "facts": ["The volume of the Black Sea is 547,000 cubic kilometers.", "The volume of the moon is 21.9 billion cubic kilometers."], "decomposition": ["What is the volume of the Black Sea?", "What is the volume of the moon?", "Is #1 higher than #2?"], "evidence": [[[["Black Sea-2"]], ["no_evidence"], ["no_evidence", "operation"]], [[["Black Sea-2"]], [["Moon-48"], "no_evidence"], ["operation"]], [[["Black Sea-28"], "no_evidence"], [["Earth-85"], "no_evidence"], ["operation"]]]}
{"qid": "50bf347c2a05b645a0f9", "term": "Supreme Court of the United States", "description": "Highest court in the United States", "question": "Is Supreme Court of the United States analogous to High Courts of Justice of Spain?", "answer": false, "facts": ["The Supreme Court of the United States is the final court ad has final say in judicial matters.", "The High Courts of Justice in Spain rule over single communities.", "The Supreme Court of Spain is the highest court in Spain and can overrule lesser courts."], "decomposition": ["What is the extent of the jurisdiction of The Supreme Court of the United States?", "Do the High courts of justice (Spain) have the same jurisdiction as #1?"], "evidence": [[[["Supreme Court of the United States-1"]], [["High Courts of Justice of Spain-1", "Judiciary of Spain-7"]]], [[["Supreme Court of the United States-1"]], [["High Courts of Justice of Spain-1"], "operation"]], [[["Supreme Court of the United States-60"]], ["operation"]]]}
{"qid": "1f187be8cef09e713156", "term": "Black fly", "description": "family of insects", "question": "Was Black fly upstaged by another insect in Jeff Goldblum's 1986 film?", "answer": true, "facts": ["Jeff Goldnlum starred in the 1986 movie The Fly.", "The fly used in the movie The Fly was a common Housefly.", "The Black fly is most closely related to Chironomidae since they both feed on mammals."], "decomposition": ["Which fly was used in the 1986 movie The Fly?", "is #1 a black fly?"], "evidence": [[["no_evidence"], ["operation"]], [[["The Fly (1986 film)-4"]], [["Black fly-1", "Housefly-1"]]], [[["The Fly (1986 film)-4"]], ["operation"]]]}
{"qid": "5278f0501c540dff6407", "term": "Freemasonry", "description": "group of fraternal organizations", "question": "Has Freemasonry been represented on the Moon?", "answer": true, "facts": ["Freemasonry is a group of fraternal organizations rooted in fraternities of stonemasons of the fourteenth century.", "Buzz Aldrin was initiated into the Freemason fraternity in 1955", "Buzz Aldrin and Neil Armstrong were the first men to land on the moon in 1969."], "decomposition": ["What occupation goes into space?", "Have any #1 been Free Masons?", "Have any people listed in #2 been to the moon?"], "evidence": [[[["Astronaut-1"]], [["James Irwin-1", "James Irwin-23"]], [["James Irwin-1"]]], [[["Astronaut-1"]], [["Buzz Aldrin-1"], "no_evidence"], ["no_evidence", "operation"]], [[["Astronaut-1"]], [["John Glenn-62"]], [["John Glenn-3"], "operation"]]]}
{"qid": "964da699d1ada747b266", "term": "BBC World Service", "description": "The BBC's international Chor radio station", "question": "Is the BBC World Service hosted in Europe?", "answer": true, "facts": ["The BBC World Service is part of the BBC network.", "The BBC operates in England.", "England is part of Europe."], "decomposition": ["Where is the BBC World Service located?", "Is #1 located in Europe?"], "evidence": [[[["BBC World Service-15"]], [["London-1", "Outline of the United Kingdom-1"]]], [[["BBC World Service-15"]], ["operation"]], [[["BBC World Service-2"]], [["United Kingdom-25"]]]]}
{"qid": "e5eaf0633f2fcedbcc8e", "term": "Great Recession", "description": "Early 21st-century global economic decline", "question": "Was Great Recession the period of severest unemployment?", "answer": false, "facts": ["The Great Recession had an unemployment peak of 10%.", "The Great Depression saw global GDP decline by almost 30% and unemployment approach 25%.", "US unemployment numbers approached 15% in May 2020 due to the Coronavirus."], "decomposition": ["What was the unemployment rate during the Great Recession?", "What was the US unemployment rate in May 2020?", "Is #2 less than #1?"], "evidence": [[[["Great Recession-43"]], [["Unemployment in the United States-21"]], ["operation"]], [[["Effects of the Great Recession-11"]], [["Unemployment in the United States-21"]], [["Effects of the Great Recession-11", "Unemployment in the United States-21"], "operation"]], [[["Effects of the Great Recession-11"]], [["Unemployment-153"], "no_evidence"], ["operation"]]]}
{"qid": "b2c1c69dbfc82dc9da50", "term": "Pea", "description": "species of plant", "question": "Could a bee hummingbird balance a scale with a single pea on it?", "answer": false, "facts": ["The average pea weighs between 0.1 and 0.36 grams.", "Female bee hummingbirds on average weigh 2.6 grams, while on average male bee hummingbirds weigh 1.95 grams."], "decomposition": ["What is the weight range of the average pea?", "What is the weight range of the average bee hummbingbird?", "Is there an overlap between #1 and #2?"], "evidence": [[[["Pea-2"]], [["Bee hummingbird-2"]], ["operation"]], [[["Pea-2"]], [["Bee hummingbird-2"]], ["operation"]], [[["Pea-2"]], [["Bee hummingbird-2"]], ["operation"]]]}
{"qid": "6523b3b72884557b38e8", "term": "Very Large Telescope", "description": "telescope in the Atacama Desert, Chile", "question": "Is the Very Large Telescope the most productive telescope in the world?", "answer": false, "facts": ["Telescope productivity is measured based on how many scientific papers a telescope generates.", "The Hubble Space Telescope is the most productive telescope in the world. "], "decomposition": ["What are counted when measuring telescope productivity?", "How many occurrences of #1 have there been for the Very Large Telescope?", "How many occurrences of #1 have there been for the Hubble Telescope?", "Is #2 greater than #3?"], "evidence": [[[["Very Large Telescope-3"]], [["Very Large Telescope-16"]], [["Hubble Space Telescope-84"]], ["operation"]], [[["Very Large Telescope-3"]], [["Very Large Telescope-16"]], [["Hubble Space Telescope-84"]], [["Very Large Telescope-3"], "operation"]], [["no_evidence"], [["Very Large Telescope-16"], "no_evidence"], [["Hubble Space Telescope-69"], "no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "4a915ea5d025292cd7ec", "term": "Serfdom", "description": "status of peasants under feudalism", "question": "Did Japanese serfdom have higher status than English counterpart?", "answer": true, "facts": ["Serfs in Medieval England were peasants that were indentured servants to their lords.", "Serfs were often harshly treated and had little legal redress against the actions of their lords.", "Japanese serfs were farmers and fishermen.", "Japanese believed that serfs produced food, which was depended on by all classes, therefore, they worked harder."], "decomposition": ["How did English lords treat their serfs?", "What did the Japanese recognize serfs as?", "Is #2 higher in importance than #1?"], "evidence": [[[["Serfdom-2"]], [["Serfdom-5"]], ["operation"]], [[["Serfdom-2"]], [["Manorialism-17"]], ["operation"]], [[["Serfdom-2"], "no_evidence"], [["Shōen-8", "Shōen-9"], "no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "570dad603aee73b5c88e", "term": "Doctor Who", "description": "British science fiction TV series", "question": "In Doctor Who, did the war doctor get more screen time than his successor?", "answer": false, "facts": ["The War Doctor was succeeded by the \"9th Doctor\". ", "The War Doctor was featured in two episodes of Doctor Who.", "The 9th Doctor was featured in 13 episodes of Doctor Who."], "decomposition": ["Who was the successor of the War Doctor?", "How many episodes was #1 in?", "How many episodes was the War Doctor in?", "Is #3 greater than #2?"], "evidence": [[[["War Doctor-1"]], [["Ninth Doctor-4", "Ninth Doctor-5", "Ninth Doctor-6"]], [["War Doctor-10", "War Doctor-8"]], ["operation"]], [[["War Doctor-1"]], [["Ninth Doctor-4", "Ninth Doctor-5"]], [["Doctor Who-47"]], ["operation"]], [[["War Doctor-1"]], [["Ninth Doctor-1"], "no_evidence"], [["War Doctor-10", "War Doctor-7", "War Doctor-8", "War Doctor-9"]], ["no_evidence", "operation"]]]}
{"qid": "690a36d5fed5b17969aa", "term": "Jack Dempsey", "description": "American boxer", "question": "Did Jack Dempsey fight the current WBC heavyweight champion?", "answer": false, "facts": ["Jack Dempsey died in 1983", "The current WBC heavyweight champion is Tyson Fury", "Tyson Fury was born in 1988"], "decomposition": ["When did Jack Dempsey die?", "When was the current WBC heavyweight champion born?", "Is #2 before #1?"], "evidence": [[[["Jack Dempsey-1"]], [["Tyson Fury-1"]], ["operation"]], [[["Jack Dempsey-1"]], [["Tyson Fury-1"]], ["operation"]], [[["Jack Dempsey-53"]], [["Deontay Wilder-1"]], ["operation"]]]}
{"qid": "7571100f05bc56919c78", "term": "Funeral", "description": "ceremony for a person who has died", "question": "Is it unusual to play Happy hardcore music at a funeral?", "answer": true, "facts": ["Happy hardcore is a music genre of hard dance.", "Happy hardcore emerged both from the UK breakbeat hardcore rave scene, and Belgian, German and Dutch hardcore techno scenes.", "A funeral is traditionally a somber event.", "Funerals typically do not involve dancing.", "Raves are typically energetic and upbeat places and are not somber like a funeral."], "decomposition": ["What type of music is usually played at funerals?", "What are the characteristics of Happy Hardcore music?", "Do any of #1 have the characteristics of #2?"], "evidence": [[[["Funeral-8"]], [["Happy hardcore-1"]], ["operation"]], [[["Dirge-1"]], [["Happy hardcore-1", "Happy hardcore-7"], "no_evidence"], ["no_evidence", "operation"]], [[["Funeral march-1"]], [["Happy hardcore-2"]], [["Funeral march-1"]]]]}
{"qid": "e8cc7615cfaf45069eb5", "term": "Ludacris", "description": "American rapper and actor", "question": "Can you watch the Borgia's World of Wonders before Ludacris's Release Therapy finishes?", "answer": true, "facts": ["World of Wonders is an episode of the Showtime TV series The Borgias, with a run time of 49 minutes.", "Ludacris's 2006 album Release Therapy has a run time of 62 minutes."], "decomposition": ["What is the run time of  the Borgia's World of Wonders?", "What is the run time of  Ludacris's Release Therapy?", "Is #1 shorter than #2?"], "evidence": [[[["The Borgias (2011 TV series)-14"], "no_evidence"], [["Release Therapy-1"], "no_evidence"], ["operation"]], [[["The Borgias (2011 TV series)-1", "The Borgias (2011 TV series)-4"], "no_evidence"], [["Release Therapy-1"], "no_evidence"], ["no_evidence", "operation"]], [["no_evidence"], ["no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "a11f537f67260464d010", "term": "Mitsubishi", "description": "group of autonomous, Japanese multinational companies", "question": "Can someone in Uberlandia work for Mitsubishi?", "answer": true, "facts": ["Mitsubishi is a Japanese auto manufacturer", "Mitsubishi operates a plant in Catalao, Brazil", "Uberlandia is just under 70 miles from Catalao"], "decomposition": ["How far is Uberlandia from Catalao?", "Is #1 within reasonable distance to commute to work?", "Is there a Mitsubishi organization in Catalao?", "Are #2 and #3 positive?"], "evidence": [[[["Catalão-1", "Uberlândia-1"], "no_evidence"], ["operation"], ["no_evidence"], ["operation"]], [[["Catalão-4"]], ["operation"], [["Catalão-1"]], ["operation"]], [[["Catalão-1", "Uberlândia-1"], "no_evidence"], ["no_evidence", "operation"], [["Catalão-1"], "operation"], ["no_evidence", "operation"]]]}
{"qid": "5812637ba98cba20a9af", "term": "Mercedes-Benz", "description": "automobile brand of Daimler AG", "question": "Is it legal for a licensed child driving Mercedes-Benz to be employed in US?", "answer": true, "facts": ["The minimum age for driving in the US is 16.", "Child labor laws in the US require a child to be 14 years of age or older to work."], "decomposition": ["What is the minimum driving age in the US?", "What is the minimum age for someone to be employed in the US?", "Is #1 greater than or equal to #2?"], "evidence": [[[["Graduated driver licensing-35"], "no_evidence"], [["Child labour law-10"]], ["operation"]], [[["Driver's licenses in the United States-9"]], [["Child labor laws in the United States-2"]], ["operation"]], [[["Driver's licenses in the United States-9"]], [["Child labour-66", "Legal working age-1"]], ["operation"]]]}
{"qid": "5099d89884624a70fff7", "term": "Benito Mussolini", "description": "Fascist leader of Italy", "question": "Did Benito Mussolini wear bigger shoes than Hafþór Björnsson?", "answer": false, "facts": ["Benito Mussolini was 5' 6​1⁄2\" tall.", "Hafþór Björnsson is 6 feet 9 inches tall.", "Shoe size increases proportionally as height increases."], "decomposition": ["How tall was Benito Mussolini?", "How tall is Hafþór Björnsson?", "Is #2 smaller than #1?"], "evidence": [[[["Benito Mussolini-8"], "no_evidence"], [["Hafþór Júlíus Björnsson-5"]], ["operation"]], [[["Benito Mussolini-1"], "no_evidence"], [["Hafþór Júlíus Björnsson-19"]], ["no_evidence", "operation"]], [["no_evidence"], [["Hafþór Júlíus Björnsson-5"]], ["no_evidence", "operation"]]]}
{"qid": "43a26c2f067095e1992b", "term": "Guitar Hero", "description": "video game series", "question": "Is Guitar Hero Beatles inappropriate for a US third grader?", "answer": false, "facts": ["The average age of a US third grader is 8.", "Guitar Hero is recommended for ages 7 and up.", "The Beatles were a British rock band with a plethora of radio friendly hits."], "decomposition": ["How old is the average US third grader?", "What is the recommended age to play Guitar Hero?", "Is #1 higher than #2?"], "evidence": [[[["Third grade-1"]], ["no_evidence"], ["operation"]], [[["Third grade-1"]], ["no_evidence"], ["operation"]], [[["Third grade-1"]], ["no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "cf95bbecccc040a95dbb", "term": "Acetylene", "description": "chemical compound", "question": "Does welding with acetylene simulate the temperature of a star?", "answer": true, "facts": ["Acetylene is used for oxyacetylene welding ", "An acetylene/oxygen flame burns at about 3,773 K ", "The star Betelgeuse has a surface temperature of 3,500 K"], "decomposition": ["What temperature is reached when welding with acetylene?", "What temperature can stars reach?", "Are #1 and #2 similar in magnitude?"], "evidence": [[[["Acetylene-14"]], [["Star-91"]], ["operation"]], [[["Acetylene-8"], "no_evidence"], [["Star-91"]], ["operation"]], [[["Acetylene-14"]], [["Star-91"]], ["operation"]]]}
{"qid": "50ee714386bc6323ae11", "term": "Pelvis", "description": "lower part of the trunk of the human body between the abdomen and the thighs (sometimes also called pelvic region of the trunk", "question": "Is cycling a high-risk activity for pelvis fractures?", "answer": false, "facts": ["Cycling is a low-impact activity ", "Stress fractures in a pelvic bone often develop as a result of repetitive, high-impact activity that puts stress on the pelvis, such as long-distance running or ballet"], "decomposition": ["What type of activity can result in stress fractures?", "Would cycling be considered #1?"], "evidence": [[[["Stress fracture-6"]], [["Stationary bicycle-7"], "no_evidence", "operation"]], [[["Stress fracture-1"]], ["operation"]], [[["Pelvic fracture-20"]], ["operation"]]]}
{"qid": "3570d57f16a40488ff42", "term": "Judo", "description": "modern martial art, combat and Olympic sport", "question": "Do silicone suits make judo difficult?", "answer": true, "facts": ["Judo is a martial art that requires combatants to grip their opponents and throw them in various ways.", "Judo practitioners traditionally wear an outfit called a gi, which opponents use to grip and throw.", "Silicone is one of the slipperiest substances on the planet."], "decomposition": ["What maneuvers are required to do Judo?", "What characteristics does an article of clothing need to have in order to do #1 effectively?", "What characteristics does a silicone suit have? ", "Is #3 excluded from #2?"], "evidence": [[[["Judo-1"]], [["Keikogi-1"], "no_evidence"], [["Silicone rubber-2"], "no_evidence"], ["no_evidence", "operation"]], [[["Leopold's maneuvers-6"], "no_evidence"], ["no_evidence"], [["Silicone-47"]], ["operation"]], [[["Judo-1"]], [["Judo-48"]], [["Silicone-1"]], ["operation"]]]}
{"qid": "40eb773857f1933b4b36", "term": "Society", "description": "Social group involved in persistent social interaction", "question": "Can a jet plane be made without society?", "answer": false, "facts": ["A jet plane requires many materials to build.", "A jet plane requires much prior knowledge to build.", "The specialized knowledge and materials is not obtainable without other people."], "decomposition": ["What materials do jet planes require to be built?", "Is #1 obtainable without people?"], "evidence": [[[["Jet aircraft-8"]], [["Jet engine-5"], "operation"]], [[["Aircraft-43"]], [["Aircraft-41"], "no_evidence"]], [[["Components of jet engines-3", "Jet engine-2"], "no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "f318d0f8f873ce921ac9", "term": "Lie", "description": "intentionally false statement to a person or group made by another person or group who knows it is not wholly the truth", "question": "Is it okay to lie after taking an oath in a court of law?", "answer": false, "facts": ["In a court of law, lying under oath is considered perjury. ", "Perjury is considered a crime."], "decomposition": ["When you lie in court, what is that considered?", "Is #1 legal?"], "evidence": [[[["Perjury-1"]], [["Perjury-2"]]], [[["Perjury-1"]], ["operation"]], [[["Perjury-1"]], [["Perjury-2"]]]]}
{"qid": "07ba78b177df5d2a30c3", "term": "Whole genome sequencing", "description": "A process that determines the complete DNA sequence of an organism's genome at a single time", "question": "Did Rosalind Franklin contribute to work that led to Whole Genome Sequencing?", "answer": true, "facts": ["Rosalind Franklin used specialized photography to capture the first photos of the double helix.", "The double helix is the form that DNA takes.", "Without understanding the structure of DNA, genome sequencing would be impossible."], "decomposition": ["Rosalind Franklin capture the first photo of what?", "What takes the form of #1?", "Is understanding #2 essential to genome sequencing?"], "evidence": [[[["Rosalind Franklin-19"]], [["DNA-1"]], [["Whole genome sequencing-1"], "operation"]], [[["Rosalind Franklin-3"]], [["Rosalind Franklin-3"]], [["Whole genome sequencing-1"], "operation"]], [[["Rosalind Franklin-3"]], [["Rosalind Franklin-3"]], [["Rosalind Franklin-3", "Whole genome sequencing-3"]]]]}
{"qid": "ac641c5074e03e422221", "term": "Kane (wrestler)", "description": "American professional wrestler, actor, businessman, and politician", "question": "Was Kane (wrestler) banned from WCW  headquarters city?", "answer": false, "facts": ["Kane (wrestler is a professional wrestler most known for his WWE tenure.", "Kane wrestled one match in WCW as Bruiser Mastino.", "WWE main rival WCW was headquartered in Atlanta, Georgia.", "Kane competed in an eight-man tag match at Wrestlemania XXVII in the Georgia Dome.", "The Georgia Dome was a stadium in Atlanta Georgia."], "decomposition": ["Where were the headquarters of the WCW?", "Did Kane never perform in #1?"], "evidence": [[[["World Championship Wrestling-4"]], [["Royal Rumble (2002)-1", "Royal Rumble (2002)-15"], "operation"]], [[["World Championship Wrestling-4"]], [["Kane (wrestler)-1"], "no_evidence", "operation"]], [[["World Championship Wrestling-4"]], [["Royal Rumble (2002)-1", "Royal Rumble (2002)-15"]]]]}
{"qid": "7fa631340ce8c42aba53", "term": "1980 United States presidential election", "description": "49th quadrennial presidential election in the United States", "question": "Were there greater landslides than 1980 United States presidential election?", "answer": true, "facts": ["A landslide refers to a competitor beating their opponent by a wide margin.", "Ronald Reagan defeated Jimmy carter in the 1980 United States presidential election by around 8 million votes.", "Franklin D. Roosevelt won the 1936 United States presidential election over Alf Landon by more than 11 million votes.", "In 1804 Thomas Jefferson received 162 (92%) of the electoral votes while Charles Cotesworth Pinckney received only 14 (8%)."], "decomposition": ["By what votes margin did Ronald Reagan defeat Jimmy Carter in the 1980 US Presidential election?", "By how many votes was Franklin D. Roosevelt leading Alf Landon in the 1936 US Presidential election?", "How many more votes did Thomas Jefferson receive than Charles Cotesworth Pinckney in the 1804 United States presidential election?", "Are #2 and #3 greater individually than #1?"], "evidence": [[[["Ronald Reagan-50"]], [["Franklin D. Roosevelt-52"]], [["Thomas Jefferson-73"], "no_evidence"], ["operation"]], [[["1980 United States presidential election-50"]], [["1936 United States presidential election-4"]], [["1804 United States presidential election-3", "Thomas Jefferson-73"]], ["operation"]], [[["1980 United States presidential election-4"]], [["1936 United States presidential election-4"]], [["1804 United States presidential election-3"]], ["operation"]]]}
{"qid": "d82193894aa1c12fbc40", "term": "Nissan", "description": "Japanese automobile manufacturer", "question": "Do workers at Nissan's headquarters eat with chopsticks?", "answer": true, "facts": ["Nissan's headquarters are located in Yokohama, Japan.", "It is customary to eat with chopsticks in East Asian countries.", "Japan is a country in East Asia."], "decomposition": ["Where is Nissan's headquarters located?", "Do people living in #1 usually eat with chopsticks?"], "evidence": [[[["Nissan-1", "Yokohama-1"]], [["Chopsticks-1"]]], [[["Nissan-1"]], [["Chopsticks-1", "Etiquette in Japan-21"]]], [[["Nissan-3"]], [["Chopsticks-1"], "operation"]]]}
{"qid": "0e29451fbb512170bddd", "term": "J. K. Rowling", "description": "English novelist", "question": "Are any of J.K. Rowling's books in the genre of And Then There Were None?", "answer": true, "facts": ["And Then There Were None was a mystery novel written by Agatha Christie.", "J.K. Rowling is best known for her wizard fantasy series Harry Potter.", "Robert Galbraith is the author of the Cuckoo's Calling, a mystery crime fiction novel.", "Robert Galbraith is the pseudonym that J.K. Rowling writes under."], "decomposition": ["What genre is the book And Then There Were None?", "What genre are Rowling's fiction Cormoran Strike series?", "Is #1 same as #2?"], "evidence": [[[["And Then There Were None-1"]], [["Cormoran Strike-1"]], ["operation"]], [[["And Then There Were None-1"]], [["Cormoran Strike-1"]], ["operation"]], [[["And Then There Were None-10"], "no_evidence"], [["Cormoran Strike-1"]], ["operation"]]]}
{"qid": "b816f51e0fedcae2a789", "term": "Liberty Bell", "description": "bell that serves as a symbol of American independence and liberty", "question": "Is the Liberty Bell still in its original location?", "answer": false, "facts": ["The Liberty Bell originally was located in Independence Hall in Philadelphia.", "It was moved to a nearby pavilion to accommodate viewers in 1976."], "decomposition": ["What was the original location of the Liberty Bell?", "What is the current location of the Liberty Bell?", "Is #2 the same as #1?"], "evidence": [[[["The Liberty Bell (band)-2"], "operation"], [["Location, Location, Location-3"], "no_evidence"], ["no_evidence"]], [[["Liberty Bell-1"]], [["Liberty Bell-1"]], [["Liberty Bell-1"], "operation"]], [[["Liberty Bell-1"]], [["Liberty Bell-1"]], ["operation"]]]}
{"qid": "e6d8397b258ac4006210", "term": "Rosemary", "description": "species of plant, rosemary", "question": "Is Rosemary outclassed as plant found in most song titles?", "answer": true, "facts": ["Rosemary appears in a few popular song titles such as Love Grows (Where My Rosemary Goes) and Randy Newman's Rosemary.", "Rose appears in many song titles including: Kiss From a Rose, The Rose, Desert Rose, Beauty of the Rose, and I Never Promised You a Rose Garden."], "decomposition": ["How many songs have \"rosemary\" in the title?", "How many songs have the plant \"rose\" in the title?", "Is #1 fewer than #2?"], "evidence": [[[["Love Grows (Where My Rosemary Goes)-3"], "no_evidence"], [["Blue Rose (song)-4", "Kiss from a Rose-1", "Lady Rose (song)-1", "The Rose (song)-2"], "no_evidence"], ["operation"]], [[["Love Grows (Where My Rosemary Goes)-1", "Rosemary Lane (song)-1"]], [["Desert Rose (Sting song)-1", "Every Rose Has Its Thorn-1", "Kiss from a Rose-1"]], ["operation"]], [[["Rosemary-23"], "no_evidence"], [["Rose-25"], "no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "007e8eb724fccca37c36", "term": "Apollo", "description": "God in Greek mythology", "question": "Do Apollo and Baldur share similar interests?", "answer": true, "facts": ["Apollo is a Greek god of light.", "Baldur is a Norse god of light.", "They are both interested in light."], "decomposition": ["Apollo is the Greek god of what object?", "What is Baldur the Norse god of?", "Is the item in #2 the same as #1?"], "evidence": [[[["Apollo-1"]], ["no_evidence"], ["operation"]], [[["Apollo-1"]], [["Baldr-1"], "no_evidence"], ["no_evidence", "operation"]], [[["Apollo-1"]], [["Baldr-7"]], ["operation"]]]}
{"qid": "3502d54b8241e79903a9", "term": "Missionary", "description": "member of a religious group sent into an area to do evangelism", "question": "Were the first missionaries required to attend mass on Sundays?", "answer": true, "facts": ["The word \"mission\" originates from 1598 when the Jesuits sent members abroad.", "Jesuits are a Roman Catholic order of religious men", "The Roman Catholic religion requires members to attend mass on Sundays"], "decomposition": ["What religion were the first missionaries?", "Does #1 require mass attendance?"], "evidence": [[[["Missionary-4"]], [["Mass (liturgy)-1", "Mass (liturgy)-13"], "operation"]], [[["Missionary-4"]], [["Eucharist in the Catholic Church-76"], "no_evidence"]], [[["Guadalupe Missionaries-1"]], [["Mass (liturgy)-13"], "operation"]]]}
{"qid": "5f96f27de4c8cdafc070", "term": "Brake", "description": "mechanical device that inhibits motion", "question": "Can people die from brake failure?", "answer": true, "facts": ["Brake failure is the inability of brakes to function.", "When vehicles experience brake failure, they cannot be stopped safely, which results in a crash.", "People die in vehicular crashes."], "decomposition": ["What is a brake failure?", "What can #1 lead to in a car?", "Have people died from #2?"], "evidence": [[[["Disc brake-63"]], [["Traffic collision-1", "Traffic collision-50"]], [["Falco (musician)-22"], "operation"]], [[["Brake-1"], "no_evidence"], [["Traffic collision-1", "Traffic collision-24"], "no_evidence"], [["Traffic collision-3"], "operation"]], [["no_evidence"], ["no_evidence"], ["no_evidence"]]]}
{"qid": "4b2e265815601bfa4152", "term": "Astrophotography", "description": "specialized type of photography for recording images of astronomical objects and large areas of the night sky", "question": "Is it difficult to conduct astrophotography in the summer in Sweden?", "answer": true, "facts": ["Astrophotography is used to photograph the night sky.", "Swedish summers have short nights."], "decomposition": ["What does Astrophotography take photos of?", "Are #1's short in the summers of Sweden?"], "evidence": [[[["Astrophotography-1"]], [["Sweden-59"], "operation"]], [[["Astrophotography-1"]], [["Sweden-56"], "operation"]], [[["Astrophotography-1"]], [["Tourism in Sweden-6"]]]]}
{"qid": "3b3547ab6ae47d840f37", "term": "Nature", "description": "Hominin events for the last 10 million years", "question": "Would someone go to San Francisco for a nature escape?", "answer": false, "facts": ["San Francisco is a major US city with over 800,000 people.", "San Francisco is known for mass transit and being a metropolitan area."], "decomposition": ["What kind of developed human settlement is San Francisco?", "Are #1's known for nature?"], "evidence": [[[["San Francisco-1"]], [["San Francisco-1"]]], [[["San Francisco-1"]], ["no_evidence", "operation"]], [[["San Francisco-95"]], ["operation"]]]}
{"qid": "00f951d01196c2e77fe6", "term": "Presidency of Richard Nixon", "description": "American cabinet", "question": "Would the high school class of 2010 have lived through the Presidency of Richard Nixon?", "answer": false, "facts": ["People in the high school class of 2010 were born between 1991 and 1993.", "Richard Nixon was President of the United States until 1974."], "decomposition": ["When was Richard Nixon president of the US until?", "What year range would the high school class of 2010 be born in?", "Is #1 in #2?"], "evidence": [[[["Richard Nixon-1"]], [["Secondary education in the United States-36"], "no_evidence"], ["operation"]], [[["Richard Nixon-1"]], [["Secondary education-1"], "no_evidence"], ["operation"]], [[["Richard Nixon-46"]], ["no_evidence"], ["operation"]]]}
{"qid": "c6b927da57fb0b45b830", "term": "Bicycle", "description": "Pedal-driven two-wheel vehicle", "question": "Do children's bicycles often have extra wheels?", "answer": true, "facts": ["Training wheels are a set of two wheels to attach to bicycles of new bike riders for additional support.", "Training wheels are marketed primarily at children."], "decomposition": ["What types of bicycles have more than two wheels?", "Are any of #1 customarily bought for children?"], "evidence": [[[["Training wheels-1"]], [["Training wheels-1"]]], [[["Tricycle-3"]], ["operation"]], [[["Tricycle-1"]], [["Tricycle-3"]]]]}
{"qid": "7c74e1234d292f83fbba", "term": "Land of Israel", "description": "Traditional Jewish name for an area of indefinite geographical extension in the Southern Levant.", "question": "Was Land of Israel in possession of an Islamic empire in 16th century?", "answer": true, "facts": ["Land of Israel was controlled by the Ottoman Empire in 16th century. ", "The religion of Ottoman Empire was Sunni Islam. "], "decomposition": ["Who ruled the geographic region of Israel in the 16th century?", "Was Islam the state religion of #1?"], "evidence": [[[["Israel-23", "Palestine (region)-20"]], [["Ottoman Empire-93"], "operation"]], [[["Israel-22"]], [["Ottoman Empire-96"], "no_evidence"]], [[["Israel-22"]], [["Ottoman Empire-96"], "operation"]]]}
{"qid": "11cc9b01c009823d5f82", "term": "Short-eared dog", "description": "species of canid", "question": "Has Cesar Millan ever tamed a short-eared dog?", "answer": false, "facts": ["Cesar Millan is a Mexican-American dog trainer with over 25 years of canine experience.", "The short-eared dog lives in various parts of the rainforest environment, preferring areas with little human disturbance.", "The short-eared dog is a solitary animal and prefers moving in trees away from human and other animal interactions.", "The short-eared dog is a wild animal that is not suitable as a pet."], "decomposition": ["Which kind of dogs does Cesar Millan's train?", "What are the social characteristics of the short-eared dog?", "Does #2 match the characteristics of #1?"], "evidence": [[[["Cesar Millan-11"]], [["Short-eared dog-9"]], ["operation"]], [[["Cesar Millan-2"], "no_evidence"], [["Short-eared dog-1", "Short-eared dog-9"]], ["operation"]], [[["Cesar Millan-2"]], [["Short-eared dog-9"]], ["operation"]]]}
{"qid": "ea8bdd791571893e082d", "term": "Olive", "description": "Species of plant", "question": "Would you find olives at a heladeria?", "answer": false, "facts": ["Olives are fruits of the olive tree used in savory dishes and preparations like olive oil and tapenade", "A heladeria is an ice cream parlour"], "decomposition": ["What kinds of foods are served at a heladeria?", "Are olives a type of #1?"], "evidence": [[[["Lares Ice Cream Parlor-4"]], [["Olive-6"]]], [[["Heladería Coromoto-1"]], [["Olive-2"], "operation"]], [[["Heladería Coromoto-1"]], ["operation"]]]}
{"qid": "9e616f744f4084608c54", "term": "Sesame Street", "description": "American children's television program", "question": "Was Elmo an original muppet character on Sesame Street?", "answer": false, "facts": ["Sesame Street started in 1969.", "Elmo first appeared on the show in 1980."], "decomposition": ["When did Sesame Street make its debut?", "When did Elmo first appear on Sesame Street?", "Is #2 the same as #1?"], "evidence": [[[["Sesame Street-1"]], [["Elmo-3"]], ["operation"]], [[["Sesame Street-1"]], [["Elmo-3"]], ["operation"]], [[["Sesame Street-21"], "no_evidence"], [["Sesame Street-7"], "operation"], ["operation"]]]}
{"qid": "463faa7aaa7d9e1e366b", "term": "Europa (moon)", "description": "The smallest of the four Galilean moons of Jupiter", "question": "Is Europa linked to Viennese waltzes?", "answer": true, "facts": ["Europa is a moon of Jupiter", "Europa played an important role in Stanley Kubrick's film 2001: A Space Odyssey", "The soundtrack to 2001: A Space Odyssey prominently featured The Blue Danube", "The Blue Danube is a famous Viennese waltz composed by Johan Strauss II"], "decomposition": ["Which moon of Jupiter played an important role in the film '2001: A Space Odyssey'?", "Is #1 Europa?", "Which soundtrack was prominently featured in the movie?", "Is #3 a Viennese waltz?", "Are #2 and #4 positive?"], "evidence": [[["no_evidence"], ["operation"], [["2001: A Space Odyssey (film)-2", "The Blue Danube-14"]], [["The Blue Danube-1"]], ["operation"]], [[["2001: A Space Odyssey (film)-7"], "no_evidence"], [["Europa (moon)-1"], "operation"], [["2001: A Space Odyssey (film)-2"]], [["The Blue Danube-1"]], ["operation"]], [[["2001: A Space Odyssey (film)-7"], "no_evidence"], ["no_evidence", "operation"], [["2001: A Space Odyssey (film)-2"]], [["Johann Strauss II-1", "The Blue Danube-1"]], ["no_evidence", "operation"]]]}
{"qid": "0e8b696f5770ad5e3ea7", "term": "Pablo Escobar", "description": "Colombian drug lord (1949–1993)", "question": "Did Pablo Escobar's nickname collection outshine Robert Moses Grove's?", "answer": true, "facts": ["Robert Moses Grove was a baseball player nicknamed Lefty Grove.", "Pablo Escobar had several nicknames including: Don Pablo, El Padrino, and El Patrón."], "decomposition": ["How many nicknames did Pablo Escobar have?", "How many nicknames did Robert Moses Grove have?", "Is #1 greater than #2?"], "evidence": [[[["Pablo Escobar-28"]], [["Lefty Grove-1"]], [["Lefty Grove-1", "Pablo Escobar-28"]]], [[["Pablo Escobar-1", "Pablo Escobar-28"], "no_evidence"], [["Lefty Grove-1"]], ["operation"]], [[["Pablo Escobar-28"], "no_evidence"], [["Lefty Grove-1"]], ["no_evidence", "operation"]]]}
{"qid": "16bb34f451c9620e422c", "term": "Justin Timberlake", "description": "American singer, record producer, and actor", "question": "Can Justin Timberlake ride Shipwreck Falls at Six Flags?", "answer": true, "facts": ["Shipwreck Falls is a boat ride at Six Flags", "The minimum height for Shipwreck Falls is 42\"", "Justin Timberlake is 73\" tall"], "decomposition": ["What is Shipwreck Falls?", "What is the minimum height required to ride #1?", "How tall is Justin Timberlake?", "Is #3 bigger than #2?"], "evidence": [[[["Shipwreck Falls-1"]], ["no_evidence"], [["Justin Timberlake-1"], "no_evidence"], ["operation"]], [[["Shipwreck Falls-1"]], ["no_evidence"], ["no_evidence"], ["no_evidence", "operation"]], [[["Shipwreck Falls-1"]], ["no_evidence"], ["no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "c096042cd5db3c7ed663", "term": "Dodo", "description": "Extinct large flightless pigeon from Mauritius", "question": "Would a Dodo hypothetically tower over Ma Petite?", "answer": true, "facts": ["A Dodo was an extinct bird that was over 3 feet tall.", "Ma Petite was a character on American Horror Story played by Jyoti Amge.", "Jyoti Amge is around 2 feet tall."], "decomposition": ["How tall were dodos?", "Who played the role of Ma Petite?", "How tall is #2?", "Is #1 greater than #3?"], "evidence": [[[["Dodo-2"]], [["Jyoti Amge-1"]], [["Jyoti Amge-2"]], ["operation"]], [[["Dodo-2"]], [["Jyoti Amge-3"]], [["Jyoti Amge-2"]], ["operation"]], [[["Dodo-2"]], [["Jyoti Amge-3"]], [["Jyoti Amge-2"]], ["operation"]]]}
{"qid": "5799a384a9ca6cc645a0", "term": "Saturn", "description": "Sixth planet from the Sun in the Solar System", "question": "Is Saturn named after king of gods in Greek mythology?", "answer": false, "facts": ["Saturn, the sixth planet from the sun is named after the Roman god Saturn.", "The Roman god Saturn is derived from its Greek equivalent, Kronos.", "The king of the gods in Greek mythology was Zeus.", "Kronos was Zeus's father, and was the leader of the Titans."], "decomposition": ["Who were the king of the gods in Greek mythology?", "Which god was the planet Saturn named after?", "Is #2 the same as any of #1?"], "evidence": [[[["Zeus-1"]], [["Saturn-35"]], ["operation"]], [[["Zeus-1"]], [["Saturn-1"]], ["operation"]], [[["Cronus-1", "Uranus (mythology)-1", "Zeus-1"]], [["Saturn (mythology)-1", "Saturn-1"]], ["operation"]]]}
{"qid": "ec13093ea857962c647f", "term": "Palm Beach, Florida", "description": "Town in Florida, United States", "question": "Could Palm Beach be held in the palm of your hand?", "answer": false, "facts": ["Palm Beach has a total area of 8.12 square miles.", "The average palm is around 3 inches in length.", "There are 63360 inches in a mile."], "decomposition": ["What is the total area of Palm Beach?", "What is the maximum area that can be held on the palm of a human hand?", "Is #1 greater than or equal to #2?"], "evidence": [[[["Palm Beach, Florida-17"]], ["no_evidence"], ["operation"]], [[["Palm Beach, Florida-53"]], [["Human body-6"]], ["operation"]], [[["Palm Beach, Florida-17"]], ["no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "1479ad9ab9d5dbc5c140", "term": "The Matrix", "description": "1999 science fiction action film directed by the Wachowskis", "question": "Do the directors of The Matrix advocate for transgender rights?", "answer": true, "facts": ["Lilly Wachowski is a trans woman who was a director of The Matrix.", "Lena Wachowski is a trans woman who was a director of The Matrix.", "The Wachowski sisters speak actively about viewing their films through a \"lens of transness\""], "decomposition": ["Who directed The Matrix?", "Are #1 transgender rights advocates?"], "evidence": [[[["The Matrix-1"]], [["The Wachowskis-1", "The Wachowskis-57"]]], [[["The Matrix-1"]], [["The Wachowskis-57"], "operation"]], [[["The Wachowskis-2"]], [["The Wachowskis-53"], "operation"]]]}
{"qid": "d2e19ba0ffb3418fc545", "term": "Sun bear", "description": "bear found in tropical forest habitats of Southeast Asia", "question": "Do sun bears stay active during winter?", "answer": true, "facts": ["The sun bear is a species in the family Ursidae occurring in the tropical forests of Southeast Asia.", " Sun bears do not seem to hibernate.", "Hibernation is a seasonal heterothermy characterized by low body-temperature, slow breathing and heart-rate, and low metabolic rate. It most commonly occurs during winter months."], "decomposition": ["What characterizes the state of hibernation that some animals go into during winter?", "Are sun bears known to not exhibit the behavior described by #1?"], "evidence": [[[["Hibernation-3"]], [["Sun bear-2"], "operation"]], [[["Hibernation-1"]], [["Sun bear-2"], "operation"]], [[["Hibernation-1"]], [["Sun bear-11"]]]]}
{"qid": "42025ba75ec5d0f0f291", "term": "Zebra", "description": "Black and white striped animals in the horse family", "question": "Are black and white prison uniforms made to resemble a zebra?", "answer": false, "facts": ["Prison stripes are made of parallel lines.", "Zebra stripes are jagged in appearance. "], "decomposition": ["What is the design on a prison uniform?", "What is the pattern on a zebra?", "Is #1 the same as #2?"], "evidence": [[[["Prison uniform-28"], "no_evidence"], [["Plains zebra-13"]], ["operation"]], [[["Prison uniform-2"], "no_evidence"], [["Zebra-2"]], ["no_evidence", "operation"]], [[["Prison uniform-24", "Prison uniform-26"]], ["no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "ec3eecce8a13f2742ee4", "term": "Milky Way", "description": "Spiral galaxy containing our Solar System", "question": "Is number of stars in Milky Way at least ten times earth's population?", "answer": true, "facts": ["The number of stars in the Milky Way galaxy is between 100 and 400 billion.", "Earth's population in 2018 was 7.5 billion people."], "decomposition": ["How many stars are in the Milky Way galaxy?", "What is the number of the human population on earth?", "Is #1 greater than or equal to ten times #2?"], "evidence": [[[["Milky Way-2"]], [["World population-1"]], ["operation"]], [[["Milky Way-2"]], [["World population-1"]], ["operation"]], [[["Milky Way-2"]], [["World population-1"]], ["operation"]]]}
{"qid": "7281474f2760dce03f39", "term": "Crane (bird)", "description": "family of birds", "question": "Can crane slamdunk?", "answer": false, "facts": ["Crane are a type of bird. ", "Slamdunking is a basketball maneuver in which the player puts the basketball in the basket with one or two hands above the rim.", "Birds don't have hands."], "decomposition": ["What is a slamdunk?", "What body parts are needed to perform #1?", "Do cranes have #2?"], "evidence": [[[["Slam dunk-1"]], [["Slam dunk-6"]], [["Crane (bird)-1"], "operation"]], [[["Slam dunk-1"]], [["Hand-1"]], [["Crane (bird)-1"], "operation"]], [[["Slam dunk-1"]], [["Slam dunk-1"]], [["Crane (bird)-1"], "no_evidence"]]]}
{"qid": "87acce77a8b6362f4f96", "term": "Toyota Supra", "description": "A sports car and grand tourer manufactured by Toyota Motor Corporation", "question": "Would 2020 Toyota Supra lag behind at a Nascar rally?", "answer": true, "facts": ["The 2020 Toyota Supra has a top speed of 155 MPH.", "Nascar stock cars routinely exceed 200 MPH."], "decomposition": ["What speeds do stock cars in a NASCAR race routinely attain?", "What is the top speed of a Toyota Supra?", "Is #2 less than #1?"], "evidence": [[[["Stock car racing-3"]], [["Toyota Supra-61"]], ["operation"]], [[["Stock car racing-2"]], [["Toyota Supra-77"]], [["Stock car racing-2", "Toyota Supra-77"]]], [[["Stock car racing-65"]], [["Toyota Supra-61"]], ["operation"]]]}
{"qid": "497c4922b0552d7c5693", "term": "Argon", "description": "Chemical element with atomic number 18", "question": "Is Argon near Neon on the periodic table of elements?", "answer": true, "facts": ["Argon is a noble gas.", "Neon is a noble gas. ", "The noble gases are all clumped together on the periodic table of elements."], "decomposition": ["What group of the periodic table is argon in?", "What group of the periodic table is neon in?", "Is #1 the same as #2?"], "evidence": [[[["Noble gas-1"]], [["Noble gas-1"]], ["operation"]], [[["Argon-1"]], [["Noble gas-1", "Noble gas-2"]], ["operation"]], [[["Argon-1"]], [["Neon-21"]], [["Group (periodic table)-5"]]]]}
{"qid": "1a8ea71c1644ded6b058", "term": "Godzilla", "description": "Giant monster or kaiju", "question": "Could Godzilla have been killed by the Tohoku earthquake?", "answer": false, "facts": ["The Tohoku earthquake led to the Fukushima Daiichi nuclear power plant meltdown", "Nuclear meltdowns lead to a release of deadly levels of radiation", "Godzilla draws power from radiation and is not hurt by it"], "decomposition": ["What major accident was caused by the Tohoku Earthquake?", "What was released into the environment by #1?", "Does #2 cause harm to Godzilla?"], "evidence": [[[["2011 Tōhoku earthquake and tsunami-90"]], [["2011 Tōhoku earthquake and tsunami-90"]], [["Godzilla-2"], "operation"]], [[["2011 Tōhoku earthquake and tsunami-9"]], [["Fukushima Daiichi nuclear disaster-3"]], [["Godzilla-2"]]], [[["2011 Tōhoku earthquake and tsunami-9"]], [["2011 Tōhoku earthquake and tsunami-93"]], [["Godzilla-2"], "operation"]]]}
{"qid": "8b982a46f1a78d5f295f", "term": "Spider wasp", "description": "family of insects", "question": "Do spider wasps have eight legs?", "answer": false, "facts": ["A spider wasp is a kind of wasp, which is an insect.", "Insects all have six legs."], "decomposition": ["What kind of animal is a spider wasp?", "Do #1's have eight legs?"], "evidence": [[[["Spider wasp-1"]], [["Spider wasp-5"]]], [[["Spider wasp-1", "Wasp-1"]], [["Insect-1"], "operation"]], [[["Spider wasp-1"]], ["no_evidence"]]]}
{"qid": "18586794a7000980c6a8", "term": "Bing (search engine)", "description": "Web search engine from Microsoft", "question": "Do Bing (search engine) searches earn the searcher more than competitors do?", "answer": true, "facts": ["Bing (search engine) has a search rewards program that gives the user points, from conducting searches, to redeem for prizes.", "Bing (search engine) has several competitors such as Google, and DuckDuckGo.", "Google and DuckDuckGo do not have search rewards programs."], "decomposition": ["What does Bing give to people who use the search engine?", "Who are Bing's major competitors?", "What do the companies in #2 give people for using their service?", "Is #1 of greater value than #3?"], "evidence": [[[["Bing (search engine)-10", "Bing (search engine)-26"]], [["Bing (search engine)-52"]], ["no_evidence"], ["operation"]], [[["Bing (search engine)-57"]], [["Bing (search engine)-67"], "no_evidence"], ["no_evidence"], ["no_evidence", "operation"]], [[["Bing (search engine)-57"]], [["Bing (search engine)-54"]], ["no_evidence"], ["operation"]]]}
{"qid": "9cfa675eeebfbbdb2487", "term": "Bern", "description": "Place in Switzerland", "question": "Is Bern a poor choice for a xenophobic Swiss citizen to live?", "answer": false, "facts": ["Xenophobic people do not like people from other countries, such as tourists.", "Bern Switzerland was once described by CNN as being a relatively tourist free area.", "Zurich and Geneva get the most tourist traffic out of any city in Switzerland."], "decomposition": ["Who do xenophobic people want to avoid?", "What was Bern Switzerland once described by CNN as?", "Is #1 the same as #2?"], "evidence": [[[["Xenophobia-1"]], [["Bern-39", "Canton of Bern-64"], "no_evidence"], ["operation"]], [[["Xenophobia-1"]], [["Bern-39"], "no_evidence"], ["no_evidence", "operation"]], [[["Xenophobia-1"]], [["Bern-17"], "no_evidence"], ["operation"]]]}
{"qid": "df951faeafccf7c29be9", "term": "Football War", "description": "1969 War between Honduras and El Salvador", "question": "Did either side score a touchdown during the Football War?", "answer": false, "facts": ["The Football War was a war in 1969 between Honduras and El Salvador", "The Football War was caused in part by rioting during a FIFA Cup qualifying match", "The FIFA Cup is a soccer tournament", "Touchdowns are scored in American football"], "decomposition": ["Which sport was involved as one of the causes of the Football War?", "Which sport are touchdowns scored in?", "Are #1 and #2 the same?"], "evidence": [[[["Association football-1", "FIFA-1", "Football War-1"]], [["American football-1"]], ["operation"]], [[["Football War-1"]], [["Touchdown-1"]], ["operation"]], [[["Football War-1"]], [["Touchdown-1"]], ["operation"]]]}
{"qid": "a9d3a5f8cd6eb6b2c19a", "term": "Sahara", "description": "desert in Africa", "question": "Can Spartina Patens thrive in the Sahara Desert?", "answer": false, "facts": ["Spartina Patens is a type of cordgrass that grows in salt marshes.", "Spartina Patens requires a marsh-like environment to thrive.", "The Sahara Desert is known for being dry and very hot."], "decomposition": ["What soil conditions are suitable for the growth of Spartina Patens?", "Is #1 likely to be present in the Sahara desert?"], "evidence": [[[["Spartina patens-2"]], [["Sahara-2"], "operation"]], [[["Spartina patens-2"]], ["operation"]], [[["Spartina patens-1"]], [["Sahara-1"]]]]}
{"qid": "9b77992543134de72b4e", "term": "Tokyo Tower", "description": "observation tower", "question": "Will Tokyo Tower be repainted only once during President Trump's first term?", "answer": true, "facts": ["Tokyo Tower is repainted every five years ", "The last repainting began in 2018", "Trump's first presidential term is from 2017 to 2021"], "decomposition": ["How long (in years) is President Trump's first term?", "How often (interval in years) is the Tokyo Tower repainted?", "Is #2 divided by #1 less than two?"], "evidence": [[[["Term of office-11"], "no_evidence"], [["Tokyo Tower-10"]], ["operation"]], [[["President of the United States-4"]], [["Tokyo Tower-10"]], ["operation"]], [[["President of the United States-5"]], [["Tokyo Tower-3"]], ["operation"]]]}
{"qid": "054ae21cacd3669f6694", "term": "Elizabeth II", "description": "Queen of the United Kingdom and the other Commonwealth realms", "question": "Does the actress who played Elizabeth II speak fluent Arabic?", "answer": false, "facts": ["Elizabeth II was portrayed by Helen Mirren. ", "Helen Mirren doesn't speak fluent Arabic. "], "decomposition": ["Which movie has portrayed Queen Elizabeth II of the United Kingdom?", "Who acted as Queen Elizabeth II in #1?", "What is #2's nationality?", "Do they speak fluent Arabic in #3?"], "evidence": [[[["The Queen (2006 film)-2"]], [["The Queen (2006 film)-2"]], [["Helen Mirren-1", "Helen Mirren-5"]], [["English language in England-1"]]], [[["The Queen (2006 film)-4"]], [["The Queen (2006 film)-11"]], [["Helen Mirren-1"]], [["England-2"], "operation"]], [[["Elizabeth (film)-1"]], [["Elizabeth (film)-1"]], [["Cate Blanchett-5"]], [["Arab world-1"], "no_evidence"]]]}
